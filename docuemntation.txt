All documentation
Assistants
Beta
Build assistants that can call models and use tools to perform tasks.

Get started with the Assistants API

Create assistant
Beta
post
 
https://api.openai.com/v1/assistants
Create an assistant with a model and instructions.

Request body
model
string

Required
ID of the model to use. You can use the List models API to see all of your available models, or see our Model overview for descriptions of them.

name
string or null

Optional
The name of the assistant. The maximum length is 256 characters.

description
string or null

Optional
The description of the assistant. The maximum length is 512 characters.

instructions
string or null

Optional
The system instructions that the assistant uses. The maximum length is 256,000 characters.

reasoning_effort
string or null

Optional
Defaults to medium
o1 and o3-mini models only

Constrains effort on reasoning for reasoning models. Currently supported values are low, medium, and high. Reducing reasoning effort can result in faster responses and fewer tokens used on reasoning in a response.

tools
array

Optional
Defaults to []
A list of tool enabled on the assistant. There can be a maximum of 128 tools per assistant. Tools can be of types code_interpreter, file_search, or function.


Show possible types
tool_resources
object or null

Optional
A set of resources that are used by the assistant's tools. The resources are specific to the type of tool. For example, the code_interpreter tool requires a list of file IDs, while the file_search tool requires a list of vector store IDs.


Show properties
metadata
map

Optional
Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format, and querying for objects via API or the dashboard.

Keys are strings with a maximum length of 64 characters. Values are strings with a maximum length of 512 characters.

temperature
number or null

Optional
Defaults to 1
What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic.

top_p
number or null

Optional
Defaults to 1
An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered.

We generally recommend altering this or temperature but not both.

response_format
"auto" or object

Optional
Specifies the format that the model must output. Compatible with GPT-4o, GPT-4 Turbo, and all GPT-3.5 Turbo models since gpt-3.5-turbo-1106.

Setting to { "type": "json_schema", "json_schema": {...} } enables Structured Outputs which ensures the model will match your supplied JSON schema. Learn more in the Structured Outputs guide.

Setting to { "type": "json_object" } enables JSON mode, which ensures the message the model generates is valid JSON.

Important: when using JSON mode, you must also instruct the model to produce JSON yourself via a system or user message. Without this, the model may generate an unending stream of whitespace until the generation reaches the token limit, resulting in a long-running and seemingly "stuck" request. Also note that the message content may be partially cut off if finish_reason="length", which indicates the generation exceeded max_tokens or the conversation exceeded the max context length.


Show possible types
Returns
An assistant object.


Code Interpreter

Files
Example request
curl "https://api.openai.com/v1/assistants" \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "OpenAI-Beta: assistants=v2" \
  -d '{
    "instructions": "You are a personal math tutor. When asked a question, write and run Python code to answer the question.",
    "name": "Math Tutor",
    "tools": [{"type": "code_interpreter"}],
    "model": "gpt-4o"
  }'
Response
{
  "id": "asst_abc123",
  "object": "assistant",
  "created_at": 1698984975,
  "name": "Math Tutor",
  "description": null,
  "model": "gpt-4o",
  "instructions": "You are a personal math tutor. When asked a question, write and run Python code to answer the question.",
  "tools": [
    {
      "type": "code_interpreter"
    }
  ],
  "metadata": {},
  "top_p": 1.0,
  "temperature": 1.0,
  "response_format": "auto"
}
List assistants
Beta
get
 
https://api.openai.com/v1/assistants
Returns a list of assistants.

Query parameters
limit
integer

Optional
Defaults to 20
A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.

order
string

Optional
Defaults to desc
Sort order by the created_at timestamp of the objects. asc for ascending order and desc for descending order.

after
string

Optional
A cursor for use in pagination. after is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj_foo, your subsequent call can include after=obj_foo in order to fetch the next page of the list.

before
string

Optional
A cursor for use in pagination. before is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, starting with obj_foo, your subsequent call can include before=obj_foo in order to fetch the previous page of the list.

Returns
A list of assistant objects.

Example request
curl "https://api.openai.com/v1/assistants?order=desc&limit=20" \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "OpenAI-Beta: assistants=v2"
Response
{
  "object": "list",
  "data": [
    {
      "id": "asst_abc123",
      "object": "assistant",
      "created_at": 1698982736,
      "name": "Coding Tutor",
      "description": null,
      "model": "gpt-4o",
      "instructions": "You are a helpful assistant designed to make me better at coding!",
      "tools": [],
      "tool_resources": {},
      "metadata": {},
      "top_p": 1.0,
      "temperature": 1.0,
      "response_format": "auto"
    },
    {
      "id": "asst_abc456",
      "object": "assistant",
      "created_at": 1698982718,
      "name": "My Assistant",
      "description": null,
      "model": "gpt-4o",
      "instructions": "You are a helpful assistant designed to make me better at coding!",
      "tools": [],
      "tool_resources": {},
      "metadata": {},
      "top_p": 1.0,
      "temperature": 1.0,
      "response_format": "auto"
    },
    {
      "id": "asst_abc789",
      "object": "assistant",
      "created_at": 1698982643,
      "name": null,
      "description": null,
      "model": "gpt-4o",
      "instructions": null,
      "tools": [],
      "tool_resources": {},
      "metadata": {},
      "top_p": 1.0,
      "temperature": 1.0,
      "response_format": "auto"
    }
  ],
  "first_id": "asst_abc123",
  "last_id": "asst_abc789",
  "has_more": false
}
Retrieve assistant
Beta
get
 
https://api.openai.com/v1/assistants/{assistant_id}
Retrieves an assistant.

Path parameters
assistant_id
string

Required
The ID of the assistant to retrieve.

Returns
The assistant object matching the specified ID.

Example request
curl https://api.openai.com/v1/assistants/asst_abc123 \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "OpenAI-Beta: assistants=v2"
Response
{
  "id": "asst_abc123",
  "object": "assistant",
  "created_at": 1699009709,
  "name": "HR Helper",
  "description": null,
  "model": "gpt-4o",
  "instructions": "You are an HR bot, and you have access to files to answer employee questions about company policies.",
  "tools": [
    {
      "type": "file_search"
    }
  ],
  "metadata": {},
  "top_p": 1.0,
  "temperature": 1.0,
  "response_format": "auto"
}
Modify assistant
Beta
post
 
https://api.openai.com/v1/assistants/{assistant_id}
Modifies an assistant.

Path parameters
assistant_id
string

Required
The ID of the assistant to modify.

Request body
model
Optional
ID of the model to use. You can use the List models API to see all of your available models, or see our Model overview for descriptions of them.

reasoning_effort
string or null

Optional
Defaults to medium
o1 and o3-mini models only

Constrains effort on reasoning for reasoning models. Currently supported values are low, medium, and high. Reducing reasoning effort can result in faster responses and fewer tokens used on reasoning in a response.

name
string or null

Optional
The name of the assistant. The maximum length is 256 characters.

description
string or null

Optional
The description of the assistant. The maximum length is 512 characters.

instructions
string or null

Optional
The system instructions that the assistant uses. The maximum length is 256,000 characters.

tools
array

Optional
Defaults to []
A list of tool enabled on the assistant. There can be a maximum of 128 tools per assistant. Tools can be of types code_interpreter, file_search, or function.


Show possible types
tool_resources
object or null

Optional
A set of resources that are used by the assistant's tools. The resources are specific to the type of tool. For example, the code_interpreter tool requires a list of file IDs, while the file_search tool requires a list of vector store IDs.


Show properties
metadata
map

Optional
Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format, and querying for objects via API or the dashboard.

Keys are strings with a maximum length of 64 characters. Values are strings with a maximum length of 512 characters.

temperature
number or null

Optional
Defaults to 1
What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic.

top_p
number or null

Optional
Defaults to 1
An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered.

We generally recommend altering this or temperature but not both.

response_format
"auto" or object

Optional
Specifies the format that the model must output. Compatible with GPT-4o, GPT-4 Turbo, and all GPT-3.5 Turbo models since gpt-3.5-turbo-1106.

Setting to { "type": "json_schema", "json_schema": {...} } enables Structured Outputs which ensures the model will match your supplied JSON schema. Learn more in the Structured Outputs guide.

Setting to { "type": "json_object" } enables JSON mode, which ensures the message the model generates is valid JSON.

Important: when using JSON mode, you must also instruct the model to produce JSON yourself via a system or user message. Without this, the model may generate an unending stream of whitespace until the generation reaches the token limit, resulting in a long-running and seemingly "stuck" request. Also note that the message content may be partially cut off if finish_reason="length", which indicates the generation exceeded max_tokens or the conversation exceeded the max context length.


Show possible types
Returns
The modified assistant object.

Example request
curl https://api.openai.com/v1/assistants/asst_abc123 \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "OpenAI-Beta: assistants=v2" \
  -d '{
      "instructions": "You are an HR bot, and you have access to files to answer employee questions about company policies. Always response with info from either of the files.",
      "tools": [{"type": "file_search"}],
      "model": "gpt-4o"
    }'
Response
{
  "id": "asst_123",
  "object": "assistant",
  "created_at": 1699009709,
  "name": "HR Helper",
  "description": null,
  "model": "gpt-4o",
  "instructions": "You are an HR bot, and you have access to files to answer employee questions about company policies. Always response with info from either of the files.",
  "tools": [
    {
      "type": "file_search"
    }
  ],
  "tool_resources": {
    "file_search": {
      "vector_store_ids": []
    }
  },
  "metadata": {},
  "top_p": 1.0,
  "temperature": 1.0,
  "response_format": "auto"
}
Delete assistant
Beta
delete
 
https://api.openai.com/v1/assistants/{assistant_id}
Delete an assistant.

Path parameters
assistant_id
string

Required
The ID of the assistant to delete.

Returns
Deletion status

Example request
curl https://api.openai.com/v1/assistants/asst_abc123 \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "OpenAI-Beta: assistants=v2" \
  -X DELETE
Response
{
  "id": "asst_abc123",
  "object": "assistant.deleted",
  "deleted": true
}
The assistant object
Beta
Represents an assistant that can call the model and use tools.

id
string

The identifier, which can be referenced in API endpoints.

object
string

The object type, which is always assistant.

created_at
integer

The Unix timestamp (in seconds) for when the assistant was created.

name
string or null

The name of the assistant. The maximum length is 256 characters.

description
string or null

The description of the assistant. The maximum length is 512 characters.

model
string

ID of the model to use. You can use the List models API to see all of your available models, or see our Model overview for descriptions of them.

instructions
string or null

The system instructions that the assistant uses. The maximum length is 256,000 characters.

tools
array

A list of tool enabled on the assistant. There can be a maximum of 128 tools per assistant. Tools can be of types code_interpreter, file_search, or function.


Show possible types
tool_resources
object or null

A set of resources that are used by the assistant's tools. The resources are specific to the type of tool. For example, the code_interpreter tool requires a list of file IDs, while the file_search tool requires a list of vector store IDs.


Show properties
metadata
map

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format, and querying for objects via API or the dashboard.

Keys are strings with a maximum length of 64 characters. Values are strings with a maximum length of 512 characters.

temperature
number or null

What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic.

top_p
number or null

An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered.

We generally recommend altering this or temperature but not both.

response_format
"auto" or object

Specifies the format that the model must output. Compatible with GPT-4o, GPT-4 Turbo, and all GPT-3.5 Turbo models since gpt-3.5-turbo-1106.

Setting to { "type": "json_schema", "json_schema": {...} } enables Structured Outputs which ensures the model will match your supplied JSON schema. Learn more in the Structured Outputs guide.

Setting to { "type": "json_object" } enables JSON mode, which ensures the message the model generates is valid JSON.

Important: when using JSON mode, you must also instruct the model to produce JSON yourself via a system or user message. Without this, the model may generate an unending stream of whitespace until the generation reaches the token limit, resulting in a long-running and seemingly "stuck" request. Also note that the message content may be partially cut off if finish_reason="length", which indicates the generation exceeded max_tokens or the conversation exceeded the max context length.


Show possible types
OBJECT The assistant object
{
  "id": "asst_abc123",
  "object": "assistant",
  "created_at": 1698984975,
  "name": "Math Tutor",
  "description": null,
  "model": "gpt-4o",
  "instructions": "You are a personal math tutor. When asked a question, write and run Python code to answer the question.",
  "tools": [
    {
      "type": "code_interpreter"
    }
  ],
  "metadata": {},
  "top_p": 1.0,
  "temperature": 1.0,
  "response_format": "auto"
}
Threads
Beta
Create threads that assistants can interact with.

Related guide: Assistants

Create thread
Beta
post
 
https://api.openai.com/v1/threads
Create a thread.

Request body
messages
array

Optional
A list of messages to start the thread with.


Show properties
tool_resources
object or null

Optional
A set of resources that are made available to the assistant's tools in this thread. The resources are specific to the type of tool. For example, the code_interpreter tool requires a list of file IDs, while the file_search tool requires a list of vector store IDs.


Show properties
metadata
map

Optional
Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format, and querying for objects via API or the dashboard.

Keys are strings with a maximum length of 64 characters. Values are strings with a maximum length of 512 characters.

Returns
A thread object.


Empty

Messages
Example request
curl https://api.openai.com/v1/threads \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "OpenAI-Beta: assistants=v2" \
  -d ''
Response
{
  "id": "thread_abc123",
  "object": "thread",
  "created_at": 1699012949,
  "metadata": {},
  "tool_resources": {}
}
Retrieve thread
Beta
get
 
https://api.openai.com/v1/threads/{thread_id}
Retrieves a thread.

Path parameters
thread_id
string

Required
The ID of the thread to retrieve.

Returns
The thread object matching the specified ID.

Example request
curl https://api.openai.com/v1/threads/thread_abc123 \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "OpenAI-Beta: assistants=v2"
Response
{
  "id": "thread_abc123",
  "object": "thread",
  "created_at": 1699014083,
  "metadata": {},
  "tool_resources": {
    "code_interpreter": {
      "file_ids": []
    }
  }
}
Modify thread
Beta
post
 
https://api.openai.com/v1/threads/{thread_id}
Modifies a thread.

Path parameters
thread_id
string

Required
The ID of the thread to modify. Only the metadata can be modified.

Request body
tool_resources
object or null

Optional
A set of resources that are made available to the assistant's tools in this thread. The resources are specific to the type of tool. For example, the code_interpreter tool requires a list of file IDs, while the file_search tool requires a list of vector store IDs.


Show properties
metadata
map

Optional
Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format, and querying for objects via API or the dashboard.

Keys are strings with a maximum length of 64 characters. Values are strings with a maximum length of 512 characters.

Returns
The modified thread object matching the specified ID.

Example request
curl https://api.openai.com/v1/threads/thread_abc123 \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "OpenAI-Beta: assistants=v2" \
  -d '{
      "metadata": {
        "modified": "true",
        "user": "abc123"
      }
    }'
Response
{
  "id": "thread_abc123",
  "object": "thread",
  "created_at": 1699014083,
  "metadata": {
    "modified": "true",
    "user": "abc123"
  },
  "tool_resources": {}
}
Delete thread
Beta
delete
 
https://api.openai.com/v1/threads/{thread_id}
Delete a thread.

Path parameters
thread_id
string

Required
The ID of the thread to delete.

Returns
Deletion status

Example request
curl https://api.openai.com/v1/threads/thread_abc123 \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "OpenAI-Beta: assistants=v2" \
  -X DELETE
Response
{
  "id": "thread_abc123",
  "object": "thread.deleted",
  "deleted": true
}
The thread object
Beta
Represents a thread that contains messages.

id
string

The identifier, which can be referenced in API endpoints.

object
string

The object type, which is always thread.

created_at
integer

The Unix timestamp (in seconds) for when the thread was created.

tool_resources
object or null

A set of resources that are made available to the assistant's tools in this thread. The resources are specific to the type of tool. For example, the code_interpreter tool requires a list of file IDs, while the file_search tool requires a list of vector store IDs.


Show properties
metadata
map

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format, and querying for objects via API or the dashboard.

Keys are strings with a maximum length of 64 characters. Values are strings with a maximum length of 512 characters.

OBJECT The thread object
{
  "id": "thread_abc123",
  "object": "thread",
  "created_at": 1698107661,
  "metadata": {}
}
Messages
Beta
Create messages within threads

Related guide: Assistants

Create message
Beta
post
 
https://api.openai.com/v1/threads/{thread_id}/messages
Create a message.

Path parameters
thread_id
string

Required
The ID of the thread to create a message for.

Request body
role
string

Required
The role of the entity that is creating the message. Allowed values include:

user: Indicates the message is sent by an actual user and should be used in most cases to represent user-generated messages.
assistant: Indicates the message is generated by the assistant. Use this value to insert messages from the assistant into the conversation.
content
string or array

Required

Show possible types
attachments
array or null

Optional
A list of files attached to the message, and the tools they should be added to.


Show properties
metadata
map

Optional
Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format, and querying for objects via API or the dashboard.

Keys are strings with a maximum length of 64 characters. Values are strings with a maximum length of 512 characters.

Returns
A message object.

Example request
curl https://api.openai.com/v1/threads/thread_abc123/messages \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "OpenAI-Beta: assistants=v2" \
  -d '{
      "role": "user",
      "content": "How does AI work? Explain it in simple terms."
    }'
Response
{
  "id": "msg_abc123",
  "object": "thread.message",
  "created_at": 1713226573,
  "assistant_id": null,
  "thread_id": "thread_abc123",
  "run_id": null,
  "role": "user",
  "content": [
    {
      "type": "text",
      "text": {
        "value": "How does AI work? Explain it in simple terms.",
        "annotations": []
      }
    }
  ],
  "attachments": [],
  "metadata": {}
}
List messages
Beta
get
 
https://api.openai.com/v1/threads/{thread_id}/messages
Returns a list of messages for a given thread.

Path parameters
thread_id
string

Required
The ID of the thread the messages belong to.

Query parameters
limit
integer

Optional
Defaults to 20
A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.

order
string

Optional
Defaults to desc
Sort order by the created_at timestamp of the objects. asc for ascending order and desc for descending order.

after
string

Optional
A cursor for use in pagination. after is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj_foo, your subsequent call can include after=obj_foo in order to fetch the next page of the list.

before
string

Optional
A cursor for use in pagination. before is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, starting with obj_foo, your subsequent call can include before=obj_foo in order to fetch the previous page of the list.

run_id
string

Optional
Filter messages by the run ID that generated them.

Returns
A list of message objects.

Example request
curl https://api.openai.com/v1/threads/thread_abc123/messages \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "OpenAI-Beta: assistants=v2"
Response
{
  "object": "list",
  "data": [
    {
      "id": "msg_abc123",
      "object": "thread.message",
      "created_at": 1699016383,
      "assistant_id": null,
      "thread_id": "thread_abc123",
      "run_id": null,
      "role": "user",
      "content": [
        {
          "type": "text",
          "text": {
            "value": "How does AI work? Explain it in simple terms.",
            "annotations": []
          }
        }
      ],
      "attachments": [],
      "metadata": {}
    },
    {
      "id": "msg_abc456",
      "object": "thread.message",
      "created_at": 1699016383,
      "assistant_id": null,
      "thread_id": "thread_abc123",
      "run_id": null,
      "role": "user",
      "content": [
        {
          "type": "text",
          "text": {
            "value": "Hello, what is AI?",
            "annotations": []
          }
        }
      ],
      "attachments": [],
      "metadata": {}
    }
  ],
  "first_id": "msg_abc123",
  "last_id": "msg_abc456",
  "has_more": false
}
Retrieve message
Beta
get
 
https://api.openai.com/v1/threads/{thread_id}/messages/{message_id}
Retrieve a message.

Path parameters
thread_id
string

Required
The ID of the thread to which this message belongs.

message_id
string

Required
The ID of the message to retrieve.

Returns
The message object matching the specified ID.

Example request
curl https://api.openai.com/v1/threads/thread_abc123/messages/msg_abc123 \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "OpenAI-Beta: assistants=v2"
Response
{
  "id": "msg_abc123",
  "object": "thread.message",
  "created_at": 1699017614,
  "assistant_id": null,
  "thread_id": "thread_abc123",
  "run_id": null,
  "role": "user",
  "content": [
    {
      "type": "text",
      "text": {
        "value": "How does AI work? Explain it in simple terms.",
        "annotations": []
      }
    }
  ],
  "attachments": [],
  "metadata": {}
}
Modify message
Beta
post
 
https://api.openai.com/v1/threads/{thread_id}/messages/{message_id}
Modifies a message.

Path parameters
thread_id
string

Required
The ID of the thread to which this message belongs.

message_id
string

Required
The ID of the message to modify.

Request body
metadata
map

Optional
Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format, and querying for objects via API or the dashboard.

Keys are strings with a maximum length of 64 characters. Values are strings with a maximum length of 512 characters.

Returns
The modified message object.

Example request
curl https://api.openai.com/v1/threads/thread_abc123/messages/msg_abc123 \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "OpenAI-Beta: assistants=v2" \
  -d '{
      "metadata": {
        "modified": "true",
        "user": "abc123"
      }
    }'
Response
{
  "id": "msg_abc123",
  "object": "thread.message",
  "created_at": 1699017614,
  "assistant_id": null,
  "thread_id": "thread_abc123",
  "run_id": null,
  "role": "user",
  "content": [
    {
      "type": "text",
      "text": {
        "value": "How does AI work? Explain it in simple terms.",
        "annotations": []
      }
    }
  ],
  "file_ids": [],
  "metadata": {
    "modified": "true",
    "user": "abc123"
  }
}
Delete message
Beta
delete
 
https://api.openai.com/v1/threads/{thread_id}/messages/{message_id}
Deletes a message.

Path parameters
thread_id
string

Required
The ID of the thread to which this message belongs.

message_id
string

Required
The ID of the message to delete.

Returns
Deletion status

Example request
curl -X DELETE https://api.openai.com/v1/threads/thread_abc123/messages/msg_abc123 \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "OpenAI-Beta: assistants=v2"
Response
{
  "id": "msg_abc123",
  "object": "thread.message.deleted",
  "deleted": true
}
The message object
Beta
Represents a message within a thread.

id
string

The identifier, which can be referenced in API endpoints.

object
string

The object type, which is always thread.message.

created_at
integer

The Unix timestamp (in seconds) for when the message was created.

thread_id
string

The thread ID that this message belongs to.

status
string

The status of the message, which can be either in_progress, incomplete, or completed.

incomplete_details
object or null

On an incomplete message, details about why the message is incomplete.


Show properties
completed_at
integer or null

The Unix timestamp (in seconds) for when the message was completed.

incomplete_at
integer or null

The Unix timestamp (in seconds) for when the message was marked as incomplete.

role
string

The entity that produced the message. One of user or assistant.

content
array

The content of the message in array of text and/or images.


Show possible types
assistant_id
string or null

If applicable, the ID of the assistant that authored this message.

run_id
string or null

The ID of the run associated with the creation of this message. Value is null when messages are created manually using the create message or create thread endpoints.

attachments
array or null

A list of files attached to the message, and the tools they were added to.


Show properties
metadata
map

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format, and querying for objects via API or the dashboard.

Keys are strings with a maximum length of 64 characters. Values are strings with a maximum length of 512 characters.

OBJECT The message object
{
  "id": "msg_abc123",
  "object": "thread.message",
  "created_at": 1698983503,
  "thread_id": "thread_abc123",
  "role": "assistant",
  "content": [
    {
      "type": "text",
      "text": {
        "value": "Hi! How can I help you today?",
        "annotations": []
      }
    }
  ],
  "assistant_id": "asst_abc123",
  "run_id": "run_abc123",
  "attachments": [],
  "metadata": {}
}
Runs
Beta
Represents an execution run on a thread.

Related guide: Assistants

Create run
Beta
post
 
https://api.openai.com/v1/threads/{thread_id}/runs
Create a run.

Path parameters
thread_id
string

Required
The ID of the thread to run.

Query parameters
include[]
array

Optional
A list of additional fields to include in the response. Currently the only supported value is step_details.tool_calls[*].file_search.results[*].content to fetch the file search result content.

See the file search tool documentation for more information.

Request body
assistant_id
string

Required
The ID of the assistant to use to execute this run.

model
string

Optional
The ID of the Model to be used to execute this run. If a value is provided here, it will override the model associated with the assistant. If not, the model associated with the assistant will be used.

reasoning_effort
string or null

Optional
Defaults to medium
o1 and o3-mini models only

Constrains effort on reasoning for reasoning models. Currently supported values are low, medium, and high. Reducing reasoning effort can result in faster responses and fewer tokens used on reasoning in a response.

instructions
string or null

Optional
Overrides the instructions of the assistant. This is useful for modifying the behavior on a per-run basis.

additional_instructions
string or null

Optional
Appends additional instructions at the end of the instructions for the run. This is useful for modifying the behavior on a per-run basis without overriding other instructions.

additional_messages
array or null

Optional
Adds additional messages to the thread before creating the run.


Show properties
tools
array or null

Optional
Override the tools the assistant can use for this run. This is useful for modifying the behavior on a per-run basis.


Show possible types
metadata
map

Optional
Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format, and querying for objects via API or the dashboard.

Keys are strings with a maximum length of 64 characters. Values are strings with a maximum length of 512 characters.

temperature
number or null

Optional
Defaults to 1
What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic.

top_p
number or null

Optional
Defaults to 1
An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered.

We generally recommend altering this or temperature but not both.

stream
boolean or null

Optional
If true, returns a stream of events that happen during the Run as server-sent events, terminating when the Run enters a terminal state with a data: [DONE] message.

max_prompt_tokens
integer or null

Optional
The maximum number of prompt tokens that may be used over the course of the run. The run will make a best effort to use only the number of prompt tokens specified, across multiple turns of the run. If the run exceeds the number of prompt tokens specified, the run will end with status incomplete. See incomplete_details for more info.

max_completion_tokens
integer or null

Optional
The maximum number of completion tokens that may be used over the course of the run. The run will make a best effort to use only the number of completion tokens specified, across multiple turns of the run. If the run exceeds the number of completion tokens specified, the run will end with status incomplete. See incomplete_details for more info.

truncation_strategy
object

Optional
Controls for how a thread will be truncated prior to the run. Use this to control the intial context window of the run.


Show properties
tool_choice
string or object

Optional
Controls which (if any) tool is called by the model. none means the model will not call any tools and instead generates a message. auto is the default value and means the model can pick between generating a message or calling one or more tools. required means the model must call one or more tools before responding to the user. Specifying a particular tool like {"type": "file_search"} or {"type": "function", "function": {"name": "my_function"}} forces the model to call that tool.


Show possible types
parallel_tool_calls
boolean

Optional
Defaults to true
Whether to enable parallel function calling during tool use.

response_format
"auto" or object

Optional
Specifies the format that the model must output. Compatible with GPT-4o, GPT-4 Turbo, and all GPT-3.5 Turbo models since gpt-3.5-turbo-1106.

Setting to { "type": "json_schema", "json_schema": {...} } enables Structured Outputs which ensures the model will match your supplied JSON schema. Learn more in the Structured Outputs guide.

Setting to { "type": "json_object" } enables JSON mode, which ensures the message the model generates is valid JSON.

Important: when using JSON mode, you must also instruct the model to produce JSON yourself via a system or user message. Without this, the model may generate an unending stream of whitespace until the generation reaches the token limit, resulting in a long-running and seemingly "stuck" request. Also note that the message content may be partially cut off if finish_reason="length", which indicates the generation exceeded max_tokens or the conversation exceeded the max context length.


Show possible types
Returns
A run object.


Default

Streaming

Streaming with Functions
Example request
curl https://api.openai.com/v1/threads/thread_abc123/runs \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -H "OpenAI-Beta: assistants=v2" \
  -d '{
    "assistant_id": "asst_abc123"
  }'
Response
{
  "id": "run_abc123",
  "object": "thread.run",
  "created_at": 1699063290,
  "assistant_id": "asst_abc123",
  "thread_id": "thread_abc123",
  "status": "queued",
  "started_at": 1699063290,
  "expires_at": null,
  "cancelled_at": null,
  "failed_at": null,
  "completed_at": 1699063291,
  "last_error": null,
  "model": "gpt-4o",
  "instructions": null,
  "incomplete_details": null,
  "tools": [
    {
      "type": "code_interpreter"
    }
  ],
  "metadata": {},
  "usage": null,
  "temperature": 1.0,
  "top_p": 1.0,
  "max_prompt_tokens": 1000,
  "max_completion_tokens": 1000,
  "truncation_strategy": {
    "type": "auto",
    "last_messages": null
  },
  "response_format": "auto",
  "tool_choice": "auto",
  "parallel_tool_calls": true
}
Create thread and run
Beta
post
 
https://api.openai.com/v1/threads/runs
Create a thread and run it in one request.

Request body
assistant_id
string

Required
The ID of the assistant to use to execute this run.

thread
object

Optional
Options to create a new thread. If no thread is provided when running a request, an empty thread will be created.


Show properties
model
string

Optional
The ID of the Model to be used to execute this run. If a value is provided here, it will override the model associated with the assistant. If not, the model associated with the assistant will be used.

instructions
string or null

Optional
Override the default system message of the assistant. This is useful for modifying the behavior on a per-run basis.

tools
array or null

Optional
Override the tools the assistant can use for this run. This is useful for modifying the behavior on a per-run basis.

tool_resources
object or null

Optional
A set of resources that are used by the assistant's tools. The resources are specific to the type of tool. For example, the code_interpreter tool requires a list of file IDs, while the file_search tool requires a list of vector store IDs.


Show properties
metadata
map

Optional
Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format, and querying for objects via API or the dashboard.

Keys are strings with a maximum length of 64 characters. Values are strings with a maximum length of 512 characters.

temperature
number or null

Optional
Defaults to 1
What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic.

top_p
number or null

Optional
Defaults to 1
An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered.

We generally recommend altering this or temperature but not both.

stream
boolean or null

Optional
If true, returns a stream of events that happen during the Run as server-sent events, terminating when the Run enters a terminal state with a data: [DONE] message.

max_prompt_tokens
integer or null

Optional
The maximum number of prompt tokens that may be used over the course of the run. The run will make a best effort to use only the number of prompt tokens specified, across multiple turns of the run. If the run exceeds the number of prompt tokens specified, the run will end with status incomplete. See incomplete_details for more info.

max_completion_tokens
integer or null

Optional
The maximum number of completion tokens that may be used over the course of the run. The run will make a best effort to use only the number of completion tokens specified, across multiple turns of the run. If the run exceeds the number of completion tokens specified, the run will end with status incomplete. See incomplete_details for more info.

truncation_strategy
object

Optional
Controls for how a thread will be truncated prior to the run. Use this to control the intial context window of the run.


Show properties
tool_choice
string or object

Optional
Controls which (if any) tool is called by the model. none means the model will not call any tools and instead generates a message. auto is the default value and means the model can pick between generating a message or calling one or more tools. required means the model must call one or more tools before responding to the user. Specifying a particular tool like {"type": "file_search"} or {"type": "function", "function": {"name": "my_function"}} forces the model to call that tool.


Show possible types
parallel_tool_calls
boolean

Optional
Defaults to true
Whether to enable parallel function calling during tool use.

response_format
"auto" or object

Optional
Specifies the format that the model must output. Compatible with GPT-4o, GPT-4 Turbo, and all GPT-3.5 Turbo models since gpt-3.5-turbo-1106.

Setting to { "type": "json_schema", "json_schema": {...} } enables Structured Outputs which ensures the model will match your supplied JSON schema. Learn more in the Structured Outputs guide.

Setting to { "type": "json_object" } enables JSON mode, which ensures the message the model generates is valid JSON.

Important: when using JSON mode, you must also instruct the model to produce JSON yourself via a system or user message. Without this, the model may generate an unending stream of whitespace until the generation reaches the token limit, resulting in a long-running and seemingly "stuck" request. Also note that the message content may be partially cut off if finish_reason="length", which indicates the generation exceeded max_tokens or the conversation exceeded the max context length.


Show possible types
Returns
A run object.


Default

Streaming

Streaming with Functions
Example request
curl https://api.openai.com/v1/threads/runs \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -H "OpenAI-Beta: assistants=v2" \
  -d '{
      "assistant_id": "asst_abc123",
      "thread": {
        "messages": [
          {"role": "user", "content": "Explain deep learning to a 5 year old."}
        ]
      }
    }'
Response
{
  "id": "run_abc123",
  "object": "thread.run",
  "created_at": 1699076792,
  "assistant_id": "asst_abc123",
  "thread_id": "thread_abc123",
  "status": "queued",
  "started_at": null,
  "expires_at": 1699077392,
  "cancelled_at": null,
  "failed_at": null,
  "completed_at": null,
  "required_action": null,
  "last_error": null,
  "model": "gpt-4o",
  "instructions": "You are a helpful assistant.",
  "tools": [],
  "tool_resources": {},
  "metadata": {},
  "temperature": 1.0,
  "top_p": 1.0,
  "max_completion_tokens": null,
  "max_prompt_tokens": null,
  "truncation_strategy": {
    "type": "auto",
    "last_messages": null
  },
  "incomplete_details": null,
  "usage": null,
  "response_format": "auto",
  "tool_choice": "auto",
  "parallel_tool_calls": true
}
List runs
Beta
get
 
https://api.openai.com/v1/threads/{thread_id}/runs
Returns a list of runs belonging to a thread.

Path parameters
thread_id
string

Required
The ID of the thread the run belongs to.

Query parameters
limit
integer

Optional
Defaults to 20
A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.

order
string

Optional
Defaults to desc
Sort order by the created_at timestamp of the objects. asc for ascending order and desc for descending order.

after
string

Optional
A cursor for use in pagination. after is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj_foo, your subsequent call can include after=obj_foo in order to fetch the next page of the list.

before
string

Optional
A cursor for use in pagination. before is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, starting with obj_foo, your subsequent call can include before=obj_foo in order to fetch the previous page of the list.

Returns
A list of run objects.

Example request
curl https://api.openai.com/v1/threads/thread_abc123/runs \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -H "OpenAI-Beta: assistants=v2"
Response
{
  "object": "list",
  "data": [
    {
      "id": "run_abc123",
      "object": "thread.run",
      "created_at": 1699075072,
      "assistant_id": "asst_abc123",
      "thread_id": "thread_abc123",
      "status": "completed",
      "started_at": 1699075072,
      "expires_at": null,
      "cancelled_at": null,
      "failed_at": null,
      "completed_at": 1699075073,
      "last_error": null,
      "model": "gpt-4o",
      "instructions": null,
      "incomplete_details": null,
      "tools": [
        {
          "type": "code_interpreter"
        }
      ],
      "tool_resources": {
        "code_interpreter": {
          "file_ids": [
            "file-abc123",
            "file-abc456"
          ]
        }
      },
      "metadata": {},
      "usage": {
        "prompt_tokens": 123,
        "completion_tokens": 456,
        "total_tokens": 579
      },
      "temperature": 1.0,
      "top_p": 1.0,
      "max_prompt_tokens": 1000,
      "max_completion_tokens": 1000,
      "truncation_strategy": {
        "type": "auto",
        "last_messages": null
      },
      "response_format": "auto",
      "tool_choice": "auto",
      "parallel_tool_calls": true
    },
    {
      "id": "run_abc456",
      "object": "thread.run",
      "created_at": 1699063290,
      "assistant_id": "asst_abc123",
      "thread_id": "thread_abc123",
      "status": "completed",
      "started_at": 1699063290,
      "expires_at": null,
      "cancelled_at": null,
      "failed_at": null,
      "completed_at": 1699063291,
      "last_error": null,
      "model": "gpt-4o",
      "instructions": null,
      "incomplete_details": null,
      "tools": [
        {
          "type": "code_interpreter"
        }
      ],
      "tool_resources": {
        "code_interpreter": {
          "file_ids": [
            "file-abc123",
            "file-abc456"
          ]
        }
      },
      "metadata": {},
      "usage": {
        "prompt_tokens": 123,
        "completion_tokens": 456,
        "total_tokens": 579
      },
      "temperature": 1.0,
      "top_p": 1.0,
      "max_prompt_tokens": 1000,
      "max_completion_tokens": 1000,
      "truncation_strategy": {
        "type": "auto",
        "last_messages": null
      },
      "response_format": "auto",
      "tool_choice": "auto",
      "parallel_tool_calls": true
    }
  ],
  "first_id": "run_abc123",
  "last_id": "run_abc456",
  "has_more": false
}
Retrieve run
Beta
get
 
https://api.openai.com/v1/threads/{thread_id}/runs/{run_id}
Retrieves a run.

Path parameters
thread_id
string

Required
The ID of the thread that was run.

run_id
string

Required
The ID of the run to retrieve.

Returns
The run object matching the specified ID.

Example request
curl https://api.openai.com/v1/threads/thread_abc123/runs/run_abc123 \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "OpenAI-Beta: assistants=v2"
Response
{
  "id": "run_abc123",
  "object": "thread.run",
  "created_at": 1699075072,
  "assistant_id": "asst_abc123",
  "thread_id": "thread_abc123",
  "status": "completed",
  "started_at": 1699075072,
  "expires_at": null,
  "cancelled_at": null,
  "failed_at": null,
  "completed_at": 1699075073,
  "last_error": null,
  "model": "gpt-4o",
  "instructions": null,
  "incomplete_details": null,
  "tools": [
    {
      "type": "code_interpreter"
    }
  ],
  "metadata": {},
  "usage": {
    "prompt_tokens": 123,
    "completion_tokens": 456,
    "total_tokens": 579
  },
  "temperature": 1.0,
  "top_p": 1.0,
  "max_prompt_tokens": 1000,
  "max_completion_tokens": 1000,
  "truncation_strategy": {
    "type": "auto",
    "last_messages": null
  },
  "response_format": "auto",
  "tool_choice": "auto",
  "parallel_tool_calls": true
}
Modify run
Beta
post
 
https://api.openai.com/v1/threads/{thread_id}/runs/{run_id}
Modifies a run.

Path parameters
thread_id
string

Required
The ID of the thread that was run.

run_id
string

Required
The ID of the run to modify.

Request body
metadata
map

Optional
Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format, and querying for objects via API or the dashboard.

Keys are strings with a maximum length of 64 characters. Values are strings with a maximum length of 512 characters.

Returns
The modified run object matching the specified ID.

Example request
curl https://api.openai.com/v1/threads/thread_abc123/runs/run_abc123 \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -H "OpenAI-Beta: assistants=v2" \
  -d '{
    "metadata": {
      "user_id": "user_abc123"
    }
  }'
Response
{
  "id": "run_abc123",
  "object": "thread.run",
  "created_at": 1699075072,
  "assistant_id": "asst_abc123",
  "thread_id": "thread_abc123",
  "status": "completed",
  "started_at": 1699075072,
  "expires_at": null,
  "cancelled_at": null,
  "failed_at": null,
  "completed_at": 1699075073,
  "last_error": null,
  "model": "gpt-4o",
  "instructions": null,
  "incomplete_details": null,
  "tools": [
    {
      "type": "code_interpreter"
    }
  ],
  "tool_resources": {
    "code_interpreter": {
      "file_ids": [
        "file-abc123",
        "file-abc456"
      ]
    }
  },
  "metadata": {
    "user_id": "user_abc123"
  },
  "usage": {
    "prompt_tokens": 123,
    "completion_tokens": 456,
    "total_tokens": 579
  },
  "temperature": 1.0,
  "top_p": 1.0,
  "max_prompt_tokens": 1000,
  "max_completion_tokens": 1000,
  "truncation_strategy": {
    "type": "auto",
    "last_messages": null
  },
  "response_format": "auto",
  "tool_choice": "auto",
  "parallel_tool_calls": true
}
Submit tool outputs to run
Beta
post
 
https://api.openai.com/v1/threads/{thread_id}/runs/{run_id}/submit_tool_outputs
When a run has the status: "requires_action" and required_action.type is submit_tool_outputs, this endpoint can be used to submit the outputs from the tool calls once they're all completed. All outputs must be submitted in a single request.

Path parameters
thread_id
string

Required
The ID of the thread to which this run belongs.

run_id
string

Required
The ID of the run that requires the tool output submission.

Request body
tool_outputs
array

Required
A list of tools for which the outputs are being submitted.


Show properties
stream
boolean or null

Optional
If true, returns a stream of events that happen during the Run as server-sent events, terminating when the Run enters a terminal state with a data: [DONE] message.

Returns
The modified run object matching the specified ID.


Default

Streaming
Example request
curl https://api.openai.com/v1/threads/thread_123/runs/run_123/submit_tool_outputs \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -H "OpenAI-Beta: assistants=v2" \
  -d '{
    "tool_outputs": [
      {
        "tool_call_id": "call_001",
        "output": "70 degrees and sunny."
      }
    ]
  }'
Response
{
  "id": "run_123",
  "object": "thread.run",
  "created_at": 1699075592,
  "assistant_id": "asst_123",
  "thread_id": "thread_123",
  "status": "queued",
  "started_at": 1699075592,
  "expires_at": 1699076192,
  "cancelled_at": null,
  "failed_at": null,
  "completed_at": null,
  "last_error": null,
  "model": "gpt-4o",
  "instructions": null,
  "tools": [
    {
      "type": "function",
      "function": {
        "name": "get_current_weather",
        "description": "Get the current weather in a given location",
        "parameters": {
          "type": "object",
          "properties": {
            "location": {
              "type": "string",
              "description": "The city and state, e.g. San Francisco, CA"
            },
            "unit": {
              "type": "string",
              "enum": ["celsius", "fahrenheit"]
            }
          },
          "required": ["location"]
        }
      }
    }
  ],
  "metadata": {},
  "usage": null,
  "temperature": 1.0,
  "top_p": 1.0,
  "max_prompt_tokens": 1000,
  "max_completion_tokens": 1000,
  "truncation_strategy": {
    "type": "auto",
    "last_messages": null
  },
  "response_format": "auto",
  "tool_choice": "auto",
  "parallel_tool_calls": true
}
Cancel a run
Beta
post
 
https://api.openai.com/v1/threads/{thread_id}/runs/{run_id}/cancel
Cancels a run that is in_progress.

Path parameters
thread_id
string

Required
The ID of the thread to which this run belongs.

run_id
string

Required
The ID of the run to cancel.

Returns
The modified run object matching the specified ID.

Example request
curl https://api.openai.com/v1/threads/thread_abc123/runs/run_abc123/cancel \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "OpenAI-Beta: assistants=v2" \
  -X POST
Response
{
  "id": "run_abc123",
  "object": "thread.run",
  "created_at": 1699076126,
  "assistant_id": "asst_abc123",
  "thread_id": "thread_abc123",
  "status": "cancelling",
  "started_at": 1699076126,
  "expires_at": 1699076726,
  "cancelled_at": null,
  "failed_at": null,
  "completed_at": null,
  "last_error": null,
  "model": "gpt-4o",
  "instructions": "You summarize books.",
  "tools": [
    {
      "type": "file_search"
    }
  ],
  "tool_resources": {
    "file_search": {
      "vector_store_ids": ["vs_123"]
    }
  },
  "metadata": {},
  "usage": null,
  "temperature": 1.0,
  "top_p": 1.0,
  "response_format": "auto",
  "tool_choice": "auto",
  "parallel_tool_calls": true
}
The run object
Beta
Represents an execution run on a thread.

id
string

The identifier, which can be referenced in API endpoints.

object
string

The object type, which is always thread.run.

created_at
integer

The Unix timestamp (in seconds) for when the run was created.

thread_id
string

The ID of the thread that was executed on as a part of this run.

assistant_id
string

The ID of the assistant used for execution of this run.

status
string

The status of the run, which can be either queued, in_progress, requires_action, cancelling, cancelled, failed, completed, incomplete, or expired.

required_action
object or null

Details on the action required to continue the run. Will be null if no action is required.


Show properties
last_error
object or null

The last error associated with this run. Will be null if there are no errors.


Show properties
expires_at
integer or null

The Unix timestamp (in seconds) for when the run will expire.

started_at
integer or null

The Unix timestamp (in seconds) for when the run was started.

cancelled_at
integer or null

The Unix timestamp (in seconds) for when the run was cancelled.

failed_at
integer or null

The Unix timestamp (in seconds) for when the run failed.

completed_at
integer or null

The Unix timestamp (in seconds) for when the run was completed.

incomplete_details
object or null

Details on why the run is incomplete. Will be null if the run is not incomplete.


Show properties
model
string

The model that the assistant used for this run.

instructions
string

The instructions that the assistant used for this run.

tools
array

The list of tools that the assistant used for this run.


Show possible types
metadata
map

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format, and querying for objects via API or the dashboard.

Keys are strings with a maximum length of 64 characters. Values are strings with a maximum length of 512 characters.

usage
object or null

Usage statistics related to the run. This value will be null if the run is not in a terminal state (i.e. in_progress, queued, etc.).


Show properties
temperature
number or null

The sampling temperature used for this run. If not set, defaults to 1.

top_p
number or null

The nucleus sampling value used for this run. If not set, defaults to 1.

max_prompt_tokens
integer or null

The maximum number of prompt tokens specified to have been used over the course of the run.

max_completion_tokens
integer or null

The maximum number of completion tokens specified to have been used over the course of the run.

truncation_strategy
object

Controls for how a thread will be truncated prior to the run. Use this to control the intial context window of the run.


Show properties
tool_choice
string or object

Controls which (if any) tool is called by the model. none means the model will not call any tools and instead generates a message. auto is the default value and means the model can pick between generating a message or calling one or more tools. required means the model must call one or more tools before responding to the user. Specifying a particular tool like {"type": "file_search"} or {"type": "function", "function": {"name": "my_function"}} forces the model to call that tool.


Show possible types
parallel_tool_calls
boolean

Whether to enable parallel function calling during tool use.

response_format
"auto" or object

Specifies the format that the model must output. Compatible with GPT-4o, GPT-4 Turbo, and all GPT-3.5 Turbo models since gpt-3.5-turbo-1106.

Setting to { "type": "json_schema", "json_schema": {...} } enables Structured Outputs which ensures the model will match your supplied JSON schema. Learn more in the Structured Outputs guide.

Setting to { "type": "json_object" } enables JSON mode, which ensures the message the model generates is valid JSON.

Important: when using JSON mode, you must also instruct the model to produce JSON yourself via a system or user message. Without this, the model may generate an unending stream of whitespace until the generation reaches the token limit, resulting in a long-running and seemingly "stuck" request. Also note that the message content may be partially cut off if finish_reason="length", which indicates the generation exceeded max_tokens or the conversation exceeded the max context length.


Show possible types
OBJECT The run object
{
  "id": "run_abc123",
  "object": "thread.run",
  "created_at": 1698107661,
  "assistant_id": "asst_abc123",
  "thread_id": "thread_abc123",
  "status": "completed",
  "started_at": 1699073476,
  "expires_at": null,
  "cancelled_at": null,
  "failed_at": null,
  "completed_at": 1699073498,
  "last_error": null,
  "model": "gpt-4o",
  "instructions": null,
  "tools": [{"type": "file_search"}, {"type": "code_interpreter"}],
  "metadata": {},
  "incomplete_details": null,
  "usage": {
    "prompt_tokens": 123,
    "completion_tokens": 456,
    "total_tokens": 579
  },
  "temperature": 1.0,
  "top_p": 1.0,
  "max_prompt_tokens": 1000,
  "max_completion_tokens": 1000,
  "truncation_strategy": {
    "type": "auto",
    "last_messages": null
  },
  "response_format": "auto",
  "tool_choice": "auto",
  "parallel_tool_calls": true
}
Run steps
Beta
Represents the steps (model and tool calls) taken during the run.

Related guide: Assistants

List run steps
Beta
get
 
https://api.openai.com/v1/threads/{thread_id}/runs/{run_id}/steps
Returns a list of run steps belonging to a run.

Path parameters
thread_id
string

Required
The ID of the thread the run and run steps belong to.

run_id
string

Required
The ID of the run the run steps belong to.

Query parameters
limit
integer

Optional
Defaults to 20
A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.

order
string

Optional
Defaults to desc
Sort order by the created_at timestamp of the objects. asc for ascending order and desc for descending order.

after
string

Optional
A cursor for use in pagination. after is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj_foo, your subsequent call can include after=obj_foo in order to fetch the next page of the list.

before
string

Optional
A cursor for use in pagination. before is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, starting with obj_foo, your subsequent call can include before=obj_foo in order to fetch the previous page of the list.

include[]
array

Optional
A list of additional fields to include in the response. Currently the only supported value is step_details.tool_calls[*].file_search.results[*].content to fetch the file search result content.

See the file search tool documentation for more information.

Returns
A list of run step objects.

Example request
curl https://api.openai.com/v1/threads/thread_abc123/runs/run_abc123/steps \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -H "OpenAI-Beta: assistants=v2"
Response
{
  "object": "list",
  "data": [
    {
      "id": "step_abc123",
      "object": "thread.run.step",
      "created_at": 1699063291,
      "run_id": "run_abc123",
      "assistant_id": "asst_abc123",
      "thread_id": "thread_abc123",
      "type": "message_creation",
      "status": "completed",
      "cancelled_at": null,
      "completed_at": 1699063291,
      "expired_at": null,
      "failed_at": null,
      "last_error": null,
      "step_details": {
        "type": "message_creation",
        "message_creation": {
          "message_id": "msg_abc123"
        }
      },
      "usage": {
        "prompt_tokens": 123,
        "completion_tokens": 456,
        "total_tokens": 579
      }
    }
  ],
  "first_id": "step_abc123",
  "last_id": "step_abc456",
  "has_more": false
}
Retrieve run step
Beta
get
 
https://api.openai.com/v1/threads/{thread_id}/runs/{run_id}/steps/{step_id}
Retrieves a run step.

Path parameters
thread_id
string

Required
The ID of the thread to which the run and run step belongs.

run_id
string

Required
The ID of the run to which the run step belongs.

step_id
string

Required
The ID of the run step to retrieve.

Query parameters
include[]
array

Optional
A list of additional fields to include in the response. Currently the only supported value is step_details.tool_calls[*].file_search.results[*].content to fetch the file search result content.

See the file search tool documentation for more information.

Returns
The run step object matching the specified ID.

Example request
curl https://api.openai.com/v1/threads/thread_abc123/runs/run_abc123/steps/step_abc123 \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -H "OpenAI-Beta: assistants=v2"
Response
{
  "id": "step_abc123",
  "object": "thread.run.step",
  "created_at": 1699063291,
  "run_id": "run_abc123",
  "assistant_id": "asst_abc123",
  "thread_id": "thread_abc123",
  "type": "message_creation",
  "status": "completed",
  "cancelled_at": null,
  "completed_at": 1699063291,
  "expired_at": null,
  "failed_at": null,
  "last_error": null,
  "step_details": {
    "type": "message_creation",
    "message_creation": {
      "message_id": "msg_abc123"
    }
  },
  "usage": {
    "prompt_tokens": 123,
    "completion_tokens": 456,
    "total_tokens": 579
  }
}
The run step object
Beta
Represents a step in execution of a run.

id
string

The identifier of the run step, which can be referenced in API endpoints.

object
string

The object type, which is always thread.run.step.

created_at
integer

The Unix timestamp (in seconds) for when the run step was created.

assistant_id
string

The ID of the assistant associated with the run step.

thread_id
string

The ID of the thread that was run.

run_id
string

The ID of the run that this run step is a part of.

type
string

The type of run step, which can be either message_creation or tool_calls.

status
string

The status of the run step, which can be either in_progress, cancelled, failed, completed, or expired.

step_details
object

The details of the run step.


Show possible types
last_error
object or null

The last error associated with this run step. Will be null if there are no errors.


Show properties
expired_at
integer or null

The Unix timestamp (in seconds) for when the run step expired. A step is considered expired if the parent run is expired.

cancelled_at
integer or null

The Unix timestamp (in seconds) for when the run step was cancelled.

failed_at
integer or null

The Unix timestamp (in seconds) for when the run step failed.

completed_at
integer or null

The Unix timestamp (in seconds) for when the run step completed.

metadata
map

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format, and querying for objects via API or the dashboard.

Keys are strings with a maximum length of 64 characters. Values are strings with a maximum length of 512 characters.

usage
object or null

Usage statistics related to the run step. This value will be null while the run step's status is in_progress.


Show properties
OBJECT The run step object
{
  "id": "step_abc123",
  "object": "thread.run.step",
  "created_at": 1699063291,
  "run_id": "run_abc123",
  "assistant_id": "asst_abc123",
  "thread_id": "thread_abc123",
  "type": "message_creation",
  "status": "completed",
  "cancelled_at": null,
  "completed_at": 1699063291,
  "expired_at": null,
  "failed_at": null,
  "last_error": null,
  "step_details": {
    "type": "message_creation",
    "message_creation": {
      "message_id": "msg_abc123"
    }
  },
  "usage": {
    "prompt_tokens": 123,
    "completion_tokens": 456,
    "total_tokens": 579
  }
}
Vector stores
Beta
Vector stores are used to store files for use by the file_search tool.

Related guide: File Search

Create vector store
Beta
post
 
https://api.openai.com/v1/vector_stores
Create a vector store.

Request body
file_ids
array

Optional
A list of File IDs that the vector store should use. Useful for tools like file_search that can access files.

name
string

Optional
The name of the vector store.

expires_after
object

Optional
The expiration policy for a vector store.


Show properties
chunking_strategy
object

Optional
The chunking strategy used to chunk the file(s). If not set, will use the auto strategy. Only applicable if file_ids is non-empty.


Show possible types
metadata
map

Optional
Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format, and querying for objects via API or the dashboard.

Keys are strings with a maximum length of 64 characters. Values are strings with a maximum length of 512 characters.

Returns
A vector store object.

Example request
curl https://api.openai.com/v1/vector_stores \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -H "OpenAI-Beta: assistants=v2" \
  -d '{
    "name": "Support FAQ"
  }'
Response
{
  "id": "vs_abc123",
  "object": "vector_store",
  "created_at": 1699061776,
  "name": "Support FAQ",
  "bytes": 139920,
  "file_counts": {
    "in_progress": 0,
    "completed": 3,
    "failed": 0,
    "cancelled": 0,
    "total": 3
  }
}
List vector stores
Beta
get
 
https://api.openai.com/v1/vector_stores
Returns a list of vector stores.

Query parameters
limit
integer

Optional
Defaults to 20
A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.

order
string

Optional
Defaults to desc
Sort order by the created_at timestamp of the objects. asc for ascending order and desc for descending order.

after
string

Optional
A cursor for use in pagination. after is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj_foo, your subsequent call can include after=obj_foo in order to fetch the next page of the list.

before
string

Optional
A cursor for use in pagination. before is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, starting with obj_foo, your subsequent call can include before=obj_foo in order to fetch the previous page of the list.

Returns
A list of vector store objects.

Example request
curl https://api.openai.com/v1/vector_stores \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -H "OpenAI-Beta: assistants=v2"
Response
{
  "object": "list",
  "data": [
    {
      "id": "vs_abc123",
      "object": "vector_store",
      "created_at": 1699061776,
      "name": "Support FAQ",
      "bytes": 139920,
      "file_counts": {
        "in_progress": 0,
        "completed": 3,
        "failed": 0,
        "cancelled": 0,
        "total": 3
      }
    },
    {
      "id": "vs_abc456",
      "object": "vector_store",
      "created_at": 1699061776,
      "name": "Support FAQ v2",
      "bytes": 139920,
      "file_counts": {
        "in_progress": 0,
        "completed": 3,
        "failed": 0,
        "cancelled": 0,
        "total": 3
      }
    }
  ],
  "first_id": "vs_abc123",
  "last_id": "vs_abc456",
  "has_more": false
}
Retrieve vector store
Beta
get
 
https://api.openai.com/v1/vector_stores/{vector_store_id}
Retrieves a vector store.

Path parameters
vector_store_id
string

Required
The ID of the vector store to retrieve.

Returns
The vector store object matching the specified ID.

Example request
curl https://api.openai.com/v1/vector_stores/vs_abc123 \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -H "OpenAI-Beta: assistants=v2"
Response
{
  "id": "vs_abc123",
  "object": "vector_store",
  "created_at": 1699061776
}
Modify vector store
Beta
post
 
https://api.openai.com/v1/vector_stores/{vector_store_id}
Modifies a vector store.

Path parameters
vector_store_id
string

Required
The ID of the vector store to modify.

Request body
name
string or null

Optional
The name of the vector store.

expires_after
object

Optional
The expiration policy for a vector store.


Show properties
metadata
map

Optional
Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format, and querying for objects via API or the dashboard.

Keys are strings with a maximum length of 64 characters. Values are strings with a maximum length of 512 characters.

Returns
The modified vector store object.

Example request
curl https://api.openai.com/v1/vector_stores/vs_abc123 \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -H "OpenAI-Beta: assistants=v2"
  -d '{
    "name": "Support FAQ"
  }'
Response
{
  "id": "vs_abc123",
  "object": "vector_store",
  "created_at": 1699061776,
  "name": "Support FAQ",
  "bytes": 139920,
  "file_counts": {
    "in_progress": 0,
    "completed": 3,
    "failed": 0,
    "cancelled": 0,
    "total": 3
  }
}
Delete vector store
Beta
delete
 
https://api.openai.com/v1/vector_stores/{vector_store_id}
Delete a vector store.

Path parameters
vector_store_id
string

Required
The ID of the vector store to delete.

Returns
Deletion status

Example request
curl https://api.openai.com/v1/vector_stores/vs_abc123 \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -H "OpenAI-Beta: assistants=v2" \
  -X DELETE
Response
{
  id: "vs_abc123",
  object: "vector_store.deleted",
  deleted: true
}
The vector store object
Beta
A vector store is a collection of processed files can be used by the file_search tool.

id
string

The identifier, which can be referenced in API endpoints.

object
string

The object type, which is always vector_store.

created_at
integer

The Unix timestamp (in seconds) for when the vector store was created.

name
string

The name of the vector store.

usage_bytes
integer

The total number of bytes used by the files in the vector store.

file_counts
object


Show properties
status
string

The status of the vector store, which can be either expired, in_progress, or completed. A status of completed indicates that the vector store is ready for use.

expires_after
object

The expiration policy for a vector store.


Show properties
expires_at
integer or null

The Unix timestamp (in seconds) for when the vector store will expire.

last_active_at
integer or null

The Unix timestamp (in seconds) for when the vector store was last active.

metadata
map

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format, and querying for objects via API or the dashboard.

Keys are strings with a maximum length of 64 characters. Values are strings with a maximum length of 512 characters.

OBJECT The vector store object
{
  "id": "vs_123",
  "object": "vector_store",
  "created_at": 1698107661,
  "usage_bytes": 123456,
  "last_active_at": 1698107661,
  "name": "my_vector_store",
  "status": "completed",
  "file_counts": {
    "in_progress": 0,
    "completed": 100,
    "cancelled": 0,
    "failed": 0,
    "total": 100
  },
  "metadata": {},
  "last_used_at": 1698107661
}
Vector store files
Beta
Vector store files represent files inside a vector store.

Related guide: File Search

Create vector store file
Beta
post
 
https://api.openai.com/v1/vector_stores/{vector_store_id}/files
Create a vector store file by attaching a File to a vector store.

Path parameters
vector_store_id
string

Required
The ID of the vector store for which to create a File.

Request body
file_id
string

Required
A File ID that the vector store should use. Useful for tools like file_search that can access files.

chunking_strategy
object

Optional
The chunking strategy used to chunk the file(s). If not set, will use the auto strategy.


Show possible types
Returns
A vector store file object.

Example request
curl https://api.openai.com/v1/vector_stores/vs_abc123/files \
    -H "Authorization: Bearer $OPENAI_API_KEY" \
    -H "Content-Type: application/json" \
    -H "OpenAI-Beta: assistants=v2" \
    -d '{
      "file_id": "file-abc123"
    }'
Response
{
  "id": "file-abc123",
  "object": "vector_store.file",
  "created_at": 1699061776,
  "usage_bytes": 1234,
  "vector_store_id": "vs_abcd",
  "status": "completed",
  "last_error": null
}
List vector store files
Beta
get
 
https://api.openai.com/v1/vector_stores/{vector_store_id}/files
Returns a list of vector store files.

Path parameters
vector_store_id
string

Required
The ID of the vector store that the files belong to.

Query parameters
limit
integer

Optional
Defaults to 20
A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.

order
string

Optional
Defaults to desc
Sort order by the created_at timestamp of the objects. asc for ascending order and desc for descending order.

after
string

Optional
A cursor for use in pagination. after is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj_foo, your subsequent call can include after=obj_foo in order to fetch the next page of the list.

before
string

Optional
A cursor for use in pagination. before is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, starting with obj_foo, your subsequent call can include before=obj_foo in order to fetch the previous page of the list.

filter
string

Optional
Filter by file status. One of in_progress, completed, failed, cancelled.

Returns
A list of vector store file objects.

Example request
curl https://api.openai.com/v1/vector_stores/vs_abc123/files \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -H "OpenAI-Beta: assistants=v2"
Response
{
  "object": "list",
  "data": [
    {
      "id": "file-abc123",
      "object": "vector_store.file",
      "created_at": 1699061776,
      "vector_store_id": "vs_abc123"
    },
    {
      "id": "file-abc456",
      "object": "vector_store.file",
      "created_at": 1699061776,
      "vector_store_id": "vs_abc123"
    }
  ],
  "first_id": "file-abc123",
  "last_id": "file-abc456",
  "has_more": false
}
Retrieve vector store file
Beta
get
 
https://api.openai.com/v1/vector_stores/{vector_store_id}/files/{file_id}
Retrieves a vector store file.

Path parameters
vector_store_id
string

Required
The ID of the vector store that the file belongs to.

file_id
string

Required
The ID of the file being retrieved.

Returns
The vector store file object.

Example request
curl https://api.openai.com/v1/vector_stores/vs_abc123/files/file-abc123 \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -H "OpenAI-Beta: assistants=v2"
Response
{
  "id": "file-abc123",
  "object": "vector_store.file",
  "created_at": 1699061776,
  "vector_store_id": "vs_abcd",
  "status": "completed",
  "last_error": null
}
Delete vector store file
Beta
delete
 
https://api.openai.com/v1/vector_stores/{vector_store_id}/files/{file_id}
Delete a vector store file. This will remove the file from the vector store but the file itself will not be deleted. To delete the file, use the delete file endpoint.

Path parameters
vector_store_id
string

Required
The ID of the vector store that the file belongs to.

file_id
string

Required
The ID of the file to delete.

Returns
Deletion status

Example request
curl https://api.openai.com/v1/vector_stores/vs_abc123/files/file-abc123 \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -H "OpenAI-Beta: assistants=v2" \
  -X DELETE
Response
{
  id: "file-abc123",
  object: "vector_store.file.deleted",
  deleted: true
}
The vector store file object
Beta
A list of files attached to a vector store.

id
string

The identifier, which can be referenced in API endpoints.

object
string

The object type, which is always vector_store.file.

usage_bytes
integer

The total vector store usage in bytes. Note that this may be different from the original file size.

created_at
integer

The Unix timestamp (in seconds) for when the vector store file was created.

vector_store_id
string

The ID of the vector store that the File is attached to.

status
string

The status of the vector store file, which can be either in_progress, completed, cancelled, or failed. The status completed indicates that the vector store file is ready for use.

last_error
object or null

The last error associated with this vector store file. Will be null if there are no errors.


Show properties
chunking_strategy
object

The strategy used to chunk the file.


Show possible types
OBJECT The vector store file object
{
  "id": "file-abc123",
  "object": "vector_store.file",
  "usage_bytes": 1234,
  "created_at": 1698107661,
  "vector_store_id": "vs_abc123",
  "status": "completed",
  "last_error": null,
  "chunking_strategy": {
    "type": "static",
    "static": {
      "max_chunk_size_tokens": 800,
      "chunk_overlap_tokens": 400
    }
  }
}
Vector store file batches
Beta
Vector store file batches represent operations to add multiple files to a vector store. Related guide: File Search

Create vector store file batch
Beta
post
 
https://api.openai.com/v1/vector_stores/{vector_store_id}/file_batches
Create a vector store file batch.

Path parameters
vector_store_id
string

Required
The ID of the vector store for which to create a File Batch.

Request body
file_ids
array

Required
A list of File IDs that the vector store should use. Useful for tools like file_search that can access files.

chunking_strategy
object

Optional
The chunking strategy used to chunk the file(s). If not set, will use the auto strategy.


Show possible types
Returns
A vector store file batch object.

Example request
curl https://api.openai.com/v1/vector_stores/vs_abc123/file_batches \
    -H "Authorization: Bearer $OPENAI_API_KEY" \
    -H "Content-Type: application/json \
    -H "OpenAI-Beta: assistants=v2" \
    -d '{
      "file_ids": ["file-abc123", "file-abc456"]
    }'
Response
{
  "id": "vsfb_abc123",
  "object": "vector_store.file_batch",
  "created_at": 1699061776,
  "vector_store_id": "vs_abc123",
  "status": "in_progress",
  "file_counts": {
    "in_progress": 1,
    "completed": 1,
    "failed": 0,
    "cancelled": 0,
    "total": 0,
  }
}
Retrieve vector store file batch
Beta
get
 
https://api.openai.com/v1/vector_stores/{vector_store_id}/file_batches/{batch_id}
Retrieves a vector store file batch.

Path parameters
vector_store_id
string

Required
The ID of the vector store that the file batch belongs to.

batch_id
string

Required
The ID of the file batch being retrieved.

Returns
The vector store file batch object.

Example request
curl https://api.openai.com/v1/vector_stores/vs_abc123/files_batches/vsfb_abc123 \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -H "OpenAI-Beta: assistants=v2"
Response
{
  "id": "vsfb_abc123",
  "object": "vector_store.file_batch",
  "created_at": 1699061776,
  "vector_store_id": "vs_abc123",
  "status": "in_progress",
  "file_counts": {
    "in_progress": 1,
    "completed": 1,
    "failed": 0,
    "cancelled": 0,
    "total": 0,
  }
}
Cancel vector store file batch
Beta
post
 
https://api.openai.com/v1/vector_stores/{vector_store_id}/file_batches/{batch_id}/cancel
Cancel a vector store file batch. This attempts to cancel the processing of files in this batch as soon as possible.

Path parameters
vector_store_id
string

Required
The ID of the vector store that the file batch belongs to.

batch_id
string

Required
The ID of the file batch to cancel.

Returns
The modified vector store file batch object.

Example request
curl https://api.openai.com/v1/vector_stores/vs_abc123/files_batches/vsfb_abc123/cancel \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -H "OpenAI-Beta: assistants=v2" \
  -X POST
Response
{
  "id": "vsfb_abc123",
  "object": "vector_store.file_batch",
  "created_at": 1699061776,
  "vector_store_id": "vs_abc123",
  "status": "in_progress",
  "file_counts": {
    "in_progress": 12,
    "completed": 3,
    "failed": 0,
    "cancelled": 0,
    "total": 15,
  }
}
List vector store files in a batch
Beta
get
 
https://api.openai.com/v1/vector_stores/{vector_store_id}/file_batches/{batch_id}/files
Returns a list of vector store files in a batch.

Path parameters
vector_store_id
string

Required
The ID of the vector store that the files belong to.

batch_id
string

Required
The ID of the file batch that the files belong to.

Query parameters
limit
integer

Optional
Defaults to 20
A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.

order
string

Optional
Defaults to desc
Sort order by the created_at timestamp of the objects. asc for ascending order and desc for descending order.

after
string

Optional
A cursor for use in pagination. after is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj_foo, your subsequent call can include after=obj_foo in order to fetch the next page of the list.

before
string

Optional
A cursor for use in pagination. before is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, starting with obj_foo, your subsequent call can include before=obj_foo in order to fetch the previous page of the list.

filter
string

Optional
Filter by file status. One of in_progress, completed, failed, cancelled.

Returns
A list of vector store file objects.

Example request
curl https://api.openai.com/v1/vector_stores/vs_abc123/files_batches/vsfb_abc123/files \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -H "OpenAI-Beta: assistants=v2"
Response
{
  "object": "list",
  "data": [
    {
      "id": "file-abc123",
      "object": "vector_store.file",
      "created_at": 1699061776,
      "vector_store_id": "vs_abc123"
    },
    {
      "id": "file-abc456",
      "object": "vector_store.file",
      "created_at": 1699061776,
      "vector_store_id": "vs_abc123"
    }
  ],
  "first_id": "file-abc123",
  "last_id": "file-abc456",
  "has_more": false
}
The vector store files batch object
Beta
A batch of files attached to a vector store.

id
string

The identifier, which can be referenced in API endpoints.

object
string

The object type, which is always vector_store.file_batch.

created_at
integer

The Unix timestamp (in seconds) for when the vector store files batch was created.

vector_store_id
string

The ID of the vector store that the File is attached to.

status
string

The status of the vector store files batch, which can be either in_progress, completed, cancelled or failed.

file_counts
object


Show properties
OBJECT The vector store files batch object
{
  "id": "vsfb_123",
  "object": "vector_store.files_batch",
  "created_at": 1698107661,
  "vector_store_id": "vs_abc123",
  "status": "completed",
  "file_counts": {
    "in_progress": 0,
    "completed": 100,
    "failed": 0,
    "cancelled": 0,
    "total": 100
  }
}
Streaming
Beta
Stream the result of executing a Run or resuming a Run after submitting tool outputs. You can stream events from the Create Thread and Run, Create Run, and Submit Tool Outputs endpoints by passing "stream": true. The response will be a Server-Sent events stream. Our Node and Python SDKs provide helpful utilities to make streaming easy. Reference the Assistants API quickstart to learn more.

The message delta object
Beta
Represents a message delta i.e. any changed fields on a message during streaming.

id
string

The identifier of the message, which can be referenced in API endpoints.

object
string

The object type, which is always thread.message.delta.

delta
object

The delta containing the fields that have changed on the Message.


Show properties
OBJECT The message delta object
{
  "id": "msg_123",
  "object": "thread.message.delta",
  "delta": {
    "content": [
      {
        "index": 0,
        "type": "text",
        "text": { "value": "Hello", "annotations": [] }
      }
    ]
  }
}
The run step delta object
Beta
Represents a run step delta i.e. any changed fields on a run step during streaming.

id
string

The identifier of the run step, which can be referenced in API endpoints.

object
string

The object type, which is always thread.run.step.delta.

delta
object

The delta containing the fields that have changed on the run step.


Show properties
OBJECT The run step delta object
{
  "id": "step_123",
  "object": "thread.run.step.delta",
  "delta": {
    "step_details": {
      "type": "tool_calls",
      "tool_calls": [
        {
          "index": 0,
          "id": "call_123",
          "type": "code_interpreter",
          "code_interpreter": { "input": "", "outputs": [] }
        }
      ]
    }
  }
}
Assistant stream events
Beta
Represents an event emitted when streaming a Run.

Each event in a server-sent events stream has an event and data property:

event: thread.created
data: {"id": "thread_123", "object": "thread", ...}
We emit events whenever a new object is created, transitions to a new state, or is being streamed in parts (deltas). For example, we emit thread.run.created when a new run is created, thread.run.completed when a run completes, and so on. When an Assistant chooses to create a message during a run, we emit a thread.message.created event, a thread.message.in_progress event, many thread.message.delta events, and finally a thread.message.completed event.

We may add additional events over time, so we recommend handling unknown events gracefully in your code. See the Assistants API quickstart to learn how to integrate the Assistants API with streaming.

thread.created
data is a thread

Occurs when a new thread is created.

thread.run.created
data is a run

Occurs when a new run is created.

thread.run.queued
data is a run

Occurs when a run moves to a queued status.

thread.run.in_progress
data is a run

Occurs when a run moves to an in_progress status.

thread.run.requires_action
data is a run

Occurs when a run moves to a requires_action status.

thread.run.completed
data is a run

Occurs when a run is completed.

thread.run.incomplete
data is a run

Occurs when a run ends with status incomplete.

thread.run.failed
data is a run

Occurs when a run fails.

thread.run.cancelling
data is a run

Occurs when a run moves to a cancelling status.

thread.run.cancelled
data is a run

Occurs when a run is cancelled.

thread.run.expired
data is a run

Occurs when a run expires.

thread.run.step.created
data is a run step

Occurs when a run step is created.

thread.run.step.in_progress
data is a run step

Occurs when a run step moves to an in_progress state.

thread.run.step.delta
data is a run step delta

Occurs when parts of a run step are being streamed.

thread.run.step.completed
data is a run step

Occurs when a run step is completed.

thread.run.step.failed
data is a run step

Occurs when a run step fails.

thread.run.step.cancelled
data is a run step

Occurs when a run step is cancelled.

thread.run.step.expired
data is a run step

Occurs when a run step expires.

thread.message.created
data is a message

Occurs when a message is created.

thread.message.in_progress
data is a message

Occurs when a message moves to an in_progress state.

thread.message.delta
data is a message delta

Occurs when parts of a Message are being streamed.

thread.message.completed
data is a message

Occurs when a message is completed.

thread.message.incomplete
data is a message

Occurs when a message ends before it is completed.

error
data is an error

Occurs when an error occurs. This can happen due to an internal server error or a timeout.

done
data is [DONE]

Occurs when a stream ends.

Administration
Programmatically manage your organization. The Audit Logs endpoint provides a log of all actions taken in the organization for security and monitoring purposes. To access these endpoints please generate an Admin API Key through the API Platform Organization overview. Admin API keys cannot be used for non-administration endpoints. For best practices on setting up your organization, please refer to this guide

Admin API Keys
The Usage API provides detailed insights into your activity across the OpenAI API. It also includes a separate Costs endpoint, which offers visibility into your spend, breaking down consumption by invoice line items and project IDs. While the Usage API delivers granular usage data, it may not always reconcile perfectly with the Costs due to minor differences in how usage and spend are recorded. For financial purposes, we recommend using the Costs endpoint or the Costs tab in the Usage Dashboard, which will reconcile back to your billing invoice.

List admin API keys
get
 
https://api.openai.com/v1/organization/admin_api_keys
List organization API keys

Query parameters
after
string or null

Optional
order
string

Optional
Defaults to asc
limit
integer

Optional
Defaults to 20
Returns
A list of admin API key objects.

Example request
curl https://api.openai.com/v1/organization/admin_api_keys?after=key_abc&limit=20 \
  -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
  -H "Content-Type: application/json"
Response
{
  "object": "list",
  "data": [
    {
      "object": "organization.admin_api_key",
      "id": "key_abc",
      "name": "Main Admin Key",
      "redacted_value": "sk-admin...def",
      "created_at": 1711471533,
      "owner": {
        "type": "service_account",
        "object": "organization.service_account",
        "id": "sa_456",
        "name": "My Service Account",
        "created_at": 1711471533,
        "role": "member"
      }
    }
  ],
  "first_id": "key_abc",
  "last_id": "key_abc",
  "has_more": false
}
Create admin API key
post
 
https://api.openai.com/v1/organization/admin_api_keys
Create an organization admin API key

Request body
name
string

Required
Returns
The created admin API key object.

Example request
curl -X POST https://api.openai.com/v1/organization/admin_api_keys \
  -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
  -H "Content-Type: application/json" \
  -d '{
      "name": "New Admin Key"
  }'
Response
{
  "object": "organization.admin_api_key",
  "id": "key_xyz",
  "name": "New Admin Key",
  "redacted_value": "sk-admin...xyz",
  "created_at": 1711471533,
  "owner": {
    "type": "user",
    "object": "organization.user",
    "id": "user_123",
    "name": "John Doe",
    "created_at": 1711471533,
    "role": "owner"
  },
  "value": "sk-admin-1234abcd"
}
Retrieve admin API key
get
 
https://api.openai.com/v1/organization/admin_api_keys/{key_id}
Retrieve a single organization API key

Path parameters
key_id
string

Required
Returns
The requested admin API key object.

Example request
curl https://api.openai.com/v1/organization/admin_api_keys/key_abc \
  -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
  -H "Content-Type: application/json"
Response
{
  "object": "organization.admin_api_key",
  "id": "key_abc",
  "name": "Main Admin Key",
  "redacted_value": "sk-admin...xyz",
  "created_at": 1711471533,
  "owner": {
    "type": "user",
    "object": "organization.user",
    "id": "user_123",
    "name": "John Doe",
    "created_at": 1711471533,
    "role": "owner"
  }
}
Delete admin API key
delete
 
https://api.openai.com/v1/organization/admin_api_keys/{key_id}
Delete an organization admin API key

Path parameters
key_id
string

Required
Returns
A confirmation object indicating the key was deleted.

Example request
curl -X DELETE https://api.openai.com/v1/organization/admin_api_keys/key_abc \
  -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
  -H "Content-Type: application/json"
Response
{
  "id": "key_abc",
  "object": "organization.admin_api_key.deleted",
  "deleted": true
}
Invites
Invite and manage invitations for an organization.

List invites
get
 
https://api.openai.com/v1/organization/invites
Returns a list of invites in the organization.

Query parameters
limit
integer

Optional
Defaults to 20
A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.

after
string

Optional
A cursor for use in pagination. after is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj_foo, your subsequent call can include after=obj_foo in order to fetch the next page of the list.

Returns
A list of Invite objects.

Example request
curl https://api.openai.com/v1/organization/invites?after=invite-abc&limit=20 \
  -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
  -H "Content-Type: application/json"
Response
{
  "object": "list",
  "data": [
    {
      "object": "organization.invite",
      "id": "invite-abc",
      "email": "user@example.com",
      "role": "owner",
      "status": "accepted",
      "invited_at": 1711471533,
      "expires_at": 1711471533,
      "accepted_at": 1711471533
    }
  ],
  "first_id": "invite-abc",
  "last_id": "invite-abc",
  "has_more": false
}
Create invite
post
 
https://api.openai.com/v1/organization/invites
Create an invite for a user to the organization. The invite must be accepted by the user before they have access to the organization.

Request body
email
string

Required
Send an email to this address

role
string

Required
owner or reader

projects
array

Optional
An array of projects to which membership is granted at the same time the org invite is accepted. If omitted, the user will be invited to the default project for compatibility with legacy behavior.


Show properties
Returns
The created Invite object.

Example request
curl -X POST https://api.openai.com/v1/organization/invites \
  -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
  -H "Content-Type: application/json" \
  -d '{
      "email": "anotheruser@example.com",
      "role": "reader",
      "projects": [
        {
          "id": "project-xyz",
          "role": "member"
        },
        {
          "id": "project-abc",
          "role": "owner"
        }
      ]
  }'
Response
{
  "object": "organization.invite",
  "id": "invite-def",
  "email": "anotheruser@example.com",
  "role": "reader",
  "status": "pending",
  "invited_at": 1711471533,
  "expires_at": 1711471533,
  "accepted_at": null,
  "projects": [
    {
      "id": "project-xyz",
      "role": "member"
    },
    {
      "id": "project-abc",
      "role": "owner"
    }
  ]
}
Retrieve invite
get
 
https://api.openai.com/v1/organization/invites/{invite_id}
Retrieves an invite.

Path parameters
invite_id
string

Required
The ID of the invite to retrieve.

Returns
The Invite object matching the specified ID.

Example request
curl https://api.openai.com/v1/organization/invites/invite-abc \
  -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
  -H "Content-Type: application/json"
Response
{
    "object": "organization.invite",
    "id": "invite-abc",
    "email": "user@example.com",
    "role": "owner",
    "status": "accepted",
    "invited_at": 1711471533,
    "expires_at": 1711471533,
    "accepted_at": 1711471533
}
Delete invite
delete
 
https://api.openai.com/v1/organization/invites/{invite_id}
Delete an invite. If the invite has already been accepted, it cannot be deleted.

Path parameters
invite_id
string

Required
The ID of the invite to delete.

Returns
Confirmation that the invite has been deleted

Example request
curl -X DELETE https://api.openai.com/v1/organization/invites/invite-abc \
  -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
  -H "Content-Type: application/json"
Response
{
    "object": "organization.invite.deleted",
    "id": "invite-abc",
    "deleted": true
}
The invite object
Represents an individual invite to the organization.

object
string

The object type, which is always organization.invite

id
string

The identifier, which can be referenced in API endpoints

email
string

The email address of the individual to whom the invite was sent

role
string

owner or reader

status
string

accepted,expired, or pending

invited_at
integer

The Unix timestamp (in seconds) of when the invite was sent.

expires_at
integer

The Unix timestamp (in seconds) of when the invite expires.

accepted_at
integer

The Unix timestamp (in seconds) of when the invite was accepted.

projects
array

The projects that were granted membership upon acceptance of the invite.


Show properties
OBJECT The invite object
{
  "object": "organization.invite",
  "id": "invite-abc",
  "email": "user@example.com",
  "role": "owner",
  "status": "accepted",
  "invited_at": 1711471533,
  "expires_at": 1711471533,
  "accepted_at": 1711471533,
  "projects": [
    {
      "id": "project-xyz",
      "role": "member"
    }
  ]
}
Users
Manage users and their role in an organization.

List users
get
 
https://api.openai.com/v1/organization/users
Lists all of the users in the organization.

Query parameters
limit
integer

Optional
Defaults to 20
A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.

after
string

Optional
A cursor for use in pagination. after is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj_foo, your subsequent call can include after=obj_foo in order to fetch the next page of the list.

emails
array

Optional
Filter by the email address of users.

Returns
A list of User objects.

Example request
curl https://api.openai.com/v1/organization/users?after=user_abc&limit=20 \
  -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
  -H "Content-Type: application/json"
Response
{
    "object": "list",
    "data": [
        {
            "object": "organization.user",
            "id": "user_abc",
            "name": "First Last",
            "email": "user@example.com",
            "role": "owner",
            "added_at": 1711471533
        }
    ],
    "first_id": "user-abc",
    "last_id": "user-xyz",
    "has_more": false
}
Modify user
post
 
https://api.openai.com/v1/organization/users/{user_id}
Modifies a user's role in the organization.

Path parameters
user_id
string

Required
The ID of the user.

Request body
role
string

Required
owner or reader

Returns
The updated User object.

Example request
curl -X POST https://api.openai.com/v1/organization/users/user_abc \
  -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
  -H "Content-Type: application/json" \
  -d '{
      "role": "owner"
  }'
Response
{
    "object": "organization.user",
    "id": "user_abc",
    "name": "First Last",
    "email": "user@example.com",
    "role": "owner",
    "added_at": 1711471533
}
Retrieve user
get
 
https://api.openai.com/v1/organization/users/{user_id}
Retrieves a user by their identifier.

Path parameters
user_id
string

Required
The ID of the user.

Returns
The User object matching the specified ID.

Example request
curl https://api.openai.com/v1/organization/users/user_abc \
  -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
  -H "Content-Type: application/json"
Response
{
    "object": "organization.user",
    "id": "user_abc",
    "name": "First Last",
    "email": "user@example.com",
    "role": "owner",
    "added_at": 1711471533
}
Delete user
delete
 
https://api.openai.com/v1/organization/users/{user_id}
Deletes a user from the organization.

Path parameters
user_id
string

Required
The ID of the user.

Returns
Confirmation of the deleted user

Example request
curl -X DELETE https://api.openai.com/v1/organization/users/user_abc \
  -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
  -H "Content-Type: application/json"
Response
{
    "object": "organization.user.deleted",
    "id": "user_abc",
    "deleted": true
}
The user object
Represents an individual user within an organization.

object
string

The object type, which is always organization.user

id
string

The identifier, which can be referenced in API endpoints

name
string

The name of the user

email
string

The email address of the user

role
string

owner or reader

added_at
integer

The Unix timestamp (in seconds) of when the user was added.

OBJECT The user object
{
    "object": "organization.user",
    "id": "user_abc",
    "name": "First Last",
    "email": "user@example.com",
    "role": "owner",
    "added_at": 1711471533
}
Projects
Manage the projects within an orgnanization includes creation, updating, and archiving or projects. The Default project cannot be archived.

List projects
get
 
https://api.openai.com/v1/organization/projects
Returns a list of projects.

Query parameters
limit
integer

Optional
Defaults to 20
A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.

after
string

Optional
A cursor for use in pagination. after is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj_foo, your subsequent call can include after=obj_foo in order to fetch the next page of the list.

include_archived
boolean

Optional
Defaults to false
If true returns all projects including those that have been archived. Archived projects are not included by default.

Returns
A list of Project objects.

Example request
curl https://api.openai.com/v1/organization/projects?after=proj_abc&limit=20&include_archived=false \
  -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
  -H "Content-Type: application/json"
Response
{
    "object": "list",
    "data": [
        {
            "id": "proj_abc",
            "object": "organization.project",
            "name": "Project example",
            "created_at": 1711471533,
            "archived_at": null,
            "status": "active"
        }
    ],
    "first_id": "proj-abc",
    "last_id": "proj-xyz",
    "has_more": false
}
Create project
post
 
https://api.openai.com/v1/organization/projects
Create a new project in the organization. Projects can be created and archived, but cannot be deleted.

Request body
name
string

Required
The friendly name of the project, this name appears in reports.

Returns
The created Project object.

Example request
curl -X POST https://api.openai.com/v1/organization/projects \
  -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
  -H "Content-Type: application/json" \
  -d '{
      "name": "Project ABC"
  }'
Response
{
    "id": "proj_abc",
    "object": "organization.project",
    "name": "Project ABC",
    "created_at": 1711471533,
    "archived_at": null,
    "status": "active"
}
Retrieve project
get
 
https://api.openai.com/v1/organization/projects/{project_id}
Retrieves a project.

Path parameters
project_id
string

Required
The ID of the project.

Returns
The Project object matching the specified ID.

Example request
curl https://api.openai.com/v1/organization/projects/proj_abc \
  -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
  -H "Content-Type: application/json"
Response
{
    "id": "proj_abc",
    "object": "organization.project",
    "name": "Project example",
    "created_at": 1711471533,
    "archived_at": null,
    "status": "active"
}
Modify project
post
 
https://api.openai.com/v1/organization/projects/{project_id}
Modifies a project in the organization.

Path parameters
project_id
string

Required
The ID of the project.

Request body
name
string

Required
The updated name of the project, this name appears in reports.

Returns
The updated Project object.

Example request
curl -X POST https://api.openai.com/v1/organization/projects/proj_abc \
  -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
  -H "Content-Type: application/json" \
  -d '{
      "name": "Project DEF"
  }'
Archive project
post
 
https://api.openai.com/v1/organization/projects/{project_id}/archive
Archives a project in the organization. Archived projects cannot be used or updated.

Path parameters
project_id
string

Required
The ID of the project.

Returns
The archived Project object.

Example request
curl -X POST https://api.openai.com/v1/organization/projects/proj_abc/archive \
  -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
  -H "Content-Type: application/json"
Response
{
    "id": "proj_abc",
    "object": "organization.project",
    "name": "Project DEF",
    "created_at": 1711471533,
    "archived_at": 1711471533,
    "status": "archived"
}
The project object
Represents an individual project.

id
string

The identifier, which can be referenced in API endpoints

object
string

The object type, which is always organization.project

name
string

The name of the project. This appears in reporting.

created_at
integer

The Unix timestamp (in seconds) of when the project was created.

archived_at
integer or null

The Unix timestamp (in seconds) of when the project was archived or null.

status
string

active or archived

OBJECT The project object
{
    "id": "proj_abc",
    "object": "organization.project",
    "name": "Project example",
    "created_at": 1711471533,
    "archived_at": null,
    "status": "active"
}
Project users
Manage users within a project, including adding, updating roles, and removing users.

List project users
get
 
https://api.openai.com/v1/organization/projects/{project_id}/users
Returns a list of users in the project.

Path parameters
project_id
string

Required
The ID of the project.

Query parameters
limit
integer

Optional
Defaults to 20
A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.

after
string

Optional
A cursor for use in pagination. after is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj_foo, your subsequent call can include after=obj_foo in order to fetch the next page of the list.

Returns
A list of ProjectUser objects.

Example request
curl https://api.openai.com/v1/organization/projects/proj_abc/users?after=user_abc&limit=20 \
  -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
  -H "Content-Type: application/json"
Response
{
    "object": "list",
    "data": [
        {
            "object": "organization.project.user",
            "id": "user_abc",
            "name": "First Last",
            "email": "user@example.com",
            "role": "owner",
            "added_at": 1711471533
        }
    ],
    "first_id": "user-abc",
    "last_id": "user-xyz",
    "has_more": false
}
Create project user
post
 
https://api.openai.com/v1/organization/projects/{project_id}/users
Adds a user to the project. Users must already be members of the organization to be added to a project.

Path parameters
project_id
string

Required
The ID of the project.

Request body
user_id
string

Required
The ID of the user.

role
string

Required
owner or member

Returns
The created ProjectUser object.

Example request
curl -X POST https://api.openai.com/v1/organization/projects/proj_abc/users \
  -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
  -H "Content-Type: application/json" \
  -d '{
      "user_id": "user_abc",
      "role": "member"
  }'
Response
{
    "object": "organization.project.user",
    "id": "user_abc",
    "email": "user@example.com",
    "role": "owner",
    "added_at": 1711471533
}
Retrieve project user
get
 
https://api.openai.com/v1/organization/projects/{project_id}/users/{user_id}
Retrieves a user in the project.

Path parameters
project_id
string

Required
The ID of the project.

user_id
string

Required
The ID of the user.

Returns
The ProjectUser object matching the specified ID.

Example request
curl https://api.openai.com/v1/organization/projects/proj_abc/users/user_abc \
  -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
  -H "Content-Type: application/json"
Response
{
    "object": "organization.project.user",
    "id": "user_abc",
    "name": "First Last",
    "email": "user@example.com",
    "role": "owner",
    "added_at": 1711471533
}
Modify project user
post
 
https://api.openai.com/v1/organization/projects/{project_id}/users/{user_id}
Modifies a user's role in the project.

Path parameters
project_id
string

Required
The ID of the project.

user_id
string

Required
The ID of the user.

Request body
role
string

Required
owner or member

Returns
The updated ProjectUser object.

Example request
curl -X POST https://api.openai.com/v1/organization/projects/proj_abc/users/user_abc \
  -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
  -H "Content-Type: application/json" \
  -d '{
      "role": "owner"
  }'
Response
{
    "object": "organization.project.user",
    "id": "user_abc",
    "name": "First Last",
    "email": "user@example.com",
    "role": "owner",
    "added_at": 1711471533
}
Delete project user
delete
 
https://api.openai.com/v1/organization/projects/{project_id}/users/{user_id}
Deletes a user from the project.

Path parameters
project_id
string

Required
The ID of the project.

user_id
string

Required
The ID of the user.

Returns
Confirmation that project has been deleted or an error in case of an archived project, which has no users

Example request
curl -X DELETE https://api.openai.com/v1/organization/projects/proj_abc/users/user_abc \
  -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
  -H "Content-Type: application/json"
Response
{
    "object": "organization.project.user.deleted",
    "id": "user_abc",
    "deleted": true
}
The project user object
Represents an individual user in a project.

object
string

The object type, which is always organization.project.user

id
string

The identifier, which can be referenced in API endpoints

name
string

The name of the user

email
string

The email address of the user

role
string

owner or member

added_at
integer

The Unix timestamp (in seconds) of when the project was added.

OBJECT The project user object
{
    "object": "organization.project.user",
    "id": "user_abc",
    "name": "First Last",
    "email": "user@example.com",
    "role": "owner",
    "added_at": 1711471533
}
Project service accounts
Manage service accounts within a project. A service account is a bot user that is not associated with a user. If a user leaves an organization, their keys and membership in projects will no longer work. Service accounts do not have this limitation. However, service accounts can also be deleted from a project.

List project service accounts
get
 
https://api.openai.com/v1/organization/projects/{project_id}/service_accounts
Returns a list of service accounts in the project.

Path parameters
project_id
string

Required
The ID of the project.

Query parameters
limit
integer

Optional
Defaults to 20
A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.

after
string

Optional
A cursor for use in pagination. after is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj_foo, your subsequent call can include after=obj_foo in order to fetch the next page of the list.

Returns
A list of ProjectServiceAccount objects.

Example request
curl https://api.openai.com/v1/organization/projects/proj_abc/service_accounts?after=custom_id&limit=20 \
  -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
  -H "Content-Type: application/json"
Response
{
    "object": "list",
    "data": [
        {
            "object": "organization.project.service_account",
            "id": "svc_acct_abc",
            "name": "Service Account",
            "role": "owner",
            "created_at": 1711471533
        }
    ],
    "first_id": "svc_acct_abc",
    "last_id": "svc_acct_xyz",
    "has_more": false
}
Create project service account
post
 
https://api.openai.com/v1/organization/projects/{project_id}/service_accounts
Creates a new service account in the project. This also returns an unredacted API key for the service account.

Path parameters
project_id
string

Required
The ID of the project.

Request body
name
string

Required
The name of the service account being created.

Returns
The created ProjectServiceAccount object.

Example request
curl -X POST https://api.openai.com/v1/organization/projects/proj_abc/service_accounts \
  -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
  -H "Content-Type: application/json" \
  -d '{
      "name": "Production App"
  }'
Response
{
    "object": "organization.project.service_account",
    "id": "svc_acct_abc",
    "name": "Production App",
    "role": "member",
    "created_at": 1711471533,
    "api_key": {
        "object": "organization.project.service_account.api_key",
        "value": "sk-abcdefghijklmnop123",
        "name": "Secret Key",
        "created_at": 1711471533,
        "id": "key_abc"
    }
}
Retrieve project service account
get
 
https://api.openai.com/v1/organization/projects/{project_id}/service_accounts/{service_account_id}
Retrieves a service account in the project.

Path parameters
project_id
string

Required
The ID of the project.

service_account_id
string

Required
The ID of the service account.

Returns
The ProjectServiceAccount object matching the specified ID.

Example request
curl https://api.openai.com/v1/organization/projects/proj_abc/service_accounts/svc_acct_abc \
  -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
  -H "Content-Type: application/json"
Response
{
    "object": "organization.project.service_account",
    "id": "svc_acct_abc",
    "name": "Service Account",
    "role": "owner",
    "created_at": 1711471533
}
Delete project service account
delete
 
https://api.openai.com/v1/organization/projects/{project_id}/service_accounts/{service_account_id}
Deletes a service account from the project.

Path parameters
project_id
string

Required
The ID of the project.

service_account_id
string

Required
The ID of the service account.

Returns
Confirmation of service account being deleted, or an error in case of an archived project, which has no service accounts

Example request
curl -X DELETE https://api.openai.com/v1/organization/projects/proj_abc/service_accounts/svc_acct_abc \
  -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
  -H "Content-Type: application/json"
Response
{
    "object": "organization.project.service_account.deleted",
    "id": "svc_acct_abc",
    "deleted": true
}
The project service account object
Represents an individual service account in a project.

object
string

The object type, which is always organization.project.service_account

id
string

The identifier, which can be referenced in API endpoints

name
string

The name of the service account

role
string

owner or member

created_at
integer

The Unix timestamp (in seconds) of when the service account was created

OBJECT The project service account object
{
    "object": "organization.project.service_account",
    "id": "svc_acct_abc",
    "name": "Service Account",
    "role": "owner",
    "created_at": 1711471533
}
Project API keys
Manage API keys for a given project. Supports listing and deleting keys for users. This API does not allow issuing keys for users, as users need to authorize themselves to generate keys.

List project API keys
get
 
https://api.openai.com/v1/organization/projects/{project_id}/api_keys
Returns a list of API keys in the project.

Path parameters
project_id
string

Required
The ID of the project.

Query parameters
limit
integer

Optional
Defaults to 20
A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.

after
string

Optional
A cursor for use in pagination. after is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj_foo, your subsequent call can include after=obj_foo in order to fetch the next page of the list.

Returns
A list of ProjectApiKey objects.

Example request
curl https://api.openai.com/v1/organization/projects/proj_abc/api_keys?after=key_abc&limit=20 \
  -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
  -H "Content-Type: application/json"
Response
{
    "object": "list",
    "data": [
        {
            "object": "organization.project.api_key",
            "redacted_value": "sk-abc...def",
            "name": "My API Key",
            "created_at": 1711471533,
            "id": "key_abc",
            "owner": {
                "type": "user",
                "user": {
                    "object": "organization.project.user",
                    "id": "user_abc",
                    "name": "First Last",
                    "email": "user@example.com",
                    "role": "owner",
                    "added_at": 1711471533
                }
            }
        }
    ],
    "first_id": "key_abc",
    "last_id": "key_xyz",
    "has_more": false
}
Retrieve project API key
get
 
https://api.openai.com/v1/organization/projects/{project_id}/api_keys/{key_id}
Retrieves an API key in the project.

Path parameters
project_id
string

Required
The ID of the project.

key_id
string

Required
The ID of the API key.

Returns
The ProjectApiKey object matching the specified ID.

Example request
curl https://api.openai.com/v1/organization/projects/proj_abc/api_keys/key_abc \
  -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
  -H "Content-Type: application/json"
Response
{
    "object": "organization.project.api_key",
    "redacted_value": "sk-abc...def",
    "name": "My API Key",
    "created_at": 1711471533,
    "id": "key_abc",
    "owner": {
        "type": "user",
        "user": {
            "object": "organization.project.user",
            "id": "user_abc",
            "name": "First Last",
            "email": "user@example.com",
            "role": "owner",
            "added_at": 1711471533
        }
    }
}
Delete project API key
delete
 
https://api.openai.com/v1/organization/projects/{project_id}/api_keys/{key_id}
Deletes an API key from the project.

Path parameters
project_id
string

Required
The ID of the project.

key_id
string

Required
The ID of the API key.

Returns
Confirmation of the key's deletion or an error if the key belonged to a service account

Example request
curl -X DELETE https://api.openai.com/v1/organization/projects/proj_abc/api_keys/key_abc \
  -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
  -H "Content-Type: application/json"
Response
{
    "object": "organization.project.api_key.deleted",
    "id": "key_abc",
    "deleted": true
}
The project API key object
Represents an individual API key in a project.

object
string

The object type, which is always organization.project.api_key

redacted_value
string

The redacted value of the API key

name
string

The name of the API key

created_at
integer

The Unix timestamp (in seconds) of when the API key was created

id
string

The identifier, which can be referenced in API endpoints

owner
object


Show properties
OBJECT The project API key object
{
    "object": "organization.project.api_key",
    "redacted_value": "sk-abc...def",
    "name": "My API Key",
    "created_at": 1711471533,
    "id": "key_abc",
    "owner": {
        "type": "user",
        "user": {
            "object": "organization.project.user",
            "id": "user_abc",
            "name": "First Last",
            "email": "user@example.com",
            "role": "owner",
            "created_at": 1711471533
        }
    }
}
Project rate limits
Manage rate limits per model for projects. Rate limits may be configured to be equal to or lower than the organization's rate limits.

List project rate limits
get
 
https://api.openai.com/v1/organization/projects/{project_id}/rate_limits
Returns the rate limits per model for a project.

Path parameters
project_id
string

Required
The ID of the project.

Query parameters
limit
integer

Optional
Defaults to 100
A limit on the number of objects to be returned. The default is 100.

after
string

Optional
A cursor for use in pagination. after is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj_foo, your subsequent call can include after=obj_foo in order to fetch the next page of the list.

before
string

Optional
A cursor for use in pagination. before is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, beginning with obj_foo, your subsequent call can include before=obj_foo in order to fetch the previous page of the list.

Returns
A list of ProjectRateLimit objects.

Example request
curl https://api.openai.com/v1/organization/projects/proj_abc/rate_limits?after=rl_xxx&limit=20 \
  -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
  -H "Content-Type: application/json"
Response
{
    "object": "list",
    "data": [
        {
          "object": "project.rate_limit",
          "id": "rl-ada",
          "model": "ada",
          "max_requests_per_1_minute": 600,
          "max_tokens_per_1_minute": 150000,
          "max_images_per_1_minute": 10
        }
    ],
    "first_id": "rl-ada",
    "last_id": "rl-ada",
    "has_more": false
}
Modify project rate limit
post
 
https://api.openai.com/v1/organization/projects/{project_id}/rate_limits/{rate_limit_id}
Updates a project rate limit.

Path parameters
project_id
string

Required
The ID of the project.

rate_limit_id
string

Required
The ID of the rate limit.

Request body
max_requests_per_1_minute
integer

Optional
The maximum requests per minute.

max_tokens_per_1_minute
integer

Optional
The maximum tokens per minute.

max_images_per_1_minute
integer

Optional
The maximum images per minute. Only relevant for certain models.

max_audio_megabytes_per_1_minute
integer

Optional
The maximum audio megabytes per minute. Only relevant for certain models.

max_requests_per_1_day
integer

Optional
The maximum requests per day. Only relevant for certain models.

batch_1_day_max_input_tokens
integer

Optional
The maximum batch input tokens per day. Only relevant for certain models.

Returns
The updated ProjectRateLimit object.

Example request
curl -X POST https://api.openai.com/v1/organization/projects/proj_abc/rate_limits/rl_xxx \
  -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
  -H "Content-Type: application/json" \
  -d '{
      "max_requests_per_1_minute": 500
  }'
Response
{
    "object": "project.rate_limit",
    "id": "rl-ada",
    "model": "ada",
    "max_requests_per_1_minute": 600,
    "max_tokens_per_1_minute": 150000,
    "max_images_per_1_minute": 10
  }
The project rate limit object
Represents a project rate limit config.

object
string

The object type, which is always project.rate_limit

id
string

The identifier, which can be referenced in API endpoints.

model
string

The model this rate limit applies to.

max_requests_per_1_minute
integer

The maximum requests per minute.

max_tokens_per_1_minute
integer

The maximum tokens per minute.

max_images_per_1_minute
integer

The maximum images per minute. Only present for relevant models.

max_audio_megabytes_per_1_minute
integer

The maximum audio megabytes per minute. Only present for relevant models.

max_requests_per_1_day
integer

The maximum requests per day. Only present for relevant models.

batch_1_day_max_input_tokens
integer

The maximum batch input tokens per day. Only present for relevant models.

OBJECT The project rate limit object
{
    "object": "project.rate_limit",
    "id": "rl_ada",
    "model": "ada",
    "max_requests_per_1_minute": 600,
    "max_tokens_per_1_minute": 150000,
    "max_images_per_1_minute": 10
}
Audit logs
Logs of user actions and configuration changes within this organization. To log events, you must activate logging in the Organization Settings. Once activated, for security reasons, logging cannot be deactivated.

List audit logs
get
 
https://api.openai.com/v1/organization/audit_logs
List user actions and configuration changes within this organization.

Query parameters
effective_at
object

Optional
Return only events whose effective_at (Unix seconds) is in this range.


Show properties
project_ids[]
array

Optional
Return only events for these projects.

event_types[]
array

Optional
Return only events with a type in one of these values. For example, project.created. For all options, see the documentation for the audit log object.

actor_ids[]
array

Optional
Return only events performed by these actors. Can be a user ID, a service account ID, or an api key tracking ID.

actor_emails[]
array

Optional
Return only events performed by users with these emails.

resource_ids[]
array

Optional
Return only events performed on these targets. For example, a project ID updated.

limit
integer

Optional
Defaults to 20
A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.

after
string

Optional
A cursor for use in pagination. after is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj_foo, your subsequent call can include after=obj_foo in order to fetch the next page of the list.

before
string

Optional
A cursor for use in pagination. before is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, starting with obj_foo, your subsequent call can include before=obj_foo in order to fetch the previous page of the list.

Returns
A list of paginated Audit Log objects.

Example request
curl https://api.openai.com/v1/organization/audit_logs \
-H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
-H "Content-Type: application/json"
Response
{
    "object": "list",
    "data": [
        {
            "id": "audit_log-xxx_yyyymmdd",
            "type": "project.archived",
            "effective_at": 1722461446,
            "actor": {
                "type": "api_key",
                "api_key": {
                    "type": "user",
                    "user": {
                        "id": "user-xxx",
                        "email": "user@example.com"
                    }
                }
            },
            "project.archived": {
                "id": "proj_abc"
            },
        },
        {
            "id": "audit_log-yyy__20240101",
            "type": "api_key.updated",
            "effective_at": 1720804190,
            "actor": {
                "type": "session",
                "session": {
                    "user": {
                        "id": "user-xxx",
                        "email": "user@example.com"
                    },
                    "ip_address": "127.0.0.1",
                    "user_agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36",
                    "ja3": "a497151ce4338a12c4418c44d375173e",
                    "ja4": "q13d0313h3_55b375c5d22e_c7319ce65786",
                    "ip_address_details": {
                      "country": "US",
                      "city": "San Francisco",
                      "region": "California",
                      "region_code": "CA",
                      "asn": "1234",
                      "latitude": "37.77490",
                      "longitude": "-122.41940"
                    }
                }
            },
            "api_key.updated": {
                "id": "key_xxxx",
                "data": {
                    "scopes": ["resource_2.operation_2"]
                }
            },
        }
    ],
    "first_id": "audit_log-xxx__20240101",
    "last_id": "audit_log_yyy__20240101",
    "has_more": true
}
The audit log object
A log of a user action or configuration change within this organization.

id
string

The ID of this log.

type
string

The event type.

effective_at
integer

The Unix timestamp (in seconds) of the event.

project
object

The project that the action was scoped to. Absent for actions not scoped to projects.


Show properties
actor
object

The actor who performed the audit logged action.


Show properties
api_key.created
object

The details for events with this type.


Show properties
api_key.updated
object

The details for events with this type.


Show properties
api_key.deleted
object

The details for events with this type.


Show properties
invite.sent
object

The details for events with this type.


Show properties
invite.accepted
object

The details for events with this type.


Show properties
invite.deleted
object

The details for events with this type.


Show properties
login.failed
object

The details for events with this type.


Show properties
logout.failed
object

The details for events with this type.


Show properties
organization.updated
object

The details for events with this type.


Show properties
project.created
object

The details for events with this type.


Show properties
project.updated
object

The details for events with this type.


Show properties
project.archived
object

The details for events with this type.


Show properties
rate_limit.updated
object

The details for events with this type.


Show properties
rate_limit.deleted
object

The details for events with this type.


Show properties
service_account.created
object

The details for events with this type.


Show properties
service_account.updated
object

The details for events with this type.


Show properties
service_account.deleted
object

The details for events with this type.


Show properties
user.added
object

The details for events with this type.


Show properties
user.updated
object

The details for events with this type.


Show properties
user.deleted
object

The details for events with this type.


Show properties
OBJECT The audit log object
{
    "id": "req_xxx_20240101",
    "type": "api_key.created",
    "effective_at": 1720804090,
    "actor": {
        "type": "session",
        "session": {
            "user": {
                "id": "user-xxx",
                "email": "user@example.com"
            },
            "ip_address": "127.0.0.1",
            "user_agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36"
        }
    },
    "api_key.created": {
        "id": "key_xxxx",
        "data": {
            "scopes": ["resource.operation"]
        }
    }
}
Usage
The Usage API provides detailed insights into your activity across the OpenAI API. It also includes a separate Costs endpoint, which offers visibility into your spend, breaking down consumption by invoice line items and project IDs.

While the Usage API delivers granular usage data, it may not always reconcile perfectly with the Costs due to minor differences in how usage and spend are recorded. For financial purposes, we recommend using the Costs endpoint or the Costs tab in the Usage Dashboard, which will reconcile back to your billing invoice.

Completions
get
 
https://api.openai.com/v1/organization/usage/completions
Get completions usage details for the organization.

Query parameters
start_time
integer

Required
Start time (Unix seconds) of the query time range, inclusive.

end_time
integer

Optional
End time (Unix seconds) of the query time range, exclusive.

bucket_width
string

Optional
Defaults to 1d
Width of each time bucket in response. Currently 1m, 1h and 1d are supported, default to 1d.

project_ids
array

Optional
Return only usage for these projects.

user_ids
array

Optional
Return only usage for these users.

api_key_ids
array

Optional
Return only usage for these API keys.

models
array

Optional
Return only usage for these models.

batch
boolean

Optional
If true, return batch jobs only. If false, return non-batch jobs only. By default, return both.

group_by
array

Optional
Group the usage data by the specified fields. Support fields include project_id, user_id, api_key_id, model, batch or any combination of them.

limit
integer

Optional
Specifies the number of buckets to return.

bucket_width=1d: default: 7, max: 31
bucket_width=1h: default: 24, max: 168
bucket_width=1m: default: 60, max: 1440
page
string

Optional
A cursor for use in pagination. Corresponding to the next_page field from the previous response.

Returns
A list of paginated, time bucketed Completions usage objects.

Example request
curl "https://api.openai.com/v1/organization/usage/completions?start_time=1730419200&limit=1" \
-H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
-H "Content-Type: application/json"
Response
{
    "object": "page",
    "data": [
        {
            "object": "bucket",
            "start_time": 1730419200,
            "end_time": 1730505600,
            "results": [
                {
                    "object": "organization.usage.completions.result",
                    "input_tokens": 1000,
                    "output_tokens": 500,
                    "input_cached_tokens": 800,
                    "input_audio_tokens": 0,
                    "output_audio_tokens": 0,
                    "num_model_requests": 5,
                    "project_id": null,
                    "user_id": null,
                    "api_key_id": null,
                    "model": null,
                    "batch": null
                }
            ]
        }
    ],
    "has_more": true,
    "next_page": "page_AAAAAGdGxdEiJdKOAAAAAGcqsYA="
}
Completions usage object
The aggregated completions usage details of the specific time bucket.

object
string

input_tokens
integer

The aggregated number of text input tokens used, including cached tokens. For customers subscribe to scale tier, this includes scale tier tokens.

input_cached_tokens
integer

The aggregated number of text input tokens that has been cached from previous requests. For customers subscribe to scale tier, this includes scale tier tokens.

output_tokens
integer

The aggregated number of text output tokens used. For customers subscribe to scale tier, this includes scale tier tokens.

input_audio_tokens
integer

The aggregated number of audio input tokens used, including cached tokens.

output_audio_tokens
integer

The aggregated number of audio output tokens used.

num_model_requests
integer

The count of requests made to the model.

project_id
string or null

When group_by=project_id, this field provides the project ID of the grouped usage result.

user_id
string or null

When group_by=user_id, this field provides the user ID of the grouped usage result.

api_key_id
string or null

When group_by=api_key_id, this field provides the API key ID of the grouped usage result.

model
string or null

When group_by=model, this field provides the model name of the grouped usage result.

batch
boolean or null

When group_by=batch, this field tells whether the grouped usage result is batch or not.

OBJECT Completions usage object
{
    "object": "organization.usage.completions.result",
    "input_tokens": 5000,
    "output_tokens": 1000,
    "input_cached_tokens": 4000,
    "input_audio_tokens": 300,
    "output_audio_tokens": 200,
    "num_model_requests": 5,
    "project_id": "proj_abc",
    "user_id": "user-abc",
    "api_key_id": "key_abc",
    "model": "gpt-4o-mini-2024-07-18",
    "batch": false
}
Embeddings
get
 
https://api.openai.com/v1/organization/usage/embeddings
Get embeddings usage details for the organization.

Query parameters
start_time
integer

Required
Start time (Unix seconds) of the query time range, inclusive.

end_time
integer

Optional
End time (Unix seconds) of the query time range, exclusive.

bucket_width
string

Optional
Defaults to 1d
Width of each time bucket in response. Currently 1m, 1h and 1d are supported, default to 1d.

project_ids
array

Optional
Return only usage for these projects.

user_ids
array

Optional
Return only usage for these users.

api_key_ids
array

Optional
Return only usage for these API keys.

models
array

Optional
Return only usage for these models.

group_by
array

Optional
Group the usage data by the specified fields. Support fields include project_id, user_id, api_key_id, model or any combination of them.

limit
integer

Optional
Specifies the number of buckets to return.

bucket_width=1d: default: 7, max: 31
bucket_width=1h: default: 24, max: 168
bucket_width=1m: default: 60, max: 1440
page
string

Optional
A cursor for use in pagination. Corresponding to the next_page field from the previous response.

Returns
A list of paginated, time bucketed Embeddings usage objects.

Example request
curl "https://api.openai.com/v1/organization/usage/embeddings?start_time=1730419200&limit=1" \
-H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
-H "Content-Type: application/json"
Response
{
    "object": "page",
    "data": [
        {
            "object": "bucket",
            "start_time": 1730419200,
            "end_time": 1730505600,
            "results": [
                {
                    "object": "organization.usage.embeddings.result",
                    "input_tokens": 16,
                    "num_model_requests": 2,
                    "project_id": null,
                    "user_id": null,
                    "api_key_id": null,
                    "model": null
                }
            ]
        }
    ],
    "has_more": false,
    "next_page": null
}
Embeddings usage object
The aggregated embeddings usage details of the specific time bucket.

object
string

input_tokens
integer

The aggregated number of input tokens used.

num_model_requests
integer

The count of requests made to the model.

project_id
string or null

When group_by=project_id, this field provides the project ID of the grouped usage result.

user_id
string or null

When group_by=user_id, this field provides the user ID of the grouped usage result.

api_key_id
string or null

When group_by=api_key_id, this field provides the API key ID of the grouped usage result.

model
string or null

When group_by=model, this field provides the model name of the grouped usage result.

OBJECT Embeddings usage object
{
    "object": "organization.usage.embeddings.result",
    "input_tokens": 20,
    "num_model_requests": 2,
    "project_id": "proj_abc",
    "user_id": "user-abc",
    "api_key_id": "key_abc",
    "model": "text-embedding-ada-002-v2"
}
Moderations
get
 
https://api.openai.com/v1/organization/usage/moderations
Get moderations usage details for the organization.

Query parameters
start_time
integer

Required
Start time (Unix seconds) of the query time range, inclusive.

end_time
integer

Optional
End time (Unix seconds) of the query time range, exclusive.

bucket_width
string

Optional
Defaults to 1d
Width of each time bucket in response. Currently 1m, 1h and 1d are supported, default to 1d.

project_ids
array

Optional
Return only usage for these projects.

user_ids
array

Optional
Return only usage for these users.

api_key_ids
array

Optional
Return only usage for these API keys.

models
array

Optional
Return only usage for these models.

group_by
array

Optional
Group the usage data by the specified fields. Support fields include project_id, user_id, api_key_id, model or any combination of them.

limit
integer

Optional
Specifies the number of buckets to return.

bucket_width=1d: default: 7, max: 31
bucket_width=1h: default: 24, max: 168
bucket_width=1m: default: 60, max: 1440
page
string

Optional
A cursor for use in pagination. Corresponding to the next_page field from the previous response.

Returns
A list of paginated, time bucketed Moderations usage objects.

Example request
curl "https://api.openai.com/v1/organization/usage/moderations?start_time=1730419200&limit=1" \
-H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
-H "Content-Type: application/json"
Response
{
    "object": "page",
    "data": [
        {
            "object": "bucket",
            "start_time": 1730419200,
            "end_time": 1730505600,
            "results": [
                {
                    "object": "organization.usage.moderations.result",
                    "input_tokens": 16,
                    "num_model_requests": 2,
                    "project_id": null,
                    "user_id": null,
                    "api_key_id": null,
                    "model": null
                }
            ]
        }
    ],
    "has_more": false,
    "next_page": null
}
Moderations usage object
The aggregated moderations usage details of the specific time bucket.

object
string

input_tokens
integer

The aggregated number of input tokens used.

num_model_requests
integer

The count of requests made to the model.

project_id
string or null

When group_by=project_id, this field provides the project ID of the grouped usage result.

user_id
string or null

When group_by=user_id, this field provides the user ID of the grouped usage result.

api_key_id
string or null

When group_by=api_key_id, this field provides the API key ID of the grouped usage result.

model
string or null

When group_by=model, this field provides the model name of the grouped usage result.

OBJECT Moderations usage object
{
    "object": "organization.usage.moderations.result",
    "input_tokens": 20,
    "num_model_requests": 2,
    "project_id": "proj_abc",
    "user_id": "user-abc",
    "api_key_id": "key_abc",
    "model": "text-moderation"
}
Images
get
 
https://api.openai.com/v1/organization/usage/images
Get images usage details for the organization.

Query parameters
start_time
integer

Required
Start time (Unix seconds) of the query time range, inclusive.

end_time
integer

Optional
End time (Unix seconds) of the query time range, exclusive.

bucket_width
string

Optional
Defaults to 1d
Width of each time bucket in response. Currently 1m, 1h and 1d are supported, default to 1d.

sources
array

Optional
Return only usages for these sources. Possible values are image.generation, image.edit, image.variation or any combination of them.

sizes
array

Optional
Return only usages for these image sizes. Possible values are 256x256, 512x512, 1024x1024, 1792x1792, 1024x1792 or any combination of them.

project_ids
array

Optional
Return only usage for these projects.

user_ids
array

Optional
Return only usage for these users.

api_key_ids
array

Optional
Return only usage for these API keys.

models
array

Optional
Return only usage for these models.

group_by
array

Optional
Group the usage data by the specified fields. Support fields include project_id, user_id, api_key_id, model, size, source or any combination of them.

limit
integer

Optional
Specifies the number of buckets to return.

bucket_width=1d: default: 7, max: 31
bucket_width=1h: default: 24, max: 168
bucket_width=1m: default: 60, max: 1440
page
string

Optional
A cursor for use in pagination. Corresponding to the next_page field from the previous response.

Returns
A list of paginated, time bucketed Images usage objects.

Example request
curl "https://api.openai.com/v1/organization/usage/images?start_time=1730419200&limit=1" \
-H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
-H "Content-Type: application/json"
Response
{
    "object": "page",
    "data": [
        {
            "object": "bucket",
            "start_time": 1730419200,
            "end_time": 1730505600,
            "results": [
                {
                    "object": "organization.usage.images.result",
                    "images": 2,
                    "num_model_requests": 2,
                    "size": null,
                    "source": null,
                    "project_id": null,
                    "user_id": null,
                    "api_key_id": null,
                    "model": null
                }
            ]
        }
    ],
    "has_more": false,
    "next_page": null
}
Images usage object
The aggregated images usage details of the specific time bucket.

object
string

images
integer

The number of images processed.

num_model_requests
integer

The count of requests made to the model.

source
string or null

When group_by=source, this field provides the source of the grouped usage result, possible values are image.generation, image.edit, image.variation.

size
string or null

When group_by=size, this field provides the image size of the grouped usage result.

project_id
string or null

When group_by=project_id, this field provides the project ID of the grouped usage result.

user_id
string or null

When group_by=user_id, this field provides the user ID of the grouped usage result.

api_key_id
string or null

When group_by=api_key_id, this field provides the API key ID of the grouped usage result.

model
string or null

When group_by=model, this field provides the model name of the grouped usage result.

OBJECT Images usage object
{
    "object": "organization.usage.images.result",
    "images": 2,
    "num_model_requests": 2,
    "size": "1024x1024",
    "source": "image.generation",
    "project_id": "proj_abc",
    "user_id": "user-abc",
    "api_key_id": "key_abc",
    "model": "dall-e-3"
}
Audio speeches
get
 
https://api.openai.com/v1/organization/usage/audio_speeches
Get audio speeches usage details for the organization.

Query parameters
start_time
integer

Required
Start time (Unix seconds) of the query time range, inclusive.

end_time
integer

Optional
End time (Unix seconds) of the query time range, exclusive.

bucket_width
string

Optional
Defaults to 1d
Width of each time bucket in response. Currently 1m, 1h and 1d are supported, default to 1d.

project_ids
array

Optional
Return only usage for these projects.

user_ids
array

Optional
Return only usage for these users.

api_key_ids
array

Optional
Return only usage for these API keys.

models
array

Optional
Return only usage for these models.

group_by
array

Optional
Group the usage data by the specified fields. Support fields include project_id, user_id, api_key_id, model or any combination of them.

limit
integer

Optional
Specifies the number of buckets to return.

bucket_width=1d: default: 7, max: 31
bucket_width=1h: default: 24, max: 168
bucket_width=1m: default: 60, max: 1440
page
string

Optional
A cursor for use in pagination. Corresponding to the next_page field from the previous response.

Returns
A list of paginated, time bucketed Audio speeches usage objects.

Example request
curl "https://api.openai.com/v1/organization/usage/audio_speeches?start_time=1730419200&limit=1" \
-H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
-H "Content-Type: application/json"
Response
{
    "object": "page",
    "data": [
        {
            "object": "bucket",
            "start_time": 1730419200,
            "end_time": 1730505600,
            "results": [
                {
                    "object": "organization.usage.audio_speeches.result",
                    "characters": 45,
                    "num_model_requests": 1,
                    "project_id": null,
                    "user_id": null,
                    "api_key_id": null,
                    "model": null
                }
            ]
        }
    ],
    "has_more": false,
    "next_page": null
}
Audio speeches usage object
The aggregated audio speeches usage details of the specific time bucket.

object
string

characters
integer

The number of characters processed.

num_model_requests
integer

The count of requests made to the model.

project_id
string or null

When group_by=project_id, this field provides the project ID of the grouped usage result.

user_id
string or null

When group_by=user_id, this field provides the user ID of the grouped usage result.

api_key_id
string or null

When group_by=api_key_id, this field provides the API key ID of the grouped usage result.

model
string or null

When group_by=model, this field provides the model name of the grouped usage result.

OBJECT Audio speeches usage object
{
    "object": "organization.usage.audio_speeches.result",
    "characters": 45,
    "num_model_requests": 1,
    "project_id": "proj_abc",
    "user_id": "user-abc",
    "api_key_id": "key_abc",
    "model": "tts-1"
}
Audio transcriptions
get
 
https://api.openai.com/v1/organization/usage/audio_transcriptions
Get audio transcriptions usage details for the organization.

Query parameters
start_time
integer

Required
Start time (Unix seconds) of the query time range, inclusive.

end_time
integer

Optional
End time (Unix seconds) of the query time range, exclusive.

bucket_width
string

Optional
Defaults to 1d
Width of each time bucket in response. Currently 1m, 1h and 1d are supported, default to 1d.

project_ids
array

Optional
Return only usage for these projects.

user_ids
array

Optional
Return only usage for these users.

api_key_ids
array

Optional
Return only usage for these API keys.

models
array

Optional
Return only usage for these models.

group_by
array

Optional
Group the usage data by the specified fields. Support fields include project_id, user_id, api_key_id, model or any combination of them.

limit
integer

Optional
Specifies the number of buckets to return.

bucket_width=1d: default: 7, max: 31
bucket_width=1h: default: 24, max: 168
bucket_width=1m: default: 60, max: 1440
page
string

Optional
A cursor for use in pagination. Corresponding to the next_page field from the previous response.

Returns
A list of paginated, time bucketed Audio transcriptions usage objects.

Example request
curl "https://api.openai.com/v1/organization/usage/audio_transcriptions?start_time=1730419200&limit=1" \
-H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
-H "Content-Type: application/json"
Response
{
    "object": "page",
    "data": [
        {
            "object": "bucket",
            "start_time": 1730419200,
            "end_time": 1730505600,
            "results": [
                {
                    "object": "organization.usage.audio_transcriptions.result",
                    "seconds": 20,
                    "num_model_requests": 1,
                    "project_id": null,
                    "user_id": null,
                    "api_key_id": null,
                    "model": null
                }
            ]
        }
    ],
    "has_more": false,
    "next_page": null
}
Audio transcriptions usage object
The aggregated audio transcriptions usage details of the specific time bucket.

object
string

seconds
integer

The number of seconds processed.

num_model_requests
integer

The count of requests made to the model.

project_id
string or null

When group_by=project_id, this field provides the project ID of the grouped usage result.

user_id
string or null

When group_by=user_id, this field provides the user ID of the grouped usage result.

api_key_id
string or null

When group_by=api_key_id, this field provides the API key ID of the grouped usage result.

model
string or null

When group_by=model, this field provides the model name of the grouped usage result.

OBJECT Audio transcriptions usage object
{
    "object": "organization.usage.audio_transcriptions.result",
    "seconds": 10,
    "num_model_requests": 1,
    "project_id": "proj_abc",
    "user_id": "user-abc",
    "api_key_id": "key_abc",
    "model": "tts-1"
}
Vector stores
get
 
https://api.openai.com/v1/organization/usage/vector_stores
Get vector stores usage details for the organization.

Query parameters
start_time
integer

Required
Start time (Unix seconds) of the query time range, inclusive.

end_time
integer

Optional
End time (Unix seconds) of the query time range, exclusive.

bucket_width
string

Optional
Defaults to 1d
Width of each time bucket in response. Currently 1m, 1h and 1d are supported, default to 1d.

project_ids
array

Optional
Return only usage for these projects.

group_by
array

Optional
Group the usage data by the specified fields. Support fields include project_id.

limit
integer

Optional
Specifies the number of buckets to return.

bucket_width=1d: default: 7, max: 31
bucket_width=1h: default: 24, max: 168
bucket_width=1m: default: 60, max: 1440
page
string

Optional
A cursor for use in pagination. Corresponding to the next_page field from the previous response.

Returns
A list of paginated, time bucketed Vector stores usage objects.

Example request
curl "https://api.openai.com/v1/organization/usage/vector_stores?start_time=1730419200&limit=1" \
-H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
-H "Content-Type: application/json"
Response
{
    "object": "page",
    "data": [
        {
            "object": "bucket",
            "start_time": 1730419200,
            "end_time": 1730505600,
            "results": [
                {
                    "object": "organization.usage.vector_stores.result",
                    "usage_bytes": 1024,
                    "project_id": null
                }
            ]
        }
    ],
    "has_more": false,
    "next_page": null
}
Vector stores usage object
The aggregated vector stores usage details of the specific time bucket.

object
string

usage_bytes
integer

The vector stores usage in bytes.

project_id
string or null

When group_by=project_id, this field provides the project ID of the grouped usage result.

OBJECT Vector stores usage object
{
    "object": "organization.usage.vector_stores.result",
    "usage_bytes": 1024,
    "project_id": "proj_abc"
}
Code interpreter sessions
get
 
https://api.openai.com/v1/organization/usage/code_interpreter_sessions
Get code interpreter sessions usage details for the organization.

Query parameters
start_time
integer

Required
Start time (Unix seconds) of the query time range, inclusive.

end_time
integer

Optional
End time (Unix seconds) of the query time range, exclusive.

bucket_width
string

Optional
Defaults to 1d
Width of each time bucket in response. Currently 1m, 1h and 1d are supported, default to 1d.

project_ids
array

Optional
Return only usage for these projects.

group_by
array

Optional
Group the usage data by the specified fields. Support fields include project_id.

limit
integer

Optional
Specifies the number of buckets to return.

bucket_width=1d: default: 7, max: 31
bucket_width=1h: default: 24, max: 168
bucket_width=1m: default: 60, max: 1440
page
string

Optional
A cursor for use in pagination. Corresponding to the next_page field from the previous response.

Returns
A list of paginated, time bucketed Code interpreter sessions usage objects.

Example request
curl "https://api.openai.com/v1/organization/usage/code_interpreter_sessions?start_time=1730419200&limit=1" \
-H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
-H "Content-Type: application/json"
Response
{
    "object": "page",
    "data": [
        {
            "object": "bucket",
            "start_time": 1730419200,
            "end_time": 1730505600,
            "results": [
                {
                    "object": "organization.usage.code_interpreter_sessions.result",
                    "num_sessions": 1,
                    "project_id": null
                }
            ]
        }
    ],
    "has_more": false,
    "next_page": null
}
Code interpreter sessions usage object
The aggregated code interpreter sessions usage details of the specific time bucket.

object
string

num_sessions
integer

The number of code interpreter sessions.

project_id
string or null

When group_by=project_id, this field provides the project ID of the grouped usage result.

OBJECT Code interpreter sessions usage object
{
    "object": "organization.usage.code_interpreter_sessions.result",
    "num_sessions": 1,
    "project_id": "proj_abc"
}
Costs
get
 
https://api.openai.com/v1/organization/costs
Get costs details for the organization.

Query parameters
start_time
integer

Required
Start time (Unix seconds) of the query time range, inclusive.

end_time
integer

Optional
End time (Unix seconds) of the query time range, exclusive.

bucket_width
string

Optional
Defaults to 1d
Width of each time bucket in response. Currently only 1d is supported, default to 1d.

project_ids
array

Optional
Return only costs for these projects.

group_by
array

Optional
Group the costs by the specified fields. Support fields include project_id, line_item and any combination of them.

limit
integer

Optional
Defaults to 7
A limit on the number of buckets to be returned. Limit can range between 1 and 180, and the default is 7.

page
string

Optional
A cursor for use in pagination. Corresponding to the next_page field from the previous response.

Returns
A list of paginated, time bucketed Costs objects.

Example request
curl "https://api.openai.com/v1/organization/costs?start_time=1730419200&limit=1" \
-H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
-H "Content-Type: application/json"
Response
{
    "object": "page",
    "data": [
        {
            "object": "bucket",
            "start_time": 1730419200,
            "end_time": 1730505600,
            "results": [
                {
                    "object": "organization.costs.result",
                    "amount": {
                        "value": 0.06,
                        "currency": "usd"
                    },
                    "line_item": null,
                    "project_id": null
                }
            ]
        }
    ],
    "has_more": false,
    "next_page": null
}
Costs object
The aggregated costs details of the specific time bucket.

object
string

amount
object

The monetary value in its associated currency.


Show properties
line_item
string or null

When group_by=line_item, this field provides the line item of the grouped costs result.

project_id
string or null

When group_by=project_id, this field provides the project ID of the grouped costs result.

OBJECT Costs object
{
    "object": "organization.costs.result",
    "amount": {
      "value": 0.06,
      "currency": "usd"
    },
    "line_item": "Image models",
    "project_id": "proj_abc"
}
Realtime
Beta
Communicate with a GPT-4o class model in real time using WebRTC or WebSockets. Supports text and audio inputs and ouputs, along with audio transcriptions. Learn more about the Realtime API.

Session tokens
REST API endpoint to generate ephemeral session tokens for use in client-side applications.

Create session
post
 
https://api.openai.com/v1/realtime/sessions
Create an ephemeral API token for use in client-side applications with the Realtime API. Can be configured with the same session parameters as the session.update client event.

It responds with a session object, plus a client_secret key which contains a usable ephemeral API token that can be used to authenticate browser clients for the Realtime API.

Request body
modalities
Optional
The set of modalities the model can respond with. To disable audio, set this to ["text"].

model
string

Optional
The Realtime model used for this session.

instructions
string

Optional
The default system instructions (i.e. system message) prepended to model calls. This field allows the client to guide the model on desired responses. The model can be instructed on response content and format, (e.g. "be extremely succinct", "act friendly", "here are examples of good responses") and on audio behavior (e.g. "talk quickly", "inject emotion into your voice", "laugh frequently"). The instructions are not guaranteed to be followed by the model, but they provide guidance to the model on the desired behavior.

Note that the server sets default instructions which will be used if this field is not set and are visible in the session.created event at the start of the session.

voice
string

Optional
The voice the model uses to respond. Voice cannot be changed during the session once the model has responded with audio at least once. Current voice options are alloy, ash, ballad, coral, echo sage, shimmer and verse.

input_audio_format
string

Optional
The format of input audio. Options are pcm16, g711_ulaw, or g711_alaw. For pcm16, input audio must be 16-bit PCM at a 24kHz sample rate, single channel (mono), and little-endian byte order.

output_audio_format
string

Optional
The format of output audio. Options are pcm16, g711_ulaw, or g711_alaw. For pcm16, output audio is sampled at a rate of 24kHz.

input_audio_transcription
object

Optional
Configuration for input audio transcription, defaults to off and can be set to null to turn off once on. Input audio transcription is not native to the model, since the model consumes audio directly. Transcription runs asynchronously through OpenAI Whisper transcription and should be treated as rough guidance rather than the representation understood by the model. The client can optionally set the language and prompt for transcription, these fields will be passed to the Whisper API.


Show properties
turn_detection
object

Optional
Configuration for turn detection. Can be set to null to turn off. Server VAD means that the model will detect the start and end of speech based on audio volume and respond at the end of user speech.


Show properties
tools
array

Optional
Tools (functions) available to the model.


Show properties
tool_choice
string

Optional
How the model chooses tools. Options are auto, none, required, or specify a function.

temperature
number

Optional
Sampling temperature for the model, limited to [0.6, 1.2]. Defaults to 0.8.

max_response_output_tokens
integer or "inf"

Optional
Maximum number of output tokens for a single assistant response, inclusive of tool calls. Provide an integer between 1 and 4096 to limit output tokens, or inf for the maximum available tokens for a given model. Defaults to inf.

Returns
The created Realtime session object, plus an ephemeral key

Example request
curl -X POST https://api.openai.com/v1/realtime/sessions \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -d '{
    "model": "gpt-4o-realtime-preview-2024-12-17",
    "modalities": ["audio", "text"],
    "instructions": "You are a friendly assistant."
  }'
Response
{
  "id": "sess_001",
  "object": "realtime.session",
  "model": "gpt-4o-realtime-preview-2024-12-17",
  "modalities": ["audio", "text"],
  "instructions": "You are a friendly assistant.",
  "voice": "alloy",
  "input_audio_format": "pcm16",
  "output_audio_format": "pcm16",
  "input_audio_transcription": {
      "model": "whisper-1"
  },
  "turn_detection": null,
  "tools": [],
  "tool_choice": "none",
  "temperature": 0.7,
  "max_response_output_tokens": 200,
  "client_secret": {
    "value": "ek_abc123", 
    "expires_at": 1234567890
  }
}
The session object
A new Realtime session configuration, with an ephermeral key. Default TTL for keys is one minute.

client_secret
object

Ephemeral key returned by the API.


Show properties
modalities
The set of modalities the model can respond with. To disable audio, set this to ["text"].

instructions
string

The default system instructions (i.e. system message) prepended to model calls. This field allows the client to guide the model on desired responses. The model can be instructed on response content and format, (e.g. "be extremely succinct", "act friendly", "here are examples of good responses") and on audio behavior (e.g. "talk quickly", "inject emotion into your voice", "laugh frequently"). The instructions are not guaranteed to be followed by the model, but they provide guidance to the model on the desired behavior.

Note that the server sets default instructions which will be used if this field is not set and are visible in the session.created event at the start of the session.

voice
string

The voice the model uses to respond. Voice cannot be changed during the session once the model has responded with audio at least once. Current voice options are alloy, ash, ballad, coral, echo sage, shimmer and verse.

input_audio_format
string

The format of input audio. Options are pcm16, g711_ulaw, or g711_alaw.

output_audio_format
string

The format of output audio. Options are pcm16, g711_ulaw, or g711_alaw.

input_audio_transcription
object

Configuration for input audio transcription, defaults to off and can be set to null to turn off once on. Input audio transcription is not native to the model, since the model consumes audio directly. Transcription runs asynchronously through Whisper and should be treated as rough guidance rather than the representation understood by the model.


Show properties
turn_detection
object

Configuration for turn detection. Can be set to null to turn off. Server VAD means that the model will detect the start and end of speech based on audio volume and respond at the end of user speech.


Show properties
tools
array

Tools (functions) available to the model.


Show properties
tool_choice
string

How the model chooses tools. Options are auto, none, required, or specify a function.

temperature
number

Sampling temperature for the model, limited to [0.6, 1.2]. Defaults to 0.8.

max_response_output_tokens
integer or "inf"

Maximum number of output tokens for a single assistant response, inclusive of tool calls. Provide an integer between 1 and 4096 to limit output tokens, or inf for the maximum available tokens for a given model. Defaults to inf.

OBJECT The session object
{
  "id": "sess_001",
  "object": "realtime.session",
  "model": "gpt-4o-realtime-preview-2024-12-17",
  "modalities": ["audio", "text"],
  "instructions": "You are a friendly assistant.",
  "voice": "alloy",
  "input_audio_format": "pcm16",
  "output_audio_format": "pcm16",
  "input_audio_transcription": {
      "model": "whisper-1"
  },
  "turn_detection": null,
  "tools": [],
  "tool_choice": "none",
  "temperature": 0.7,
  "max_response_output_tokens": 200,
  "client_secret": {
    "value": "ek_abc123", 
    "expires_at": 1234567890
  }
}
Client events
These are events that the OpenAI Realtime WebSocket server will accept from the client.

session.update
Send this event to update the sessions default configuration. The client may send this event at any time to update any field, except for voice. However, note that once a session has been initialized with a particular model, it cant be changed to another model using session.update.

When the server receives a session.update, it will respond with a session.updated event showing the full, effective configuration. Only the fields that are present are updated. To clear a field like instructions, pass an empty string.

event_id
string

Optional client-generated ID used to identify this event.

type
string

The event type, must be session.update.

session
object

Realtime session object configuration.


Show properties
OBJECT session.update
{
    "event_id": "event_123",
    "type": "session.update",
    "session": {
        "modalities": ["text", "audio"],
        "instructions": "You are a helpful assistant.",
        "voice": "sage",
        "input_audio_format": "pcm16",
        "output_audio_format": "pcm16",
        "input_audio_transcription": {
            "model": "whisper-1"
        },
        "turn_detection": {
            "type": "server_vad",
            "threshold": 0.5,
            "prefix_padding_ms": 300,
            "silence_duration_ms": 500,
            "create_response": true
        },
        "tools": [
            {
                "type": "function",
                "name": "get_weather",
                "description": "Get the current weather...",
                "parameters": {
                    "type": "object",
                    "properties": {
                        "location": { "type": "string" }
                    },
                    "required": ["location"]
                }
            }
        ],
        "tool_choice": "auto",
        "temperature": 0.8,
        "max_response_output_tokens": "inf"
    }
}
input_audio_buffer.append
Send this event to append audio bytes to the input audio buffer. The audio buffer is temporary storage you can write to and later commit. In Server VAD mode, the audio buffer is used to detect speech and the server will decide when to commit. When Server VAD is disabled, you must commit the audio buffer manually.

The client may choose how much audio to place in each event up to a maximum of 15 MiB, for example streaming smaller chunks from the client may allow the VAD to be more responsive. Unlike made other client events, the server will not send a confirmation response to this event.

event_id
string

Optional client-generated ID used to identify this event.

type
string

The event type, must be input_audio_buffer.append.

audio
string

Base64-encoded audio bytes. This must be in the format specified by the input_audio_format field in the session configuration.

OBJECT input_audio_buffer.append
{
    "event_id": "event_456",
    "type": "input_audio_buffer.append",
    "audio": "Base64EncodedAudioData"
}
input_audio_buffer.commit
Send this event to commit the user input audio buffer, which will create a new user message item in the conversation. This event will produce an error if the input audio buffer is empty. When in Server VAD mode, the client does not need to send this event, the server will commit the audio buffer automatically.

Committing the input audio buffer will trigger input audio transcription (if enabled in session configuration), but it will not create a response from the model. The server will respond with an input_audio_buffer.committed event.

event_id
string

Optional client-generated ID used to identify this event.

type
string

The event type, must be input_audio_buffer.commit.

OBJECT input_audio_buffer.commit
{
    "event_id": "event_789",
    "type": "input_audio_buffer.commit"
}
input_audio_buffer.clear
Send this event to clear the audio bytes in the buffer. The server will respond with an input_audio_buffer.cleared event.

event_id
string

Optional client-generated ID used to identify this event.

type
string

The event type, must be input_audio_buffer.clear.

OBJECT input_audio_buffer.clear
{
    "event_id": "event_012",
    "type": "input_audio_buffer.clear"
}
conversation.item.create
Add a new Item to the Conversation's context, including messages, function calls, and function call responses. This event can be used both to populate a "history" of the conversation and to add new items mid-stream, but has the current limitation that it cannot populate assistant audio messages.

If successful, the server will respond with a conversation.item.created event, otherwise an error event will be sent.

event_id
string

Optional client-generated ID used to identify this event.

type
string

The event type, must be conversation.item.create.

previous_item_id
string

The ID of the preceding item after which the new item will be inserted. If not set, the new item will be appended to the end of the conversation. If set to root, the new item will be added to the beginning of the conversation. If set to an existing ID, it allows an item to be inserted mid-conversation. If the ID cannot be found, an error will be returned and the item will not be added.

item
object

The item to add to the conversation.


Show properties
OBJECT conversation.item.create
{
    "event_id": "event_345",
    "type": "conversation.item.create",
    "previous_item_id": null,
    "item": {
        "id": "msg_001",
        "type": "message",
        "role": "user",
        "content": [
            {
                "type": "input_text",
                "text": "Hello, how are you?"
            }
        ]
    }
}
conversation.item.truncate
Send this event to truncate a previous assistant messages audio. The server will produce audio faster than realtime, so this event is useful when the user interrupts to truncate audio that has already been sent to the client but not yet played. This will synchronize the server's understanding of the audio with the client's playback.

Truncating audio will delete the server-side text transcript to ensure there is not text in the context that hasn't been heard by the user.

If successful, the server will respond with a conversation.item.truncated event.

event_id
string

Optional client-generated ID used to identify this event.

type
string

The event type, must be conversation.item.truncate.

item_id
string

The ID of the assistant message item to truncate. Only assistant message items can be truncated.

content_index
integer

The index of the content part to truncate. Set this to 0.

audio_end_ms
integer

Inclusive duration up to which audio is truncated, in milliseconds. If the audio_end_ms is greater than the actual audio duration, the server will respond with an error.

OBJECT conversation.item.truncate
{
    "event_id": "event_678",
    "type": "conversation.item.truncate",
    "item_id": "msg_002",
    "content_index": 0,
    "audio_end_ms": 1500
}
conversation.item.delete
Send this event when you want to remove any item from the conversation history. The server will respond with a conversation.item.deleted event, unless the item does not exist in the conversation history, in which case the server will respond with an error.

event_id
string

Optional client-generated ID used to identify this event.

type
string

The event type, must be conversation.item.delete.

item_id
string

The ID of the item to delete.

OBJECT conversation.item.delete
{
    "event_id": "event_901",
    "type": "conversation.item.delete",
    "item_id": "msg_003"
}
response.create
This event instructs the server to create a Response, which means triggering model inference. When in Server VAD mode, the server will create Responses automatically.

A Response will include at least one Item, and may have two, in which case the second will be a function call. These Items will be appended to the conversation history.

The server will respond with a response.created event, events for Items and content created, and finally a response.done event to indicate the Response is complete.

The response.create event includes inference configuration like instructions, and temperature. These fields will override the Session's configuration for this Response only.

event_id
string

Optional client-generated ID used to identify this event.

type
string

The event type, must be response.create.

response
object

Create a new Realtime response with these parameters


Show properties
OBJECT response.create
{
    "event_id": "event_234",
    "type": "response.create",
    "response": {
        "modalities": ["text", "audio"],
        "instructions": "Please assist the user.",
        "voice": "sage",
        "output_audio_format": "pcm16",
        "tools": [
            {
                "type": "function",
                "name": "calculate_sum",
                "description": "Calculates the sum of two numbers.",
                "parameters": {
                    "type": "object",
                    "properties": {
                        "a": { "type": "number" },
                        "b": { "type": "number" }
                    },
                    "required": ["a", "b"]
                }
            }
        ],
        "tool_choice": "auto",
        "temperature": 0.8,
        "max_output_tokens": 1024
    }
}
response.cancel
Send this event to cancel an in-progress response. The server will respond with a response.cancelled event or an error if there is no response to cancel.

event_id
string

Optional client-generated ID used to identify this event.

type
string

The event type, must be response.cancel.

response_id
string

A specific response ID to cancel - if not provided, will cancel an in-progress response in the default conversation.

OBJECT response.cancel
{
    "event_id": "event_567",
    "type": "response.cancel"
}
Server events
These are events emitted from the OpenAI Realtime WebSocket server to the client.

error
Returned when an error occurs, which could be a client problem or a server problem. Most errors are recoverable and the session will stay open, we recommend to implementors to monitor and log error messages by default.

event_id
string

The unique ID of the server event.

type
string

The event type, must be error.

error
object

Details of the error.


Show properties
OBJECT error
{
    "event_id": "event_890",
    "type": "error",
    "error": {
        "type": "invalid_request_error",
        "code": "invalid_event",
        "message": "The 'type' field is missing.",
        "param": null,
        "event_id": "event_567"
    }
}
session.created
Returned when a Session is created. Emitted automatically when a new connection is established as the first server event. This event will contain the default Session configuration.

event_id
string

The unique ID of the server event.

type
string

The event type, must be session.created.

session
object

Realtime session object configuration.


Show properties
OBJECT session.created
{
    "event_id": "event_1234",
    "type": "session.created",
    "session": {
        "id": "sess_001",
        "object": "realtime.session",
        "model": "gpt-4o-realtime-preview-2024-12-17",
        "modalities": ["text", "audio"],
        "instructions": "...model instructions here...",
        "voice": "sage",
        "input_audio_format": "pcm16",
        "output_audio_format": "pcm16",
        "input_audio_transcription": null,
        "turn_detection": {
            "type": "server_vad",
            "threshold": 0.5,
            "prefix_padding_ms": 300,
            "silence_duration_ms": 200
        },
        "tools": [],
        "tool_choice": "auto",
        "temperature": 0.8,
        "max_response_output_tokens": "inf"
    }
}
session.updated
Returned when a session is updated with a session.update event, unless there is an error.

event_id
string

The unique ID of the server event.

type
string

The event type, must be session.updated.

session
object

Realtime session object configuration.


Show properties
OBJECT session.updated
{
    "event_id": "event_5678",
    "type": "session.updated",
    "session": {
        "id": "sess_001",
        "object": "realtime.session",
        "model": "gpt-4o-realtime-preview-2024-12-17",
        "modalities": ["text"],
        "instructions": "New instructions",
        "voice": "sage",
        "input_audio_format": "pcm16",
        "output_audio_format": "pcm16",
        "input_audio_transcription": {
            "model": "whisper-1"
        },
        "turn_detection": null,
        "tools": [],
        "tool_choice": "none",
        "temperature": 0.7,
        "max_response_output_tokens": 200
    }
}
conversation.created
Returned when a conversation is created. Emitted right after session creation.

event_id
string

The unique ID of the server event.

type
string

The event type, must be conversation.created.

conversation
object

The conversation resource.


Show properties
OBJECT conversation.created
{
    "event_id": "event_9101",
    "type": "conversation.created",
    "conversation": {
        "id": "conv_001",
        "object": "realtime.conversation"
    }
}
conversation.item.created
Returned when a conversation item is created. There are several scenarios that produce this event:

The server is generating a Response, which if successful will produce either one or two Items, which will be of type message (role assistant) or type function_call.
The input audio buffer has been committed, either by the client or the server (in server_vad mode). The server will take the content of the input audio buffer and add it to a new user message Item.
The client has sent a conversation.item.create event to add a new Item to the Conversation.
event_id
string

The unique ID of the server event.

type
string

The event type, must be conversation.item.created.

previous_item_id
string

The ID of the preceding item in the Conversation context, allows the client to understand the order of the conversation.

item
object

The item to add to the conversation.


Show properties
OBJECT conversation.item.created
{
    "event_id": "event_1920",
    "type": "conversation.item.created",
    "previous_item_id": "msg_002",
    "item": {
        "id": "msg_003",
        "object": "realtime.item",
        "type": "message",
        "status": "completed",
        "role": "user",
        "content": [
            {
                "type": "input_audio",
                "transcript": "hello how are you",
                "audio": "base64encodedaudio=="
            }
        ]
    }
}
conversation.item.input_audio_transcription.completed
This event is the output of audio transcription for user audio written to the user audio buffer. Transcription begins when the input audio buffer is committed by the client or server (in server_vad mode). Transcription runs asynchronously with Response creation, so this event may come before or after the Response events.

Realtime API models accept audio natively, and thus input transcription is a separate process run on a separate ASR (Automatic Speech Recognition) model, currently always whisper-1. Thus the transcript may diverge somewhat from the model's interpretation, and should be treated as a rough guide.

event_id
string

The unique ID of the server event.

type
string

The event type, must be conversation.item.input_audio_transcription.completed.

item_id
string

The ID of the user message item containing the audio.

content_index
integer

The index of the content part containing the audio.

transcript
string

The transcribed text.

OBJECT conversation.item.input_audio_transcription.completed
{
    "event_id": "event_2122",
    "type": "conversation.item.input_audio_transcription.completed",
    "item_id": "msg_003",
    "content_index": 0,
    "transcript": "Hello, how are you?"
}
conversation.item.input_audio_transcription.failed
Returned when input audio transcription is configured, and a transcription request for a user message failed. These events are separate from other error events so that the client can identify the related Item.

event_id
string

The unique ID of the server event.

type
string

The event type, must be conversation.item.input_audio_transcription.failed.

item_id
string

The ID of the user message item.

content_index
integer

The index of the content part containing the audio.

error
object

Details of the transcription error.


Show properties
OBJECT conversation.item.input_audio_transcription.failed
{
    "event_id": "event_2324",
    "type": "conversation.item.input_audio_transcription.failed",
    "item_id": "msg_003",
    "content_index": 0,
    "error": {
        "type": "transcription_error",
        "code": "audio_unintelligible",
        "message": "The audio could not be transcribed.",
        "param": null
    }
}
conversation.item.truncated
Returned when an earlier assistant audio message item is truncated by the client with a conversation.item.truncate event. This event is used to synchronize the server's understanding of the audio with the client's playback.

This action will truncate the audio and remove the server-side text transcript to ensure there is no text in the context that hasn't been heard by the user.

event_id
string

The unique ID of the server event.

type
string

The event type, must be conversation.item.truncated.

item_id
string

The ID of the assistant message item that was truncated.

content_index
integer

The index of the content part that was truncated.

audio_end_ms
integer

The duration up to which the audio was truncated, in milliseconds.

OBJECT conversation.item.truncated
{
    "event_id": "event_2526",
    "type": "conversation.item.truncated",
    "item_id": "msg_004",
    "content_index": 0,
    "audio_end_ms": 1500
}
conversation.item.deleted
Returned when an item in the conversation is deleted by the client with a conversation.item.delete event. This event is used to synchronize the server's understanding of the conversation history with the client's view.

event_id
string

The unique ID of the server event.

type
string

The event type, must be conversation.item.deleted.

item_id
string

The ID of the item that was deleted.

OBJECT conversation.item.deleted
{
    "event_id": "event_2728",
    "type": "conversation.item.deleted",
    "item_id": "msg_005"
}
input_audio_buffer.committed
Returned when an input audio buffer is committed, either by the client or automatically in server VAD mode. The item_id property is the ID of the user message item that will be created, thus a conversation.item.created event will also be sent to the client.

event_id
string

The unique ID of the server event.

type
string

The event type, must be input_audio_buffer.committed.

previous_item_id
string

The ID of the preceding item after which the new item will be inserted.

item_id
string

The ID of the user message item that will be created.

OBJECT input_audio_buffer.committed
{
    "event_id": "event_1121",
    "type": "input_audio_buffer.committed",
    "previous_item_id": "msg_001",
    "item_id": "msg_002"
}
input_audio_buffer.cleared
Returned when the input audio buffer is cleared by the client with a input_audio_buffer.clear event.

event_id
string

The unique ID of the server event.

type
string

The event type, must be input_audio_buffer.cleared.

OBJECT input_audio_buffer.cleared
{
    "event_id": "event_1314",
    "type": "input_audio_buffer.cleared"
}
input_audio_buffer.speech_started
Sent by the server when in server_vad mode to indicate that speech has been detected in the audio buffer. This can happen any time audio is added to the buffer (unless speech is already detected). The client may want to use this event to interrupt audio playback or provide visual feedback to the user.

The client should expect to receive a input_audio_buffer.speech_stopped event when speech stops. The item_id property is the ID of the user message item that will be created when speech stops and will also be included in the input_audio_buffer.speech_stopped event (unless the client manually commits the audio buffer during VAD activation).

event_id
string

The unique ID of the server event.

type
string

The event type, must be input_audio_buffer.speech_started.

audio_start_ms
integer

Milliseconds from the start of all audio written to the buffer during the session when speech was first detected. This will correspond to the beginning of audio sent to the model, and thus includes the prefix_padding_ms configured in the Session.

item_id
string

The ID of the user message item that will be created when speech stops.

OBJECT input_audio_buffer.speech_started
{
    "event_id": "event_1516",
    "type": "input_audio_buffer.speech_started",
    "audio_start_ms": 1000,
    "item_id": "msg_003"
}
input_audio_buffer.speech_stopped
Returned in server_vad mode when the server detects the end of speech in the audio buffer. The server will also send an conversation.item.created event with the user message item that is created from the audio buffer.

event_id
string

The unique ID of the server event.

type
string

The event type, must be input_audio_buffer.speech_stopped.

audio_end_ms
integer

Milliseconds since the session started when speech stopped. This will correspond to the end of audio sent to the model, and thus includes the min_silence_duration_ms configured in the Session.

item_id
string

The ID of the user message item that will be created.

OBJECT input_audio_buffer.speech_stopped
{
    "event_id": "event_1718",
    "type": "input_audio_buffer.speech_stopped",
    "audio_end_ms": 2000,
    "item_id": "msg_003"
}
response.created
Returned when a new Response is created. The first event of response creation, where the response is in an initial state of in_progress.

event_id
string

The unique ID of the server event.

type
string

The event type, must be response.created.

response
object

The response resource.


Show properties
OBJECT response.created
{
    "event_id": "event_2930",
    "type": "response.created",
    "response": {
        "id": "resp_001",
        "object": "realtime.response",
        "status": "in_progress",
        "status_details": null,
        "output": [],
        "usage": null
    }
}
response.done
Returned when a Response is done streaming. Always emitted, no matter the final state. The Response object included in the response.done event will include all output Items in the Response but will omit the raw audio data.

event_id
string

The unique ID of the server event.

type
string

The event type, must be response.done.

response
object

The response resource.


Show properties
OBJECT response.done
{
    "event_id": "event_3132",
    "type": "response.done",
    "response": {
        "id": "resp_001",
        "object": "realtime.response",
        "status": "completed",
        "status_details": null,
        "output": [
            {
                "id": "msg_006",
                "object": "realtime.item",
                "type": "message",
                "status": "completed",
                "role": "assistant",
                "content": [
                    {
                        "type": "text",
                        "text": "Sure, how can I assist you today?"
                    }
                ]
            }
        ],
        "usage": {
            "total_tokens":275,
            "input_tokens":127,
            "output_tokens":148,
            "input_token_details": {
                "cached_tokens":384,
                "text_tokens":119,
                "audio_tokens":8,
                "cached_tokens_details": {
                    "text_tokens": 128,
                    "audio_tokens": 256
                }
            },
            "output_token_details": {
              "text_tokens":36,
              "audio_tokens":112
            }
        }
    }
}
response.output_item.added
Returned when a new Item is created during Response generation.

event_id
string

The unique ID of the server event.

type
string

The event type, must be response.output_item.added.

response_id
string

The ID of the Response to which the item belongs.

output_index
integer

The index of the output item in the Response.

item
object

The item to add to the conversation.


Show properties
OBJECT response.output_item.added
{
    "event_id": "event_3334",
    "type": "response.output_item.added",
    "response_id": "resp_001",
    "output_index": 0,
    "item": {
        "id": "msg_007",
        "object": "realtime.item",
        "type": "message",
        "status": "in_progress",
        "role": "assistant",
        "content": []
    }
}
response.output_item.done
Returned when an Item is done streaming. Also emitted when a Response is interrupted, incomplete, or cancelled.

event_id
string

The unique ID of the server event.

type
string

The event type, must be response.output_item.done.

response_id
string

The ID of the Response to which the item belongs.

output_index
integer

The index of the output item in the Response.

item
object

The item to add to the conversation.


Show properties
OBJECT response.output_item.done
{
    "event_id": "event_3536",
    "type": "response.output_item.done",
    "response_id": "resp_001",
    "output_index": 0,
    "item": {
        "id": "msg_007",
        "object": "realtime.item",
        "type": "message",
        "status": "completed",
        "role": "assistant",
        "content": [
            {
                "type": "text",
                "text": "Sure, I can help with that."
            }
        ]
    }
}
response.content_part.added
Returned when a new content part is added to an assistant message item during response generation.

event_id
string

The unique ID of the server event.

type
string

The event type, must be response.content_part.added.

response_id
string

The ID of the response.

item_id
string

The ID of the item to which the content part was added.

output_index
integer

The index of the output item in the response.

content_index
integer

The index of the content part in the item's content array.

part
object

The content part that was added.


Show properties
OBJECT response.content_part.added
{
    "event_id": "event_3738",
    "type": "response.content_part.added",
    "response_id": "resp_001",
    "item_id": "msg_007",
    "output_index": 0,
    "content_index": 0,
    "part": {
        "type": "text",
        "text": ""
    }
}
response.content_part.done
Returned when a content part is done streaming in an assistant message item. Also emitted when a Response is interrupted, incomplete, or cancelled.

event_id
string

The unique ID of the server event.

type
string

The event type, must be response.content_part.done.

response_id
string

The ID of the response.

item_id
string

The ID of the item.

output_index
integer

The index of the output item in the response.

content_index
integer

The index of the content part in the item's content array.

part
object

The content part that is done.


Show properties
OBJECT response.content_part.done
{
    "event_id": "event_3940",
    "type": "response.content_part.done",
    "response_id": "resp_001",
    "item_id": "msg_007",
    "output_index": 0,
    "content_index": 0,
    "part": {
        "type": "text",
        "text": "Sure, I can help with that."
    }
}
response.text.delta
Returned when the text value of a "text" content part is updated.

event_id
string

The unique ID of the server event.

type
string

The event type, must be response.text.delta.

response_id
string

The ID of the response.

item_id
string

The ID of the item.

output_index
integer

The index of the output item in the response.

content_index
integer

The index of the content part in the item's content array.

delta
string

The text delta.

OBJECT response.text.delta
{
    "event_id": "event_4142",
    "type": "response.text.delta",
    "response_id": "resp_001",
    "item_id": "msg_007",
    "output_index": 0,
    "content_index": 0,
    "delta": "Sure, I can h"
}
response.text.done
Returned when the text value of a "text" content part is done streaming. Also emitted when a Response is interrupted, incomplete, or cancelled.

event_id
string

The unique ID of the server event.

type
string

The event type, must be response.text.done.

response_id
string

The ID of the response.

item_id
string

The ID of the item.

output_index
integer

The index of the output item in the response.

content_index
integer

The index of the content part in the item's content array.

text
string

The final text content.

OBJECT response.text.done
{
    "event_id": "event_4344",
    "type": "response.text.done",
    "response_id": "resp_001",
    "item_id": "msg_007",
    "output_index": 0,
    "content_index": 0,
    "text": "Sure, I can help with that."
}
response.audio_transcript.delta
Returned when the model-generated transcription of audio output is updated.

event_id
string

The unique ID of the server event.

type
string

The event type, must be response.audio_transcript.delta.

response_id
string

The ID of the response.

item_id
string

The ID of the item.

output_index
integer

The index of the output item in the response.

content_index
integer

The index of the content part in the item's content array.

delta
string

The transcript delta.

OBJECT response.audio_transcript.delta
{
    "event_id": "event_4546",
    "type": "response.audio_transcript.delta",
    "response_id": "resp_001",
    "item_id": "msg_008",
    "output_index": 0,
    "content_index": 0,
    "delta": "Hello, how can I a"
}
response.audio_transcript.done
Returned when the model-generated transcription of audio output is done streaming. Also emitted when a Response is interrupted, incomplete, or cancelled.

event_id
string

The unique ID of the server event.

type
string

The event type, must be response.audio_transcript.done.

response_id
string

The ID of the response.

item_id
string

The ID of the item.

output_index
integer

The index of the output item in the response.

content_index
integer

The index of the content part in the item's content array.

transcript
string

The final transcript of the audio.

OBJECT response.audio_transcript.done
{
    "event_id": "event_4748",
    "type": "response.audio_transcript.done",
    "response_id": "resp_001",
    "item_id": "msg_008",
    "output_index": 0,
    "content_index": 0,
    "transcript": "Hello, how can I assist you today?"
}
response.audio.delta
Returned when the model-generated audio is updated.

event_id
string

The unique ID of the server event.

type
string

The event type, must be response.audio.delta.

response_id
string

The ID of the response.

item_id
string

The ID of the item.

output_index
integer

The index of the output item in the response.

content_index
integer

The index of the content part in the item's content array.

delta
string

Base64-encoded audio data delta.

OBJECT response.audio.delta
{
    "event_id": "event_4950",
    "type": "response.audio.delta",
    "response_id": "resp_001",
    "item_id": "msg_008",
    "output_index": 0,
    "content_index": 0,
    "delta": "Base64EncodedAudioDelta"
}
response.audio.done
Returned when the model-generated audio is done. Also emitted when a Response is interrupted, incomplete, or cancelled.

event_id
string

The unique ID of the server event.

type
string

The event type, must be response.audio.done.

response_id
string

The ID of the response.

item_id
string

The ID of the item.

output_index
integer

The index of the output item in the response.

content_index
integer

The index of the content part in the item's content array.

OBJECT response.audio.done
{
    "event_id": "event_5152",
    "type": "response.audio.done",
    "response_id": "resp_001",
    "item_id": "msg_008",
    "output_index": 0,
    "content_index": 0
}
response.function_call_arguments.delta
Returned when the model-generated function call arguments are updated.

event_id
string

The unique ID of the server event.

type
string

The event type, must be response.function_call_arguments.delta.

response_id
string

The ID of the response.

item_id
string

The ID of the function call item.

output_index
integer

The index of the output item in the response.

call_id
string

The ID of the function call.

delta
string

The arguments delta as a JSON string.

OBJECT response.function_call_arguments.delta
{
    "event_id": "event_5354",
    "type": "response.function_call_arguments.delta",
    "response_id": "resp_002",
    "item_id": "fc_001",
    "output_index": 0,
    "call_id": "call_001",
    "delta": "{\"location\": \"San\""
}
response.function_call_arguments.done
Returned when the model-generated function call arguments are done streaming. Also emitted when a Response is interrupted, incomplete, or cancelled.

event_id
string

The unique ID of the server event.

type
string

The event type, must be response.function_call_arguments.done.

response_id
string

The ID of the response.

item_id
string

The ID of the function call item.

output_index
integer

The index of the output item in the response.

call_id
string

The ID of the function call.

arguments
string

The final arguments as a JSON string.

OBJECT response.function_call_arguments.done
{
    "event_id": "event_5556",
    "type": "response.function_call_arguments.done",
    "response_id": "resp_002",
    "item_id": "fc_001",
    "output_index": 0,
    "call_id": "call_001",
    "arguments": "{\"location\": \"San Francisco\"}"
}
rate_limits.updated
Emitted at the beginning of a Response to indicate the updated rate limits. When a Response is created some tokens will be "reserved" for the output tokens, the rate limits shown here reflect that reservation, which is then adjusted accordingly once the Response is completed.

event_id
string

The unique ID of the server event.

type
string

The event type, must be rate_limits.updated.

rate_limits
array

List of rate limit information.


Show properties
OBJECT rate_limits.updated
{
    "event_id": "event_5758",
    "type": "rate_limits.updated",
    "rate_limits": [
        {
            "name": "requests",
            "limit": 1000,
            "remaining": 999,
            "reset_seconds": 60
        },
        {
            "name": "tokens",
            "limit": 50000,
            "remaining": 49950,
            "reset_seconds": 60
        }
    ]
}
Completions
Legacy
Given a prompt, the model will return one or more predicted completions along with the probabilities of alternative tokens at each position. Most developer should use our Chat Completions API to leverage our best and newest models.

Create completion
Legacy
post
 
https://api.openai.com/v1/completions
Creates a completion for the provided prompt and parameters.

Request body
model
string

Required
ID of the model to use. You can use the List models API to see all of your available models, or see our Model overview for descriptions of them.

prompt
string or array

Required
The prompt(s) to generate completions for, encoded as a string, array of strings, array of tokens, or array of token arrays.

Note that <|endoftext|> is the document separator that the model sees during training, so if a prompt is not specified the model will generate as if from the beginning of a new document.

best_of
integer or null

Optional
Defaults to 1
Generates best_of completions server-side and returns the "best" (the one with the highest log probability per token). Results cannot be streamed.

When used with n, best_of controls the number of candidate completions and n specifies how many to return  best_of must be greater than n.

Note: Because this parameter generates many completions, it can quickly consume your token quota. Use carefully and ensure that you have reasonable settings for max_tokens and stop.

echo
boolean or null

Optional
Defaults to false
Echo back the prompt in addition to the completion

frequency_penalty
number or null

Optional
Defaults to 0
Number between -2.0 and 2.0. Positive values penalize new tokens based on their existing frequency in the text so far, decreasing the model's likelihood to repeat the same line verbatim.

See more information about frequency and presence penalties.

logit_bias
map

Optional
Defaults to null
Modify the likelihood of specified tokens appearing in the completion.

Accepts a JSON object that maps tokens (specified by their token ID in the GPT tokenizer) to an associated bias value from -100 to 100. You can use this tokenizer tool to convert text to token IDs. Mathematically, the bias is added to the logits generated by the model prior to sampling. The exact effect will vary per model, but values between -1 and 1 should decrease or increase likelihood of selection; values like -100 or 100 should result in a ban or exclusive selection of the relevant token.

As an example, you can pass {"50256": -100} to prevent the <|endoftext|> token from being generated.

logprobs
integer or null

Optional
Defaults to null
Include the log probabilities on the logprobs most likely output tokens, as well the chosen tokens. For example, if logprobs is 5, the API will return a list of the 5 most likely tokens. The API will always return the logprob of the sampled token, so there may be up to logprobs+1 elements in the response.

The maximum value for logprobs is 5.

max_tokens
integer or null

Optional
Defaults to 16
The maximum number of tokens that can be generated in the completion.

The token count of your prompt plus max_tokens cannot exceed the model's context length. Example Python code for counting tokens.

n
integer or null

Optional
Defaults to 1
How many completions to generate for each prompt.

Note: Because this parameter generates many completions, it can quickly consume your token quota. Use carefully and ensure that you have reasonable settings for max_tokens and stop.

presence_penalty
number or null

Optional
Defaults to 0
Number between -2.0 and 2.0. Positive values penalize new tokens based on whether they appear in the text so far, increasing the model's likelihood to talk about new topics.

See more information about frequency and presence penalties.

seed
integer or null

Optional
If specified, our system will make a best effort to sample deterministically, such that repeated requests with the same seed and parameters should return the same result.

Determinism is not guaranteed, and you should refer to the system_fingerprint response parameter to monitor changes in the backend.

stop
string / array / null

Optional
Defaults to null
Up to 4 sequences where the API will stop generating further tokens. The returned text will not contain the stop sequence.

stream
boolean or null

Optional
Defaults to false
Whether to stream back partial progress. If set, tokens will be sent as data-only server-sent events as they become available, with the stream terminated by a data: [DONE] message. Example Python code.

stream_options
object or null

Optional
Defaults to null
Options for streaming response. Only set this when you set stream: true.


Show properties
suffix
string or null

Optional
Defaults to null
The suffix that comes after a completion of inserted text.

This parameter is only supported for gpt-3.5-turbo-instruct.

temperature
number or null

Optional
Defaults to 1
What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic.

We generally recommend altering this or top_p but not both.

top_p
number or null

Optional
Defaults to 1
An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered.

We generally recommend altering this or temperature but not both.

user
string

Optional
A unique identifier representing your end-user, which can help OpenAI to monitor and detect abuse. Learn more.

Returns
Returns a completion object, or a sequence of completion objects if the request is streamed.


No streaming

Streaming
Example request
curl https://api.openai.com/v1/completions \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -d '{
    "model": "gpt-3.5-turbo-instruct",
    "prompt": "Say this is a test",
    "max_tokens": 7,
    "temperature": 0
  }'
Response
{
  "id": "cmpl-uqkvlQyYK7bGYrRHQ0eXlWi7",
  "object": "text_completion",
  "created": 1589478378,
  "model": "gpt-3.5-turbo-instruct",
  "system_fingerprint": "fp_44709d6fcb",
  "choices": [
    {
      "text": "\n\nThis is indeed a test",
      "index": 0,
      "logprobs": null,
      "finish_reason": "length"
    }
  ],
  "usage": {
    "prompt_tokens": 5,
    "completion_tokens": 7,
    "total_tokens": 12
  }
}
The completion object
Legacy
Represents a completion response from the API. Note: both the streamed and non-streamed response objects share the same shape (unlike the chat endpoint).

id
string

A unique identifier for the completion.

choices
array

The list of completion choices the model generated for the input prompt.


Show properties
created
integer

The Unix timestamp (in seconds) of when the completion was created.

model
string

The model used for completion.

system_fingerprint
string

This fingerprint represents the backend configuration that the model runs with.

Can be used in conjunction with the seed request parameter to understand when backend changes have been made that might impact determinism.

object
string

The object type, which is always "text_completion"

usage
object

Usage statistics for the completion request.


Show properties
OBJECT The completion object
{
  "id": "cmpl-uqkvlQyYK7bGYrRHQ0eXlWi7",
  "object": "text_completion",
  "created": 1589478378,
  "model": "gpt-4-turbo",
  "choices": [
    {
      "text": "\n\nThis is indeed a test",
      "index": 0,
      "logprobs": null,
      "finish_reason": "length"
    }
  ],
  "usage": {
    "prompt_tokens": 5,
    "completion_tokens": 7,
    "total_tokens": 12
  }
}
Assistants (v1)
Legacy
Build assistants that can call models and use tools to perform tasks.

Get started with the Assistants API

Create assistant (v1)
Legacy
post
 
https://api.openai.com/v1/assistants
Create an assistant with a model and instructions.

Request body
model
string

Required
ID of the model to use. You can use the List models API to see all of your available models, or see our Model overview for descriptions of them. type: string

name
string or null

Optional
The name of the assistant. The maximum length is 256 characters.

description
string or null

Optional
The description of the assistant. The maximum length is 512 characters.

instructions
string or null

Optional
The system instructions that the assistant uses. The maximum length is 256,000 characters.

tools
array

Optional
Defaults to []
A list of tool enabled on the assistant. There can be a maximum of 128 tools per assistant. Tools can be of types code_interpreter, retrieval, or function.


Show possible types
file_ids
array

Optional
Defaults to []
A list of file IDs attached to this assistant. There can be a maximum of 20 files attached to the assistant. Files are ordered by their creation date in ascending order.

metadata
map

Optional
Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maxium of 512 characters long.

temperature
number or null

Optional
Defaults to 1
What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic.

top_p
number or null

Optional
Defaults to 1
An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered.

We generally recommend altering this or temperature but not both.

response_format
string or object

Optional
Specifies the format that the model must output. Compatible with GPT-4o, GPT-4 Turbo, and all GPT-3.5 Turbo models since gpt-3.5-turbo-1106.

Setting to { "type": "json_object" } enables JSON mode, which guarantees the message the model generates is valid JSON.

Important: when using JSON mode, you must also instruct the model to produce JSON yourself via a system or user message. Without this, the model may generate an unending stream of whitespace until the generation reaches the token limit, resulting in a long-running and seemingly "stuck" request. Also note that the message content may be partially cut off if finish_reason="length", which indicates the generation exceeded max_tokens or the conversation exceeded the max context length.


Show possible types
Returns
An assistant object.


Code Interpreter

Files
Example request
curl "https://api.openai.com/v1/assistants" \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "OpenAI-Beta: assistants=v1" \
  -d '{
    "instructions": "You are a personal math tutor. When asked a question, write and run Python code to answer the question.",
    "name": "Math Tutor",
    "tools": [{"type": "code_interpreter"}],
    "model": "gpt-4-turbo"
  }'
Response
{
  "id": "asst_abc123",
  "object": "assistant",
  "created_at": 1698984975,
  "name": "Math Tutor",
  "description": null,
  "model": "gpt-4-turbo",
  "instructions": "You are a personal math tutor. When asked a question, write and run Python code to answer the question.",
  "tools": [
    {
      "type": "code_interpreter"
    }
  ],
  "file_ids": [],
  "metadata": {},
  "top_p": 1.0,
  "temperature": 1.0,
  "response_format": "auto"
}
Create assistant file (v1)
Legacy
post
 
https://api.openai.com/v1/assistants/{assistant_id}/files
Create an assistant file by attaching a File to an assistant.

Path parameters
assistant_id
string

Required
The ID of the assistant for which to create a File.

Request body
file_id
string

Required
A File ID (with purpose="assistants") that the assistant should use. Useful for tools like retrieval and code_interpreter that can access files.

Returns
An assistant file object.

Example request
curl https://api.openai.com/v1/assistants/asst_abc123/files \
    -H 'Authorization: Bearer $OPENAI_API_KEY"' \
    -H 'Content-Type: application/json' \
    -H 'OpenAI-Beta: assistants=v1' \
    -d '{
      "file_id": "file-abc123"
    }'
Response
{
  "id": "file-abc123",
  "object": "assistant.file",
  "created_at": 1699055364,
  "assistant_id": "asst_abc123"
}
List assistants (v1)
Legacy
get
 
https://api.openai.com/v1/assistants
Returns a list of assistants.

Query parameters
limit
integer

Optional
Defaults to 20
A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.

order
string

Optional
Defaults to desc
Sort order by the created_at timestamp of the objects. asc for ascending order and desc for descending order.

after
string

Optional
A cursor for use in pagination. after is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj_foo, your subsequent call can include after=obj_foo in order to fetch the next page of the list.

before
string

Optional
A cursor for use in pagination. before is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj_foo, your subsequent call can include before=obj_foo in order to fetch the previous page of the list.

Returns
A list of assistant objects.

Example request
curl "https://api.openai.com/v1/assistants?order=desc&limit=20" \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "OpenAI-Beta: assistants=v1"
Response
{
  "object": "list",
  "data": [
    {
      "id": "asst_abc123",
      "object": "assistant",
      "created_at": 1698982736,
      "name": "Coding Tutor",
      "description": null,
      "model": "gpt-4-turbo",
      "instructions": "You are a helpful assistant designed to make me better at coding!",
      "tools": [],
      "file_ids": [],
      "metadata": {},
      "top_p": 1.0,
      "temperature": 1.0,
      "response_format": "auto"
    },
    {
      "id": "asst_abc456",
      "object": "assistant",
      "created_at": 1698982718,
      "name": "My Assistant",
      "description": null,
      "model": "gpt-4-turbo",
      "instructions": "You are a helpful assistant designed to make me better at coding!",
      "tools": [],
      "file_ids": [],
      "metadata": {},
      "top_p": 1.0,
      "temperature": 1.0,
      "response_format": "auto"
    },
    {
      "id": "asst_abc789",
      "object": "assistant",
      "created_at": 1698982643,
      "name": null,
      "description": null,
      "model": "gpt-4-turbo",
      "instructions": null,
      "tools": [],
      "file_ids": [],
      "metadata": {},
      "top_p": 1.0,
      "temperature": 1.0,
      "response_format": "auto"
    }
  ],
  "first_id": "asst_abc123",
  "last_id": "asst_abc789",
  "has_more": false
}
List assistant files (v1)
Legacy
get
 
https://api.openai.com/v1/assistants/{assistant_id}/files
Returns a list of assistant files.

Path parameters
assistant_id
string

Required
The ID of the assistant the file belongs to.

Query parameters
limit
integer

Optional
Defaults to 20
A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.

order
string

Optional
Defaults to desc
Sort order by the created_at timestamp of the objects. asc for ascending order and desc for descending order.

after
string

Optional
A cursor for use in pagination. after is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj_foo, your subsequent call can include after=obj_foo in order to fetch the next page of the list.

before
string

Optional
A cursor for use in pagination. before is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj_foo, your subsequent call can include before=obj_foo in order to fetch the previous page of the list.

Returns
A list of assistant file objects.

Example request
curl https://api.openai.com/v1/assistants/asst_abc123/files \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -H "OpenAI-Beta: assistants=v1"
Response
{
  "object": "list",
  "data": [
    {
      "id": "file-abc123",
      "object": "assistant.file",
      "created_at": 1699060412,
      "assistant_id": "asst_abc123"
    },
    {
      "id": "file-abc456",
      "object": "assistant.file",
      "created_at": 1699060412,
      "assistant_id": "asst_abc123"
    }
  ],
  "first_id": "file-abc123",
  "last_id": "file-abc456",
  "has_more": false
}
Retrieve assistant (v1)
Legacy
get
 
https://api.openai.com/v1/assistants/{assistant_id}
Retrieves an assistant.

Path parameters
assistant_id
string

Required
The ID of the assistant to retrieve.

Returns
The assistant object matching the specified ID.

Example request
curl https://api.openai.com/v1/assistants/asst_abc123 \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "OpenAI-Beta: assistants=v1"
Response
{
  "id": "asst_abc123",
  "object": "assistant",
  "created_at": 1699009709,
  "name": "HR Helper",
  "description": null,
  "model": "gpt-4-turbo",
  "instructions": "You are an HR bot, and you have access to files to answer employee questions about company policies.",
  "tools": [
    {
      "type": "retrieval"
    }
  ],
  "file_ids": [
    "file-abc123"
  ],
  "metadata": {}
}
Retrieve assistant file (v1)
Legacy
get
 
https://api.openai.com/v1/assistants/{assistant_id}/files/{file_id}
Retrieves an AssistantFile.

Path parameters
assistant_id
string

Required
The ID of the assistant who the file belongs to.

file_id
string

Required
The ID of the file we're getting.

Returns
The assistant file object matching the specified ID.

Example request
curl https://api.openai.com/v1/assistants/asst_abc123/files/file-abc123 \
  -H 'Authorization: Bearer $OPENAI_API_KEY"' \
  -H 'Content-Type: application/json' \
  -H 'OpenAI-Beta: assistants=v1'
Response
{
  "id": "file-abc123",
  "object": "assistant.file",
  "created_at": 1699055364,
  "assistant_id": "asst_abc123"
}
Modify assistant (v1)
Legacy
post
 
https://api.openai.com/v1/assistants/{assistant_id}
Modifies an assistant.

Path parameters
assistant_id
string

Required
The ID of the assistant to modify.

Request body
model
Optional
ID of the model to use. You can use the List models API to see all of your available models, or see our Model overview for descriptions of them. type: string

name
string or null

Optional
The name of the assistant. The maximum length is 256 characters.

description
string or null

Optional
The description of the assistant. The maximum length is 512 characters.

instructions
string or null

Optional
The system instructions that the assistant uses. The maximum length is 256,000 characters.

tools
array

Optional
Defaults to []
A list of tool enabled on the assistant. There can be a maximum of 128 tools per assistant. Tools can be of types code_interpreter, retrieval, or function.


Show possible types
file_ids
array

Optional
Defaults to []
A list of File IDs attached to this assistant. There can be a maximum of 20 files attached to the assistant. Files are ordered by their creation date in ascending order. If a file was previously attached to the list but does not show up in the list, it will be deleted from the assistant.

metadata
map

Optional
Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maxium of 512 characters long.

temperature
number or null

Optional
Defaults to 1
What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic.

top_p
number or null

Optional
Defaults to 1
An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered.

We generally recommend altering this or temperature but not both.

response_format
string or object

Optional
Specifies the format that the model must output. Compatible with GPT-4o, GPT-4 Turbo, and all GPT-3.5 Turbo models since gpt-3.5-turbo-1106.

Setting to { "type": "json_object" } enables JSON mode, which guarantees the message the model generates is valid JSON.

Important: when using JSON mode, you must also instruct the model to produce JSON yourself via a system or user message. Without this, the model may generate an unending stream of whitespace until the generation reaches the token limit, resulting in a long-running and seemingly "stuck" request. Also note that the message content may be partially cut off if finish_reason="length", which indicates the generation exceeded max_tokens or the conversation exceeded the max context length.


Show possible types
Returns
The modified assistant object.

Example request
curl https://api.openai.com/v1/assistants/asst_abc123 \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "OpenAI-Beta: assistants=v1" \
  -d '{
      "instructions": "You are an HR bot, and you have access to files to answer employee questions about company policies. Always response with info from either of the files.",
      "tools": [{"type": "retrieval"}],
      "model": "gpt-4-turbo",
      "file_ids": ["file-abc123", "file-abc456"]
    }'
Response
{
  "id": "asst_abc123",
  "object": "assistant",
  "created_at": 1699009709,
  "name": "HR Helper",
  "description": null,
  "model": "gpt-4-turbo",
  "instructions": "You are an HR bot, and you have access to files to answer employee questions about company policies. Always response with info from either of the files.",
  "tools": [
    {
      "type": "retrieval"
    }
  ],
  "file_ids": [
    "file-abc123",
    "file-abc456"
  ],
  "metadata": {},
  "top_p": 1.0,
  "temperature": 1.0,
  "response_format": "auto"
}
Delete assistant (v1)
Legacy
delete
 
https://api.openai.com/v1/assistants/{assistant_id}
Delete an assistant.

Path parameters
assistant_id
string

Required
The ID of the assistant to delete.

Returns
Deletion status

Example request
curl https://api.openai.com/v1/assistants/asst_abc123 \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "OpenAI-Beta: assistants=v1" \
  -X DELETE
Response
{
  "id": "asst_abc123",
  "object": "assistant.deleted",
  "deleted": true
}
Delete assistant file (v1)
Legacy
delete
 
https://api.openai.com/v1/assistants/{assistant_id}/files/{file_id}
Delete an assistant file.

Path parameters
assistant_id
string

Required
The ID of the assistant that the file belongs to.

file_id
string

Required
The ID of the file to delete.

Returns
Deletion status

Example request
curl https://api.openai.com/v1/assistants/asst_abc123/files/file-abc123 \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -H "OpenAI-Beta: assistants=v1" \
  -X DELETE
Response
{
  id: "file-abc123",
  object: "assistant.file.deleted",
  deleted: true
}
The assistant object (v1)
Legacy
Represents an assistant that can call the model and use tools.

id
string

The identifier, which can be referenced in API endpoints.

object
string

The object type, which is always assistant.

created_at
integer

The Unix timestamp (in seconds) for when the assistant was created.

name
string or null

The name of the assistant. The maximum length is 256 characters.

description
string or null

The description of the assistant. The maximum length is 512 characters.

model
ID of the model to use. You can use the List models API to see all of your available models, or see our Model overview for descriptions of them. type: string

instructions
string or null

The system instructions that the assistant uses. The maximum length is 256,000 characters.

tools
array

A list of tool enabled on the assistant. There can be a maximum of 128 tools per assistant. Tools can be of types code_interpreter, retrieval, or function.


Show possible types
file_ids
array

A list of file IDs attached to this assistant. There can be a maximum of 20 files attached to the assistant. Files are ordered by their creation date in ascending order.

metadata
map

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maxium of 512 characters long.

temperature
number or null

What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic.

top_p
number or null

An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered.

We generally recommend altering this or temperature but not both.

response_format
string or object

Specifies the format that the model must output. Compatible with GPT-4o, GPT-4 Turbo, and all GPT-3.5 Turbo models since gpt-3.5-turbo-1106.

Setting to { "type": "json_object" } enables JSON mode, which guarantees the message the model generates is valid JSON.

Important: when using JSON mode, you must also instruct the model to produce JSON yourself via a system or user message. Without this, the model may generate an unending stream of whitespace until the generation reaches the token limit, resulting in a long-running and seemingly "stuck" request. Also note that the message content may be partially cut off if finish_reason="length", which indicates the generation exceeded max_tokens or the conversation exceeded the max context length.


Show possible types
OBJECT The assistant object (v1)
{
  "id": "asst_abc123",
  "object": "assistant",
  "created_at": 1698984975,
  "name": "Math Tutor",
  "description": null,
  "model": "gpt-4-turbo",
  "instructions": "You are a personal math tutor. When asked a question, write and run Python code to answer the question.",
  "tools": [
    {
      "type": "code_interpreter"
    }
  ],
  "file_ids": [],
  "metadata": {},
  "top_p": 1.0,
  "temperature": 1.0,
  "response_format": "auto"
}
The assistant file object (v1)
Legacy
A list of Files attached to an assistant.

id
string

The identifier, which can be referenced in API endpoints.

object
string

The object type, which is always assistant.file.

created_at
integer

The Unix timestamp (in seconds) for when the assistant file was created.

assistant_id
string

The assistant ID that the file is attached to.

OBJECT The assistant file object (v1)
{
  "id": "file-abc123",
  "object": "assistant.file",
  "created_at": 1699055364,
  "assistant_id": "asst_abc123"
}
Threads (v1)
Legacy
Create threads that assistants can interact with.

Related guide: Assistants

Create thread (v1)
Legacy
post
 
https://api.openai.com/v1/threads
Create a thread.

Request body
messages
array

Optional
A list of messages to start the thread with.


Show properties
metadata
map

Optional
Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maxium of 512 characters long.

Returns
A thread object.


Empty

Messages
Example request
curl https://api.openai.com/v1/threads \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "OpenAI-Beta: assistants=v1" \
  -d ''
Response
{
  "id": "thread_abc123",
  "object": "thread",
  "created_at": 1699012949,
  "metadata": {}
}
Retrieve thread (v1)
Legacy
get
 
https://api.openai.com/v1/threads/{thread_id}
Retrieves a thread.

Path parameters
thread_id
string

Required
The ID of the thread to retrieve.

Returns
The thread object matching the specified ID.

Example request
curl https://api.openai.com/v1/threads/thread_abc123 \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "OpenAI-Beta: assistants=v1"
Response
{
  "id": "thread_abc123",
  "object": "thread",
  "created_at": 1699014083,
  "metadata": {}
}
Modify thread (v1)
Legacy
post
 
https://api.openai.com/v1/threads/{thread_id}
Modifies a thread.

Path parameters
thread_id
string

Required
The ID of the thread to modify. Only the metadata can be modified.

Request body
metadata
map

Optional
Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maxium of 512 characters long.

Returns
The modified thread object matching the specified ID.

Example request
curl https://api.openai.com/v1/threads/thread_abc123 \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "OpenAI-Beta: assistants=v1" \
  -d '{
      "metadata": {
        "modified": "true",
        "user": "abc123"
      }
    }'
Response
{
  "id": "thread_abc123",
  "object": "thread",
  "created_at": 1699014083,
  "metadata": {
    "modified": "true",
    "user": "abc123"
  }
}
Delete thread (v1)
Legacy
delete
 
https://api.openai.com/v1/threads/{thread_id}
Delete a thread.

Path parameters
thread_id
string

Required
The ID of the thread to delete.

Returns
Deletion status

Example request
curl https://api.openai.com/v1/threads/thread_abc123 \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "OpenAI-Beta: assistants=v1" \
  -X DELETE
Response
{
  "id": "thread_abc123",
  "object": "thread.deleted",
  "deleted": true
}
The thread object (v1)
Legacy
Represents a thread that contains messages.

id
string

The identifier, which can be referenced in API endpoints.

object
string

The object type, which is always thread.

created_at
integer

The Unix timestamp (in seconds) for when the thread was created.

metadata
map

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maxium of 512 characters long.

OBJECT The thread object (v1)
{
  "id": "thread_abc123",
  "object": "thread",
  "created_at": 1698107661,
  "metadata": {}
}
Messages (v1)
Legacy
Create messages within threads

Related guide: Assistants

Create message (v1)
Legacy
post
 
https://api.openai.com/v1/threads/{thread_id}/messages
Create a message.

Path parameters
thread_id
string

Required
The ID of the thread to create a message for.

Request body
role
string

Required
The role of the entity that is creating the message. Allowed values include:

user: Indicates the message is sent by an actual user and should be used in most cases to represent user-generated messages.
assistant: Indicates the message is generated by the assistant. Use this value to insert messages from the assistant into the conversation.
content
string

Required
The content of the message.

file_ids
array

Optional
Defaults to []
A list of File IDs that the message should use. There can be a maximum of 10 files attached to a message. Useful for tools like retrieval and code_interpreter that can access and use files.

metadata
map

Optional
Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maxium of 512 characters long.

Returns
A message object.

Example request
curl https://api.openai.com/v1/threads/thread_abc123/messages \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "OpenAI-Beta: assistants=v1" \
  -d '{
      "role": "user",
      "content": "How does AI work? Explain it in simple terms."
    }'
Response
{
  "id": "msg_abc123",
  "object": "thread.message",
  "created_at": 1699017614,
  "thread_id": "thread_abc123",
  "role": "user",
  "content": [
    {
      "type": "text",
      "text": {
        "value": "How does AI work? Explain it in simple terms.",
        "annotations": []
      }
    }
  ],
  "file_ids": [],
  "assistant_id": null,
  "run_id": null,
  "metadata": {}
}
List messages (v1)
Legacy
get
 
https://api.openai.com/v1/threads/{thread_id}/messages
Returns a list of messages for a given thread.

Path parameters
thread_id
string

Required
The ID of the thread the messages belong to.

Query parameters
limit
integer

Optional
Defaults to 20
A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.

order
string

Optional
Defaults to desc
Sort order by the created_at timestamp of the objects. asc for ascending order and desc for descending order.

after
string

Optional
A cursor for use in pagination. after is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj_foo, your subsequent call can include after=obj_foo in order to fetch the next page of the list.

before
string

Optional
A cursor for use in pagination. before is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj_foo, your subsequent call can include before=obj_foo in order to fetch the previous page of the list.

run_id
string

Optional
Filter messages by the run ID that generated them.

Returns
A list of message objects.

Example request
curl https://api.openai.com/v1/threads/thread_abc123/messages \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "OpenAI-Beta: assistants=v1"
Response
{
  "object": "list",
  "data": [
    {
      "id": "msg_abc123",
      "object": "thread.message",
      "created_at": 1699016383,
      "thread_id": "thread_abc123",
      "role": "user",
      "content": [
        {
          "type": "text",
          "text": {
            "value": "How does AI work? Explain it in simple terms.",
            "annotations": []
          }
        }
      ],
      "file_ids": [],
      "assistant_id": null,
      "run_id": null,
      "metadata": {}
    },
    {
      "id": "msg_abc456",
      "object": "thread.message",
      "created_at": 1699016383,
      "thread_id": "thread_abc123",
      "role": "user",
      "content": [
        {
          "type": "text",
          "text": {
            "value": "Hello, what is AI?",
            "annotations": []
          }
        }
      ],
      "file_ids": [
        "file-abc123"
      ],
      "assistant_id": null,
      "run_id": null,
      "metadata": {}
    }
  ],
  "first_id": "msg_abc123",
  "last_id": "msg_abc456",
  "has_more": false
}
List message files (v1)
Legacy
get
 
https://api.openai.com/v1/threads/{thread_id}/messages/{message_id}/files
Returns a list of message files.

Path parameters
thread_id
string

Required
The ID of the thread that the message and files belong to.

message_id
string

Required
The ID of the message that the files belongs to.

Query parameters
limit
integer

Optional
Defaults to 20
A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.

order
string

Optional
Defaults to desc
Sort order by the created_at timestamp of the objects. asc for ascending order and desc for descending order.

after
string

Optional
A cursor for use in pagination. after is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj_foo, your subsequent call can include after=obj_foo in order to fetch the next page of the list.

before
string

Optional
A cursor for use in pagination. before is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj_foo, your subsequent call can include before=obj_foo in order to fetch the previous page of the list.

Returns
A list of message file objects.

Example request
curl https://api.openai.com/v1/threads/thread_abc123/messages/msg_abc123/files \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -H "OpenAI-Beta: assistants=v1"
Response
{
  "object": "list",
  "data": [
    {
      "id": "file-abc123",
      "object": "thread.message.file",
      "created_at": 1699061776,
      "message_id": "msg_abc123"
    },
    {
      "id": "file-abc123",
      "object": "thread.message.file",
      "created_at": 1699061776,
      "message_id": "msg_abc123"
    }
  ],
  "first_id": "file-abc123",
  "last_id": "file-abc123",
  "has_more": false
}
Retrieve message (v1)
Legacy
get
 
https://api.openai.com/v1/threads/{thread_id}/messages/{message_id}
Retrieve a message.

Path parameters
thread_id
string

Required
The ID of the thread to which this message belongs.

message_id
string

Required
The ID of the message to retrieve.

Returns
The message object matching the specified ID.

Example request
curl https://api.openai.com/v1/threads/thread_abc123/messages/msg_abc123 \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "OpenAI-Beta: assistants=v1"
Response
{
  "id": "msg_abc123",
  "object": "thread.message",
  "created_at": 1699017614,
  "thread_id": "thread_abc123",
  "role": "user",
  "content": [
    {
      "type": "text",
      "text": {
        "value": "How does AI work? Explain it in simple terms.",
        "annotations": []
      }
    }
  ],
  "file_ids": [],
  "assistant_id": null,
  "run_id": null,
  "metadata": {}
}
Retrieve message file (v1)
Legacy
get
 
https://api.openai.com/v1/threads/{thread_id}/messages/{message_id}/files/{file_id}
Retrieves a message file.

Path parameters
thread_id
string

Required
The ID of the thread to which the message and File belong.

message_id
string

Required
The ID of the message the file belongs to.

file_id
string

Required
The ID of the file being retrieved.

Returns
The message file object.

Example request
curl https://api.openai.com/v1/threads/thread_abc123/messages/msg_abc123/files/file-abc123 \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -H "OpenAI-Beta: assistants=v1"
Response
{
  "id": "file-abc123",
  "object": "thread.message.file",
  "created_at": 1699061776,
  "message_id": "msg_abc123"
}
Modify message (v1)
Legacy
post
 
https://api.openai.com/v1/threads/{thread_id}/messages/{message_id}
Modifies a message.

Path parameters
thread_id
string

Required
The ID of the thread to which this message belongs.

message_id
string

Required
The ID of the message to modify.

Request body
metadata
map

Optional
Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maxium of 512 characters long.

Returns
The modified message object.

Example request
curl https://api.openai.com/v1/threads/thread_abc123/messages/msg_abc123 \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "OpenAI-Beta: assistants=v1" \
  -d '{
      "metadata": {
        "modified": "true",
        "user": "abc123"
      }
    }'
Response
{
  "id": "msg_abc123",
  "object": "thread.message",
  "created_at": 1699017614,
  "thread_id": "thread_abc123",
  "role": "user",
  "content": [
    {
      "type": "text",
      "text": {
        "value": "How does AI work? Explain it in simple terms.",
        "annotations": []
      }
    }
  ],
  "file_ids": [],
  "assistant_id": null,
  "run_id": null,
  "metadata": {
    "modified": "true",
    "user": "abc123"
  }
}
The message object (v1)
Legacy
Represents a message within a thread.

id
string

The identifier, which can be referenced in API endpoints.

object
string

The object type, which is always thread.message.

created_at
integer

The Unix timestamp (in seconds) for when the message was created.

thread_id
string

The thread ID that this message belongs to.

status
string

The status of the message, which can be either in_progress, incomplete, or completed.

incomplete_details
object or null

On an incomplete message, details about why the message is incomplete.


Show properties
completed_at
integer or null

The Unix timestamp (in seconds) for when the message was completed.

incomplete_at
integer or null

The Unix timestamp (in seconds) for when the message was marked as incomplete.

role
string

The entity that produced the message. One of user or assistant.

content
array

The content of the message in array of text and/or images.


Show possible types
assistant_id
string or null

If applicable, the ID of the assistant that authored this message.

run_id
string or null

The ID of the run associated with the creation of this message. Value is null when messages are created manually using the create message or create thread endpoints.

file_ids
array

A list of file IDs that the assistant should use. Useful for tools like retrieval and code_interpreter that can access files. A maximum of 10 files can be attached to a message.

metadata
map

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maxium of 512 characters long.

OBJECT The message object (v1)
{
  "id": "msg_abc123",
  "object": "thread.message",
  "created_at": 1698983503,
  "thread_id": "thread_abc123",
  "role": "assistant",
  "content": [
    {
      "type": "text",
      "text": {
        "value": "Hi! How can I help you today?",
        "annotations": []
      }
    }
  ],
  "file_ids": [],
  "assistant_id": "asst_abc123",
  "run_id": "run_abc123",
  "metadata": {}
}
The message file object (v1)
Legacy
A list of files attached to a message.

id
string

The identifier, which can be referenced in API endpoints.

object
string

The object type, which is always thread.message.file.

created_at
integer

The Unix timestamp (in seconds) for when the message file was created.

message_id
string

The ID of the message that the File is attached to.

OBJECT The message file object (v1)
{
  "id": "file-abc123",
  "object": "thread.message.file",
  "created_at": 1698107661,
  "message_id": "message_QLoItBbqwyAJEzlTy4y9kOMM",
  "file_id": "file-abc123"
}
Runs (v1)
Legacy
Represents an execution run on a thread.

Related guide: Assistants

Create run (v1)
Legacy
post
 
https://api.openai.com/v1/threads/{thread_id}/runs
Create a run.

Path parameters
thread_id
string

Required
The ID of the thread to run.

Request body
assistant_id
string

Required
The ID of the assistant to use to execute this run.

model
string

Optional
The ID of the Model to be used to execute this run. If a value is provided here, it will override the model associated with the assistant. If not, the model associated with the assistant will be used.

instructions
string or null

Optional
Overrides the instructions of the assistant. This is useful for modifying the behavior on a per-run basis.

additional_instructions
string or null

Optional
Appends additional instructions at the end of the instructions for the run. This is useful for modifying the behavior on a per-run basis without overriding other instructions.

additional_messages
array or null

Optional
Adds additional messages to the thread before creating the run.


Show properties
tools
array or null

Optional
Override the tools the assistant can use for this run. This is useful for modifying the behavior on a per-run basis.


Show possible types
metadata
map

Optional
Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maxium of 512 characters long.

temperature
number or null

Optional
Defaults to 1
What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic.

top_p
number or null

Optional
Defaults to 1
An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered.

We generally recommend altering this or temperature but not both.

stream
boolean or null

Optional
If true, returns a stream of events that happen during the Run as server-sent events, terminating when the Run enters a terminal state with a data: [DONE] message.

max_prompt_tokens
integer or null

Optional
The maximum number of prompt tokens that may be used over the course of the run. The run will make a best effort to use only the number of prompt tokens specified, across multiple turns of the run. If the run exceeds the number of prompt tokens specified, the run will end with status complete. See incomplete_details for more info.

max_completion_tokens
integer or null

Optional
The maximum number of completion tokens that may be used over the course of the run. The run will make a best effort to use only the number of completion tokens specified, across multiple turns of the run. If the run exceeds the number of completion tokens specified, the run will end with status complete. See incomplete_details for more info.

truncation_strategy
object

Optional

Show properties
tool_choice
string or object

Optional
Controls which (if any) tool is called by the model. none means the model will not call any tools and instead generates a message. auto is the default value and means the model can pick between generating a message or calling a tool. Specifying a particular tool like {"type": "TOOL_TYPE"} or {"type": "function", "function": {"name": "my_function"}} forces the model to call that tool.


Show possible types
response_format
string or object

Optional
Specifies the format that the model must output. Compatible with GPT-4o, GPT-4 Turbo, and all GPT-3.5 Turbo models since gpt-3.5-turbo-1106.

Setting to { "type": "json_object" } enables JSON mode, which guarantees the message the model generates is valid JSON.

Important: when using JSON mode, you must also instruct the model to produce JSON yourself via a system or user message. Without this, the model may generate an unending stream of whitespace until the generation reaches the token limit, resulting in a long-running and seemingly "stuck" request. Also note that the message content may be partially cut off if finish_reason="length", which indicates the generation exceeded max_tokens or the conversation exceeded the max context length.


Show possible types
Returns
A run object.


Default

Streaming

Streaming with Functions
Example request
curl https://api.openai.com/v1/threads/thread_abc123/runs \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -H "OpenAI-Beta: assistants=v1" \
  -d '{
    "assistant_id": "asst_abc123"
  }'
Response
{
  "id": "run_abc123",
  "object": "thread.run",
  "created_at": 1699063290,
  "assistant_id": "asst_abc123",
  "thread_id": "thread_abc123",
  "status": "queued",
  "started_at": 1699063290,
  "expires_at": null,
  "cancelled_at": null,
  "failed_at": null,
  "completed_at": 1699063291,
  "last_error": null,
  "model": "gpt-4-turbo",
  "instructions": null,
  "incomplete_details": null,
  "tools": [
    {
      "type": "code_interpreter"
    }
  ],
  "file_ids": [
    "file-abc123",
    "file-abc456"
  ],
  "metadata": {},
  "usage": null,
  "temperature": 1.0,
  "top_p": 1.0,
  "max_prompt_tokens": 1000,
  "max_completion_tokens": 1000,
  "truncation_strategy": {
    "type": "auto",
    "last_messages": null
  },
  "response_format": "auto",
  "tool_choice": "auto"
}
Create thread and run (v1)
Legacy
post
 
https://api.openai.com/v1/threads/runs
Create a thread and run it in one request.

Request body
assistant_id
string

Required
The ID of the assistant to use to execute this run.

thread
object

Optional

Show properties
model
string

Optional
The ID of the Model to be used to execute this run. If a value is provided here, it will override the model associated with the assistant. If not, the model associated with the assistant will be used.

instructions
string or null

Optional
Override the default system message of the assistant. This is useful for modifying the behavior on a per-run basis.

tools
array or null

Optional
Override the tools the assistant can use for this run. This is useful for modifying the behavior on a per-run basis.

metadata
map

Optional
Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maxium of 512 characters long.

temperature
number or null

Optional
Defaults to 1
What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic.

top_p
number or null

Optional
Defaults to 1
An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered.

We generally recommend altering this or temperature but not both.

stream
boolean or null

Optional
If true, returns a stream of events that happen during the Run as server-sent events, terminating when the Run enters a terminal state with a data: [DONE] message.

max_prompt_tokens
integer or null

Optional
The maximum number of prompt tokens that may be used over the course of the run. The run will make a best effort to use only the number of prompt tokens specified, across multiple turns of the run. If the run exceeds the number of prompt tokens specified, the run will end with status complete. See incomplete_details for more info.

max_completion_tokens
integer or null

Optional
The maximum number of completion tokens that may be used over the course of the run. The run will make a best effort to use only the number of completion tokens specified, across multiple turns of the run. If the run exceeds the number of completion tokens specified, the run will end with status complete. See incomplete_details for more info.

truncation_strategy
object

Optional

Show properties
tool_choice
string or object

Optional
Controls which (if any) tool is called by the model. none means the model will not call any tools and instead generates a message. auto is the default value and means the model can pick between generating a message or calling a tool. Specifying a particular tool like {"type": "TOOL_TYPE"} or {"type": "function", "function": {"name": "my_function"}} forces the model to call that tool.


Show possible types
response_format
string or object

Optional
Specifies the format that the model must output. Compatible with GPT-4o, GPT-4 Turbo, and all GPT-3.5 Turbo models since gpt-3.5-turbo-1106.

Setting to { "type": "json_object" } enables JSON mode, which guarantees the message the model generates is valid JSON.

Important: when using JSON mode, you must also instruct the model to produce JSON yourself via a system or user message. Without this, the model may generate an unending stream of whitespace until the generation reaches the token limit, resulting in a long-running and seemingly "stuck" request. Also note that the message content may be partially cut off if finish_reason="length", which indicates the generation exceeded max_tokens or the conversation exceeded the max context length.


Show possible types
Returns
A run object.


Default

Streaming

Streaming with Functions
Example request
curl https://api.openai.com/v1/threads/runs \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -H "OpenAI-Beta: assistants=v1" \
  -d '{
      "assistant_id": "asst_abc123",
      "thread": {
        "messages": [
          {"role": "user", "content": "Explain deep learning to a 5 year old."}
        ]
      }
    }'
Response
{
  "id": "run_abc123",
  "object": "thread.run",
  "created_at": 1699076792,
  "assistant_id": "asst_abc123",
  "thread_id": "thread_abc123",
  "status": "queued",
  "started_at": null,
  "expires_at": 1699077392,
  "cancelled_at": null,
  "failed_at": null,
  "completed_at": null,
  "last_error": null,
  "model": "gpt-4-turbo",
  "instructions": "You are a helpful assistant.",
  "tools": [],
  "file_ids": [],
  "metadata": {},
  "usage": null,
  "temperature": 1
}
List runs (v1)
Legacy
get
 
https://api.openai.com/v1/threads/{thread_id}/runs
Returns a list of runs belonging to a thread.

Path parameters
thread_id
string

Required
The ID of the thread the run belongs to.

Query parameters
limit
integer

Optional
Defaults to 20
A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.

order
string

Optional
Defaults to desc
Sort order by the created_at timestamp of the objects. asc for ascending order and desc for descending order.

after
string

Optional
A cursor for use in pagination. after is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj_foo, your subsequent call can include after=obj_foo in order to fetch the next page of the list.

before
string

Optional
A cursor for use in pagination. before is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj_foo, your subsequent call can include before=obj_foo in order to fetch the previous page of the list.

Returns
A list of run objects.

Example request
curl https://api.openai.com/v1/threads/thread_abc123/runs \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -H "OpenAI-Beta: assistants=v1"
Response
{
  "object": "list",
  "data": [
    {
      "id": "run_abc123",
      "object": "thread.run",
      "created_at": 1699075072,
      "assistant_id": "asst_abc123",
      "thread_id": "thread_abc123",
      "status": "completed",
      "started_at": 1699075072,
      "expires_at": null,
      "cancelled_at": null,
      "failed_at": null,
      "completed_at": 1699075073,
      "last_error": null,
      "model": "gpt-4-turbo",
      "instructions": null,
      "incomplete_details": null,
      "tools": [
        {
          "type": "code_interpreter"
        }
      ],
      "file_ids": [
        "file-abc123",
        "file-abc456"
      ],
      "metadata": {},
      "usage": {
        "prompt_tokens": 123,
        "completion_tokens": 456,
        "total_tokens": 579
      },
      "temperature": 1.0,
      "top_p": 1.0,
      "max_prompt_tokens": 1000,
      "max_completion_tokens": 1000,
      "truncation_strategy": {
        "type": "auto",
        "last_messages": null
      },
      "response_format": "auto",
      "tool_choice": "auto"
    },
    {
      "id": "run_abc456",
      "object": "thread.run",
      "created_at": 1699063290,
      "assistant_id": "asst_abc123",
      "thread_id": "thread_abc123",
      "status": "completed",
      "started_at": 1699063290,
      "expires_at": null,
      "cancelled_at": null,
      "failed_at": null,
      "completed_at": 1699063291,
      "last_error": null,
      "model": "gpt-4-turbo",
      "instructions": null,
      "incomplete_details": null,
      "tools": [
        {
          "type": "code_interpreter"
        }
      ],
      "file_ids": [
        "file-abc123",
        "file-abc456"
      ],
      "metadata": {},
      "usage": {
        "prompt_tokens": 123,
        "completion_tokens": 456,
        "total_tokens": 579
      },
      "temperature": 1.0,
      "top_p": 1.0,
      "max_prompt_tokens": 1000,
      "max_completion_tokens": 1000,
      "truncation_strategy": {
        "type": "auto",
        "last_messages": null
      },
      "response_format": "auto",
      "tool_choice": "auto"
    }
  ],
  "first_id": "run_abc123",
  "last_id": "run_abc456",
  "has_more": false
}
List run steps (v1)
Legacy
get
 
https://api.openai.com/v1/threads/{thread_id}/runs/{run_id}/steps
Returns a list of run steps belonging to a run.

Path parameters
thread_id
string

Required
The ID of the thread the run and run steps belong to.

run_id
string

Required
The ID of the run the run steps belong to.

Query parameters
limit
integer

Optional
Defaults to 20
A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.

order
string

Optional
Defaults to desc
Sort order by the created_at timestamp of the objects. asc for ascending order and desc for descending order.

after
string

Optional
A cursor for use in pagination. after is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj_foo, your subsequent call can include after=obj_foo in order to fetch the next page of the list.

before
string

Optional
A cursor for use in pagination. before is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj_foo, your subsequent call can include before=obj_foo in order to fetch the previous page of the list.

Returns
A list of run step objects.

Example request
curl https://api.openai.com/v1/threads/thread_abc123/runs/run_abc123/steps \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -H "OpenAI-Beta: assistants=v1"
Response
{
  "object": "list",
  "data": [
    {
      "id": "step_abc123",
      "object": "thread.run.step",
      "created_at": 1699063291,
      "run_id": "run_abc123",
      "assistant_id": "asst_abc123",
      "thread_id": "thread_abc123",
      "type": "message_creation",
      "status": "completed",
      "cancelled_at": null,
      "completed_at": 1699063291,
      "expired_at": null,
      "failed_at": null,
      "last_error": null,
      "step_details": {
        "type": "message_creation",
        "message_creation": {
          "message_id": "msg_abc123"
        }
      },
      "usage": {
        "prompt_tokens": 123,
        "completion_tokens": 456,
        "total_tokens": 579
      }
    }
  ],
  "first_id": "step_abc123",
  "last_id": "step_abc456",
  "has_more": false
}
Retrieve run (v1)
Legacy
get
 
https://api.openai.com/v1/threads/{thread_id}/runs/{run_id}
Retrieves a run.

Path parameters
thread_id
string

Required
The ID of the thread that was run.

run_id
string

Required
The ID of the run to retrieve.

Returns
The run object matching the specified ID.

Example request
curl https://api.openai.com/v1/threads/thread_abc123/runs/run_abc123 \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "OpenAI-Beta: assistants=v1"
Response
{
  "id": "run_abc123",
  "object": "thread.run",
  "created_at": 1699075072,
  "assistant_id": "asst_abc123",
  "thread_id": "thread_abc123",
  "status": "completed",
  "started_at": 1699075072,
  "expires_at": null,
  "cancelled_at": null,
  "failed_at": null,
  "completed_at": 1699075073,
  "last_error": null,
  "model": "gpt-4-turbo",
  "instructions": null,
  "incomplete_details": null,
  "tools": [
    {
      "type": "code_interpreter"
    }
  ],
  "file_ids": [
    "file-abc123",
    "file-abc456"
  ],
  "metadata": {},
  "usage": {
    "prompt_tokens": 123,
    "completion_tokens": 456,
    "total_tokens": 579
  },
  "temperature": 1.0,
  "top_p": 1.0,
  "max_prompt_tokens": 1000,
  "max_completion_tokens": 1000,
  "truncation_strategy": {
    "type": "auto",
    "last_messages": null
  },
  "response_format": "auto",
  "tool_choice": "auto"
}
Retrieve run step (v1)
Legacy
get
 
https://api.openai.com/v1/threads/{thread_id}/runs/{run_id}/steps/{step_id}
Retrieves a run step.

Path parameters
thread_id
string

Required
The ID of the thread to which the run and run step belongs.

run_id
string

Required
The ID of the run to which the run step belongs.

step_id
string

Required
The ID of the run step to retrieve.

Returns
The run step object matching the specified ID.

Example request
curl https://api.openai.com/v1/threads/thread_abc123/runs/run_abc123/steps/step_abc123 \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -H "OpenAI-Beta: assistants=v1"
Response
{
  "id": "step_abc123",
  "object": "thread.run.step",
  "created_at": 1699063291,
  "run_id": "run_abc123",
  "assistant_id": "asst_abc123",
  "thread_id": "thread_abc123",
  "type": "message_creation",
  "status": "completed",
  "cancelled_at": null,
  "completed_at": 1699063291,
  "expired_at": null,
  "failed_at": null,
  "last_error": null,
  "step_details": {
    "type": "message_creation",
    "message_creation": {
      "message_id": "msg_abc123"
    }
  },
  "usage": {
    "prompt_tokens": 123,
    "completion_tokens": 456,
    "total_tokens": 579
  }
}
Modify run (v1)
Legacy
post
 
https://api.openai.com/v1/threads/{thread_id}/runs/{run_id}
Modifies a run.

Path parameters
thread_id
string

Required
The ID of the thread that was run.

run_id
string

Required
The ID of the run to modify.

Request body
metadata
map

Optional
Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maxium of 512 characters long.

Returns
The modified run object matching the specified ID.

Example request
curl https://api.openai.com/v1/threads/thread_abc123/runs/run_abc123 \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -H "OpenAI-Beta: assistants=v1" \
  -d '{
    "metadata": {
      "user_id": "user_abc123"
    }
  }'
Response
{
  "id": "run_abc123",
  "object": "thread.run",
  "created_at": 1699075072,
  "assistant_id": "asst_abc123",
  "thread_id": "thread_abc123",
  "status": "completed",
  "started_at": 1699075072,
  "expires_at": null,
  "cancelled_at": null,
  "failed_at": null,
  "completed_at": 1699075073,
  "last_error": null,
  "model": "gpt-4-turbo",
  "instructions": null,
  "incomplete_details": null,
  "tools": [
    {
      "type": "code_interpreter"
    }
  ],
  "file_ids": [
    "file-abc123",
    "file-abc456"
  ],
  "metadata": {
    "user_id": "user_abc123"
  },
  "usage": {
    "prompt_tokens": 123,
    "completion_tokens": 456,
    "total_tokens": 579
  },
  "temperature": 1.0,
  "top_p": 1.0,
  "max_prompt_tokens": 1000,
  "max_completion_tokens": 1000,
  "truncation_strategy": {
    "type": "auto",
    "last_messages": null
  },
  "response_format": "auto",
  "tool_choice": "auto"
}
Submit tool outputs to run (v1)
Legacy
post
 
https://api.openai.com/v1/threads/{thread_id}/runs/{run_id}/submit_tool_outputs
When a run has the status: "requires_action" and required_action.type is submit_tool_outputs, this endpoint can be used to submit the outputs from the tool calls once they're all completed. All outputs must be submitted in a single request.

Path parameters
thread_id
string

Required
The ID of the thread to which this run belongs.

run_id
string

Required
The ID of the run that requires the tool output submission.

Request body
tool_outputs
array

Required
A list of tools for which the outputs are being submitted.


Show properties
stream
boolean or null

Optional
If true, returns a stream of events that happen during the Run as server-sent events, terminating when the Run enters a terminal state with a data: [DONE] message.

Returns
The modified run object matching the specified ID.


Default

Streaming
Example request
curl https://api.openai.com/v1/threads/thread_123/runs/run_123/submit_tool_outputs \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -H "OpenAI-Beta: assistants=v1" \
  -d '{
    "tool_outputs": [
      {
        "tool_call_id": "call_001",
        "output": "70 degrees and sunny."
      }
    ]
  }'
Response
{
  "id": "run_123",
  "object": "thread.run",
  "created_at": 1699075592,
  "assistant_id": "asst_123",
  "thread_id": "thread_123",
  "status": "queued",
  "started_at": 1699075592,
  "expires_at": 1699076192,
  "cancelled_at": null,
  "failed_at": null,
  "completed_at": null,
  "last_error": null,
  "model": "gpt-4-turbo",
  "instructions": null,
  "incomplete_details": null,
  "tools": [
    {
      "type": "function",
      "function": {
        "name": "get_current_weather",
        "description": "Get the current weather in a given location",
        "parameters": {
          "type": "object",
          "properties": {
            "location": {
              "type": "string",
              "description": "The city and state, e.g. San Francisco, CA"
            },
            "unit": {
              "type": "string",
              "enum": ["celsius", "fahrenheit"]
            }
          },
          "required": ["location"]
        }
      }
    }
  ],
  "file_ids": [],
  "metadata": {},
  "usage": null,
  "temperature": 1.0,
  "top_p": 1.0,
  "max_prompt_tokens": 1000,
  "max_completion_tokens": 1000,
  "truncation_strategy": {
    "type": "auto",
    "last_messages": null
  },
  "response_format": "auto",
  "tool_choice": "auto"
}
Cancel a run (v1)
Legacy
post
 
https://api.openai.com/v1/threads/{thread_id}/runs/{run_id}/cancel
Cancels a run that is in_progress.

Path parameters
thread_id
string

Required
The ID of the thread to which this run belongs.

run_id
string

Required
The ID of the run to cancel.

Returns
The modified run object matching the specified ID.

Example request
curl https://api.openai.com/v1/threads/thread_abc123/runs/run_abc123/cancel \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "OpenAI-Beta: assistants=v1" \
  -X POST
Response
{
  "id": "run_abc123",
  "object": "thread.run",
  "created_at": 1699076126,
  "assistant_id": "asst_abc123",
  "thread_id": "thread_abc123",
  "status": "cancelling",
  "started_at": 1699076126,
  "expires_at": 1699076726,
  "cancelled_at": null,
  "failed_at": null,
  "completed_at": null,
  "last_error": null,
  "model": "gpt-4-turbo",
  "instructions": "You summarize books.",
  "tools": [
    {
      "type": "retrieval"
    }
  ],
  "file_ids": [],
  "metadata": {},
  "usage": null,
  "temperature": 1.0,
  "top_p": 1.0,
}
The run object (v1)
Legacy
Represents an execution run on a thread.

id
string

The identifier, which can be referenced in API endpoints.

object
string

The object type, which is always thread.run.

created_at
integer

The Unix timestamp (in seconds) for when the run was created.

thread_id
string

The ID of the thread that was executed on as a part of this run.

assistant_id
string

The ID of the assistant used for execution of this run.

status
string

The status of the run, which can be either queued, in_progress, requires_action, cancelling, cancelled, failed, completed, or expired.

required_action
object or null

Details on the action required to continue the run. Will be null if no action is required.


Show properties
last_error
object or null

The last error associated with this run. Will be null if there are no errors.


Show properties
expires_at
integer or null

The Unix timestamp (in seconds) for when the run will expire.

started_at
integer or null

The Unix timestamp (in seconds) for when the run was started.

cancelled_at
integer or null

The Unix timestamp (in seconds) for when the run was cancelled.

failed_at
integer or null

The Unix timestamp (in seconds) for when the run failed.

completed_at
integer or null

The Unix timestamp (in seconds) for when the run was completed.

incomplete_details
object or null

Details on why the run is incomplete. Will be null if the run is not incomplete.


Show properties
model
string

The model that the assistant used for this run.

instructions
string

The instructions that the assistant used for this run.

tools
array

The list of tools that the assistant used for this run.


Show possible types
file_ids
array

The list of File IDs the assistant used for this run.

metadata
map

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maxium of 512 characters long.

usage
temperature
number or null

The sampling temperature used for this run. If not set, defaults to 1.

top_p
number or null

The nucleus sampling value used for this run. If not set, defaults to 1.

max_prompt_tokens
integer or null

The maximum number of prompt tokens specified to have been used over the course of the run.

max_completion_tokens
integer or null

The maximum number of completion tokens specified to have been used over the course of the run.

truncation_strategy
object


Show properties
tool_choice
string or object

Controls which (if any) tool is called by the model. none means the model will not call any tools and instead generates a message. auto is the default value and means the model can pick between generating a message or calling a tool. Specifying a particular tool like {"type": "TOOL_TYPE"} or {"type": "function", "function": {"name": "my_function"}} forces the model to call that tool.


Show possible types
response_format
string or object

Specifies the format that the model must output. Compatible with GPT-4o, GPT-4 Turbo, and all GPT-3.5 Turbo models since gpt-3.5-turbo-1106.

Setting to { "type": "json_object" } enables JSON mode, which guarantees the message the model generates is valid JSON.

Important: when using JSON mode, you must also instruct the model to produce JSON yourself via a system or user message. Without this, the model may generate an unending stream of whitespace until the generation reaches the token limit, resulting in a long-running and seemingly "stuck" request. Also note that the message content may be partially cut off if finish_reason="length", which indicates the generation exceeded max_tokens or the conversation exceeded the max context length.


Show possible types
OBJECT The run object (v1)
{
  "id": "run_abc123",
  "object": "thread.run",
  "created_at": 1698107661,
  "assistant_id": "asst_abc123",
  "thread_id": "thread_abc123",
  "status": "completed",
  "started_at": 1699073476,
  "expires_at": null,
  "cancelled_at": null,
  "failed_at": null,
  "completed_at": 1699073498,
  "last_error": null,
  "model": "gpt-4-turbo",
  "instructions": null,
  "tools": [{"type": "retrieval"}, {"type": "code_interpreter"}],
  "file_ids": [],
  "metadata": {},
  "incomplete_details": null,
  "usage": {
    "prompt_tokens": 123,
    "completion_tokens": 456,
    "total_tokens": 579
  },
  "temperature": 1.0,
  "top_p": 1.0,
  "max_prompt_tokens": 1000,
  "max_completion_tokens": 1000,
  "truncation_strategy": {
    "type": "auto",
    "last_messages": null
  },
  "response_format": "auto",
  "tool_choice": "auto"
}
The run step object (v1)
Legacy
Represents a step in execution of a run.

id
string

The identifier of the run step, which can be referenced in API endpoints.

object
string

The object type, which is always thread.run.step.

created_at
integer

The Unix timestamp (in seconds) for when the run step was created.

assistant_id
string

The ID of the assistant associated with the run step.

thread_id
string

The ID of the thread that was run.

run_id
string

The ID of the run that this run step is a part of.

type
string

The type of run step, which can be either message_creation or tool_calls.

status
string

The status of the run step, which can be either in_progress, cancelled, failed, completed, or expired.

step_details
object

The details of the run step.


Show possible types
last_error
object or null

The last error associated with this run step. Will be null if there are no errors.


Show properties
expired_at
integer or null

The Unix timestamp (in seconds) for when the run step expired. A step is considered expired if the parent run is expired.

cancelled_at
integer or null

The Unix timestamp (in seconds) for when the run step was cancelled.

failed_at
integer or null

The Unix timestamp (in seconds) for when the run step failed.

completed_at
integer or null

The Unix timestamp (in seconds) for when the run step completed.

metadata
map

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maxium of 512 characters long.

usage
OBJECT The run step object (v1)
{
  "id": "step_abc123",
  "object": "thread.run.step",
  "created_at": 1699063291,
  "run_id": "run_abc123",
  "assistant_id": "asst_abc123",
  "thread_id": "thread_abc123",
  "type": "message_creation",
  "status": "completed",
  "cancelled_at": null,
  "completed_at": 1699063291,
  "expired_at": null,
  "failed_at": null,
  "last_error": null,
  "step_details": {
    "type": "message_creation",
    "message_creation": {
      "message_id": "msg_abc123"
    }
  },
  "usage": {
    "prompt_tokens": 123,
    "completion_tokens": 456,
    "total_tokens": 579
  }
}
Streaming (v1)
Legacy
Stream the result of executing a Run or resuming a Run after submitting tool outputs.

You can stream events from the Create Thread and Run, Create Run, and Submit Tool Outputs endpoints by passing "stream": true. The response will be a Server-Sent events stream.

Our Node and Python SDKs provide helpful utilities to make streaming easy. Reference the Assistants API quickstart to learn more.

The message delta object (v1)
Legacy
Represents a message delta i.e. any changed fields on a message during streaming.

id
string

The identifier of the message, which can be referenced in API endpoints.

object
string

The object type, which is always thread.message.delta.

delta
object

The delta containing the fields that have changed on the Message.


Show properties
OBJECT The message delta object (v1)
{
  "id": "msg_123",
  "object": "thread.message.delta",
  "delta": {
    "content": [
      {
        "index": 0,
        "type": "text",
        "text": { "value": "Hello", "annotations": [] }
      }
    ]
  }
}
The run step delta object (v1)
Legacy
Represents a run step delta i.e. any changed fields on a run step during streaming.

id
string

The identifier of the run step, which can be referenced in API endpoints.

object
string

The object type, which is always thread.run.step.delta.

delta
object

The delta containing the fields that have changed on the run step.


Show properties
OBJECT The run step delta object (v1)
{
  "id": "step_123",
  "object": "thread.run.step.delta",
  "delta": {
    "step_details": {
      "type": "tool_calls",
      "tool_calls": [
        {
          "index": 0,
          "id": "call_123",
          "type": "code_interpreter",
          "code_interpreter": { "input": "", "outputs": [] }
        }
      ]
    }
  }
}
Assistant stream events (v1)
Legacy
Represents an event emitted when streaming a Run.

Each event in a server-sent events stream has an event and data property:

event: thread.created
data: {"id": "thread_123", "object": "thread", ...}
We emit events whenever a new object is created, transitions to a new state, or is being streamed in parts (deltas). For example, we emit thread.run.created when a new run is created, thread.run.completed when a run completes, and so on. When an Assistant chooses to create a message during a run, we emit a thread.message.created event, a thread.message.in_progress event, many thread.message.delta events, and finally a thread.message.completed event.

We may add additional events over time, so we recommend handling unknown events gracefully in your code. See the Assistants API quickstart to learn how to integrate the Assistants API with streaming.

thread.created
data is a thread

Occurs when a new thread is created.

thread.run.created
data is a run

Occurs when a new run is created.

thread.run.queued
data is a run

Occurs when a run moves to a queued status.

thread.run.in_progress
data is a run

Occurs when a run moves to an in_progress status.

thread.run.requires_action
data is a run

Occurs when a run moves to a requires_action status.

thread.run.completed
data is a run

Occurs when a run is completed.

thread.run.failed
data is a run

Occurs when a run fails.

thread.run.cancelling
data is a run

Occurs when a run moves to a cancelling status.

thread.run.cancelled
data is a run

Occurs when a run is cancelled.

thread.run.expired
data is a run

Occurs when a run expires.

thread.run.step.created
data is a run step

Occurs when a run step is created.

thread.run.step.in_progress
data is a run step

Occurs when a run step moves to an in_progress state.

thread.run.step.delta
data is a run step delta

Occurs when parts of a run step are being streamed.

thread.run.step.completed
data is a run step

Occurs when a run step is completed.

thread.run.step.failed
data is a run step

Occurs when a run step fails.

thread.run.step.cancelled
data is a run step

Occurs when a run step is cancelled.

thread.run.step.expired
data is a run step

Occurs when a run step expires.

thread.message.created
data is a message

Occurs when a message is created.

thread.message.in_progress
data is a message

Occurs when a message moves to an in_progress state.

thread.message.delta
data is a message delta

Occurs when parts of a Message are being streamed.

thread.message.completed
data is a message

Occurs when a message is completed.

thread.message.incomplete
data is a message

Occurs when a message ends before it is completed.

error
data is an error

Occurs when an error occurs. This can happen due to an internal server error or a timeout.

done
data is [DONE]

Occurs when a stream ends.


---
Only this page
All pages
Powered by GitBook
2 of 47
Hyperbrowser
Welcome to Hyperbrowser
Welcome to Hyperbrowser, the Internet for AI. Hyperbrowser is the next-generation platform for effortless, scalable browser automation. Instead of wrestling with local infrastructure and performance bottlenecks, you can focus on building better solutions. Whether youre collecting data, testing applications, or enabling AI-driven interactions, Hyperbrowser lets you launch and manage browser sessions with easeno complicated setup required. Hyperbrowser also provides you easy to use solutions for all your webscraping needs, whether you need to scrape a single page or crawl an entire site.

Why Hyperbrowser?
Instant Scalability - Spin up hundreds of browser sessions in seconds without infrastructure headaches

Simple Integration - Works seamlessly with popular tools like Puppeteer and Playwright

Powerful APIs - Easy to use APIs for managing your sessions, scraping/crawling any site, and much more

Production Ready - Enterprise-grade reliability and security built-in

Bypass Anti-Bot Measures - Built-in stealth mode, ad blocking, automatic CAPTCHA solving, and rotating proxies

Quick Example
Start automating in just a few lines of code

Copy
import { Hyperbrowser } from "@hyperbrowser/sdk";
import { connect } from "puppeteer-core";

const client = new Hyperbrowser({
  apiKey: process.env.HYPERBROWSER_API_KEY,
});

const session = await client.sessions.create();

// Use the session to automate browser actions
const browser = await connect({
  browserWSEndpoint: session.wsEndpoint,
  defaultViewport: null,
});

// Use the browser to automate browser actions
const page = await browser.newPage();
await page.goto("https://example.com");

await browser.close();

// Once done, you can stop the session
await client.sessions.stop(session.id);
Jump right in


Scraping

Scrape a site and get its contents in markdown



Puppeteer

Connect to a browser session with Puppeteer



Crawling

Crawl an entire site and all its linked pages

Get Started
Quickstart
Get setup with Hyperbrowser in minutes.


To get started with Hyperbrowser, head on over to the dashboard and create an account. All you need now to start scraping, crawling, creating browser sessions, etc. is to use your API Key and one of our SDKs available in Node and Python or just any normal API request. Next, let's see the different types of things we can do within just a couple minutes.

Check out our in-depth SDK references for Node and Python.

Scraping
Scrape any site and get it's data.

Install Hyperbrowser
Node
Copy
npm install @hyperbrowser/sdk
or

Copy
yarn add @hyperbrowser/sdk
Python
Copy
pip install hyperbrowser
Setup your Environment
To use Hyperbrowser with your code, you will need an API Key. You can get one easily from the dashboard. Once you have your API Key, add it to your .env file as HYPERBROWSER_API_KEY .

Scrape a Site
Next, you can scrape any site by simply setting up the Hyperbrowser client and providing the site's url.

Node
Copy
import { Hyperbrowser } from "@hyperbrowser/sdk";
import { config } from "dotenv";

config();

const client = new Hyperbrowser({
  apiKey: process.env.HYPERBROWSER_API_KEY,
});

const main = async () => {
  const scrapeResult = await client.scrape.startAndWait({
    url: "https://example.com",
  });
  console.log("Scrape result:", scrapeResult);
};

main();
Python
Copy
import os
from dotenv import load_dotenv
from hyperbrowser import AsyncHyperbrowser as Hyperbrowser
from hyperbrowser.models.scrape import StartScrapeJobParams

# Load environment variables from .env file
load_dotenv()

# Initialize Hyperbrowser client
client = Hyperbrowser(api_key=os.getenv("HYPERBROWSER_API_KEY"))


async def main():
    # Start scraping and wait for completion
    scrape_result = await client.scrape.start_and_wait(
        StartScrapeJobParams(url="https://example.com")
    )
    print("Scrape result:", scrape_result)


if __name__ == "__main__":
    import asyncio

    asyncio.run(main())
View Session in Dashboard
You can view all your sessions in the dashboard and see their recordings or other key metrics like logs.

Crawling
Crawl a site and all it's links.

Install Hyperbrowser
Node
Copy
npm install @hyperbrowser/sdk
or

Copy
yarn add @hyperbrowser/sdk
Python
Copy
pip install hyperbrowser
Setup your Environment
To use Hyperbrowser with your code, you will need an API Key. You can get one easily from the dashboard. Once you have your API Key, add it to your .env file as HYPERBROWSER_API_KEY .

Crawl a Site
Next, you can crawl any site by simply setting up the Hyperbrowser client and providing the site's url.

Node
Copy
import { Hyperbrowser } from "@hyperbrowser/sdk";
import { config } from "dotenv";

config();

const client = new Hyperbrowser({
  apiKey: process.env.HYPERBROWSER_API_KEY,
});

const main = async () => {
  const crawlResult = await client.crawl.startAndWait({
    url: "https://hyperbrowser.ai",
  });
  console.log("Crawl result:", crawlResult);
};

main();
Python
Copy
import os
from dotenv import load_dotenv
from hyperbrowser import AsyncHyperbrowser as Hyperbrowser
from hyperbrowser.models.crawl import StartCrawlJobParams

# Load environment variables from .env file
load_dotenv()

# Initialize Hyperbrowser client
client = Hyperbrowser(api_key=os.getenv("HYPERBROWSER_API_KEY"))


async def main():
    # Start crawling and wait for completion
    crawl_result = await client.crawl.start_and_wait(
        StartCrawlJobParams(url="https://hyperbrowser.ai")
    )
    print("Crawl result:")
    print(crawl_result.model_dump_json(indent=2))


if __name__ == "__main__":
    import asyncio

    asyncio.run(main())
View Session in Dashboard
You can view all your sessions in the dashboard and see their recordings or other key metrics like logs.

Puppeteer
Setup a browser session with Puppeteer.

Install Puppeteer and Hyperbrowser
Node
Copy
npm install puppeteer-core @hyperbrowser/sdk
or

Copy
yarn add puppeteer-core @hyperbrowser/sdk
Python
Copy
pip install pyppeteer hyperbrowser
Setup your Environment
To use Hyperbrowser with your code, you will need an API Key. You can get one easily from the dashboard. Once you have your API Key, add it to your .env file as HYPERBROWSER_API_KEY .

Setup Browser Session
Next, you can easily startup a browser session using puppeteer and your Hyperbrowser API Key.

Node
Copy
import { connect } from "puppeteer-core";
import { config } from "dotenv";

config();

const main = async () => {
  const browser = await connect({
    browserWSEndpoint: `wss://connect.hyperbrowser.ai?apiKey=${process.env.HYPERBROWSER_API_KEY}`,
  });

  const [page] = await browser.pages();

  // Navigate to a website
  console.log("Navigating to Hacker News...");
  await page.goto("https://news.ycombinator.com/");
  const pageTitle = await page.title();
  console.log("Page 1:", pageTitle);
  await page.evaluate(() => {
    console.log("Page 1:", document.title);
  });

  await page.goto("https://example.com");
  console.log("Page 2:", await page.title());
  await page.evaluate(() => {
    console.log("Page 2:", document.title);
  });

  await page.goto("https://apple.com");
  console.log("Page 3:", await page.title());
  await page.evaluate(() => {
    console.log("Page 3:", document.title);
  });

  await page.goto("https://google.com");
  console.log("Page 4:", await page.title());
  await page.evaluate(() => {
    console.log("Page 4:", document.title);
  });

  // Clean up
  await browser.close();
};

main();
Python
Copy
import asyncio
from pyppeteer import connect
import os
from dotenv import load_dotenv

# Load environment variables from .env file
load_dotenv()

async def main():
    # Connect to the browser using the API key from environment variables
    browser = await connect(
        browserWSEndpoint=f"wss://connect.hyperbrowser.ai?apiKey={os.getenv('HYPERBROWSER_API_KEY')}"
    )

    pages = await browser.pages()
    page = pages[0]

    # Navigate to a website
    print("Navigating to Hacker News...")
    await page.goto("https://news.ycombinator.com/")
    page_title = await page.title()
    print("Page title:", page_title)
    await page.evaluate("() => { console.log('Page 1:', document.title); }")

    await page.goto("https://example.com")
    page_title = await page.title()
    print("Page title:", page_title)
    await page.evaluate("() => { console.log('Page 2:', document.title); }")

    await page.goto("https://apple.com")
    page_title = await page.title()
    print("Page title:", page_title)
    await page.evaluate("() => { console.log('Page 3:', document.title); }")

    await page.goto("https://google.com")
    page_title = await page.title()
    print("Page title:", page_title)
    await page.evaluate("() => { console.log('Page 4:', document.title); }")

    # Clean up
    await browser.close()

# Run the async main function
if __name__ == "__main__":
    asyncio.run(main())
View Session in Dashboard
You can view all your sessions in the dashboard and see their recordings or other key metrics like logs.

Playwright
Setup a browser session with Playwright.

Install Playwright and Hyperbrowser
Node
Copy
npm install playwright-core @hyperbrowser/sdk
or

Copy
yarn add playwright-core @hyperbrowser/sdk
Python
Copy
pip install playwright hyperbrowser
Setup your Environment
To use Hyperbrowser with your code, you will need an API Key. You can get one easily from the dashboard. Once you have your API Key, add it to your .env file as HYPERBROWSER_API_KEY .

Setup Browser Session
Next, you can easily startup a browser session using playwright and your Hyperbrowser API Key.

Node
Copy
import { chromium } from "playwright-core";
import { config } from "dotenv";

config();

const main = async () => {
  // Connect to browser using Playwright
  const browser = await chromium.connectOverCDP(
    `wss://connect.hyperbrowser.ai?apiKey=${process.env.HYPERBROWSER_API_KEY}`
  );

  // Create a new context and page
  const defaultContext = browser.contexts()[0];
  const page = defaultContext.pages()[0];

  // Navigate to a website
  console.log("Navigating to Hacker News...");
  await page.goto("https://news.ycombinator.com/");
  const pageTitle = await page.title();
  console.log("Page 1:", pageTitle);
  await page.evaluate(() => {
    console.log("Page 1:", document.title);
  });

  await page.goto("https://example.com");
  console.log("Page 2:", await page.title());
  await page.evaluate(() => {
    console.log("Page 2:", document.title);
  });

  await page.goto("https://apple.com");
  console.log("Page 3:", await page.title());
  await page.evaluate(() => {
    console.log("Page 3:", document.title);
  });

  await page.goto("https://google.com");
  console.log("Page 4:", await page.title());
  await page.evaluate(() => {
    console.log("Page 4:", document.title);
  });

  // Clean up
  await defaultContext.close();
  await browser.close();
};

main();
Python
Copy
import os
from playwright.sync_api import sync_playwright
from dotenv import load_dotenv

# Load environment variables from .env file
load_dotenv()

def main():
    with sync_playwright() as p:
        # Connect to browser using Playwright
        browser = p.chromium.connect_over_cdp(
            f"wss://connect.hyperbrowser.ai?apiKey={os.getenv('HYPERBROWSER_API_KEY')}"
        )

        # Get the default context and page
        default_context = browser.contexts[0]
        page = default_context.pages[0]

        # Navigate to various websites
        print("Navigating to Hacker News...")
        page.goto("https://news.ycombinator.com/")
        page_title = page.title()
        print("Page 1:", page_title)
        page.evaluate("() => { console.log('Page 1:', document.title); }")

        page.goto("https://example.com")
        print("Page 2:", page.title())
        page.evaluate("() => { console.log('Page 2:', document.title); }")

        page.goto("https://apple.com")
        print("Page 3:", page.title())
        page.evaluate("() => { console.log('Page 3:', document.title); }")

        page.goto("https://google.com")
        print("Page 4:", page.title())
        page.evaluate("() => { console.log('Page 4:', document.title); }")

        # Clean up
        default_context.close()
        browser.close()

if __name__ == "__main__":
    main()
View Session in Dashboard
You can view all your sessions in the dashboard and see their recordings or other key metrics like logs.

Selenium
Setup a browser session with Selenium.

Install Selenium and Hyperbrowser
Node
Copy
npm install selenium-webdriver @hyperbrowser/sdk
or

Copy
yarn add selenium-webdriver @hyperbrowser/sdk
Python
Copy
pip install selenium hyperbrowser
Setup your Environment
To use Hyperbrowser with your code, you will need an API Key. You can get one easily from the dashboard. Once you have your API Key, add it to your .env file as HYPERBROWSER_API_KEY .

Setup Browser Session
Next, you can easily startup a browser session using selenium and your Hyperbrowser API Key.

Node
Copy
import dotenv from 'dotenv';
import https from 'https';
import { Builder, WebDriver } from 'selenium-webdriver';
import { Options } from 'selenium-webdriver/chrome';
import { Hyperbrowser } from '@hyperbrowser/sdk';

// Load environment variables from .env file
dotenv.config();

const client = new Hyperbrowser({ apiKey: process.env.HYPERBROWSER_API_KEY as string });

async function main() {
    const session = await client.sessions.create();
    
    const customHttpsAgent = new https.Agent({});
    (customHttpsAgent as any).addRequest = (req: any, options: any) => {
        req.setHeader('x-hyperbrowser-token', session.token);
        (https.Agent.prototype as any).addRequest.call(customHttpsAgent, req, options);
    };

    const driver: WebDriver = await new Builder()
        .forBrowser('chrome')
        .usingHttpAgent(customHttpsAgent)
        .usingServer('https://connect.hyperbrowser.ai/webdriver')
        .setChromeOptions(new Options())
        .build();

    try {
        // Navigate to a URL
        await driver.get("https://www.google.com");
        console.log("Navigated to Google");
        
        // Search
        const searchBox = await driver.findElement({ name: "q" });
        await searchBox.sendKeys("Selenium WebDriver");
        await searchBox.submit();
        console.log("Performed search");
        
        // Screenshot
        await driver.takeScreenshot().then(data => {
            require('fs').writeFileSync('search_results.png', data, 'base64');
        });
        console.log("Screenshot saved");
    } finally {
        await driver.quit();
    }
}

if (require.main === module) {
    main().catch(console.error);
}
Python
Copy
import os
from dotenv import load_dotenv

from selenium import webdriver
from selenium.webdriver.remote.remote_connection import RemoteConnection
from selenium.webdriver.chrome.options import Options
from hyperbrowser import Hyperbrowser

# Load environment variables from .env file
load_dotenv()

client = Hyperbrowser(api_key=os.getenv("HYPERBROWSER_API_KEY"))

class CustomRC(RemoteConnection):
    _signing_key = None

    def __init__(self, server: str, token: str):
        super().__init__(server)
        self._token = token

    def get_remote_connection_headers(self, parsed_url, keep_alive=False):
        headers = super().get_remote_connection_headers(parsed_url, keep_alive)
        headers.update({'x-hyperbrowser-token': self._token})
        return headers

def main():
    session = client.sessions.create()
    custom_conn = CustomRC("https://connect.hyperbrowser.ai/webdriver", session.token)
    driver = webdriver.Remote(custom_conn, options=Options())

    # Navigate to a URL
    driver.get("https://www.google.com")
    print("Navigated to Google")
    
    # Search
    search_box = driver.find_element("name", "q")
    search_box.send_keys("Selenium WebDriver")
    search_box.submit()
    print("Performed search")
    
    # Screenshot
    driver.save_screenshot("search_results.png")
    print("Screenshot saved")

if __name__ == "__main__":
    main()
View Session in Dashboard
You can view all your sessions in the dashboard and see their recordings or other key metrics like logs.

Sessions
Overview
Learn about Hyperbrowser Sessions

In Hyperbrowser, a Session is simply a dedicated, cloud-based browser instance thats yours to direct. Its like opening a fresh, private browser windowonly this one lives in the cloud and is fully controllable through code. Each Session keeps its own cookies, storage, and browsing context, so you can run your tasks without mixing them up.

With our Sessions API, you can spin up these browser environments whenever you need them, configure them with optional parameters, and close them down when youre done. Higher level endpoints like scrape and crawl also utilize sessions internally to handle their tasks.

Connect with your favorite browser automation libraries
Puppeteer

Connect with Puppeteer to automate browser actions via a websocket connection

Playwright

Connect with Playwright to automate browser actions via a websocket connection

Check out our API Reference to see the Sessions API in more detail

Usage
Starting a session is pretty simple, you can either startup a session directly by connecting to our websocket endpoint with your preferred automation tool like Playwright or Puppeteer, or you can create a session via the Sessions API.

Simple Connect
With this approach, you can startup a session with all default configurations set by just changing one line.

Node
Puppeteer
Copy
const browser = await puppeteer.connect({
    browserWSEndpoint: `wss://connect.hyperbrowser.ai?apiKey=${process.env.HYPERBROWSER_API_KEY}`,
});
Playwright
Copy
const browser = await chromium.connectOverCDP(
    `wss://connect.hyperbrowser.ai?apiKey=${process.env.HYPERBROWSER_API_KEY}`
);
Python
Puppeteer
Copy
browser = await pyppeteer.connect(
    browserWSEndpoint=f"wss://connect.hyperbrowser.ai?apiKey={os.getenv('HYPERBROWSER_API_KEY')}"
)
Playwright
Copy
with sync_playwright() as p:
        browser = p.chromium.connect_over_cdp(
            f"wss://connect.hyperbrowser.ai?apiKey={os.getenv('HYPERBROWSER_API_KEY')}"
        )
Connect with Sessions API
With this approach, you have more control over your sessions with additional features or updated configurations.

Node
Puppeteer
Copy
import { connect } from "puppeteer-core";
import { Hyperbrowser } from "@hyperbrowser/sdk"
import { config } from "dotenv";

config();

const client = new Hyperbrowser({
  apiKey: process.env.HYPERBROWSER_API_KEY,
});

const main = async () => {
  const session = await client.sessions.create({
    solveCaptchas: true,
    useStealth: true,
    useProxy: true,
  });
  const browser = await connect({
    browserWSEndpoint: session.wsEndpoint,
  });

  const [page] = await browser.pages();

  // Navigate to a website
  console.log("Navigating to Hacker News...");
  await page.goto("https://news.ycombinator.com/");
  const pageTitle = await page.title();
  console.log("Page 1:", pageTitle);
  await page.evaluate(() => {
    console.log("Page 1:", document.title);
  });

  // Clean up
  await page.close();
  await browser.close();
  await client.sessions.stop(session.id);
};

main();
Playwright
Copy
import { chromium } from "playwright-core";
import { Hyperbrowser } from "@hyperbrowser/sdk";
import { config } from "dotenv";

config();

const client = new Hyperbrowser({
  apiKey: process.env.HYPERBROWSER_API_KEY,
});

const main = async () => {
  const session = await client.sessions.create({
    solveCaptchas: true,
    useStealth: true,
    useProxy: true,
  });

  const browser = await chromium.connectOverCDP(session.wsEndpoint);

  const context = await browser.newContext();
  const page = await context.newPage();

  // Navigate to a website
  console.log("Navigating to Hacker News...");
  await page.goto("https://news.ycombinator.com/");
  const pageTitle = await page.title();
  console.log("Page 1:", pageTitle);
  await page.evaluate(() => {
    console.log("Page 1:", document.title);
  });

  // Clean up
  await page.close();
  await context.close();
  await browser.close();
  await client.sessions.stop(session.id);
};

main();
Python
Puppeteer
Copy
import asyncio
from pyppeteer import connect
import os
from dotenv import load_dotenv
from hyperbrowser import AsyncHyperbrowser
from hyperbrowser.models.session import CreateSessionParams

# Load environment variables from .env file
load_dotenv()

client = AsyncHyperbrowser(api_key=os.getenv("HYPERBROWSER_API_KEY"))


async def main():
    # Create a session and connect to it using Pyppeteer
    session = await client.sessions.create(
        params=CreateSessionParams(
            solve_captchas=True, use_stealth=True, use_proxy=True
        )
    )
    browser = await connect(browserWSEndpoint=session.ws_endpoint)

    pages = await browser.pages()
    page = pages[0]

    # Navigate to a website
    print("Navigating to Hacker News...")
    await page.goto("https://news.ycombinator.com/")
    page_title = await page.title()
    print("Page title:", page_title)
    await page.evaluate("() => { console.log('Page 1:', document.title); }")

    # Clean up
    await browser.close()
    await client.sessions.stop(session.id)

# Run the async main function
if __name__ == "__main__":
    asyncio.run(main())
Playwright
Copy
import asyncio
from playwright.async_api import async_playwright
import os
from dotenv import load_dotenv
from hyperbrowser import AsyncHyperbrowser
# You can also use the sync `Hyperbrowser` to work with sync_playwright
from hyperbrowser.models.session import CreateSessionParams

# Load environment variables from .env file
load_dotenv()

client = AsyncHyperbrowser(api_key=os.getenv("HYPERBROWSER_API_KEY"))


async def main():
    # Create a session and connect to it using Playwright
    session = await client.sessions.create(
        params=CreateSessionParams(
            solve_captchas=True, use_stealth=True, use_proxy=True
        )
    )

    # Initialize Playwright and connect to the browser
    async with async_playwright() as p:
        browser = await p.chromium.connect_over_cdp(session.ws_endpoint)
        default_context = browser.contexts[0]
        page = default_context.pages[0]

        # Navigate to a website
        print("Navigating to Hacker News...")
        await page.goto("https://news.ycombinator.com/")
        page_title = await page.title()
        print("Page title:", page_title)
        await page.evaluate("() => { console.log('Page 1:', document.title); }")

        # Clean up
        await browser.close()
        await client.sessions.stop(session.id)


# Run the async main function
if __name__ == "__main__":
    asyncio.run(main())
Hyperbrowser's CAPTCHA solving and Proxy features require being on a PAID plan.

Advanced Privacy & Anti-Detection
Hyperbrowser Anti-Bot Detection

Sometimes you need your automated browser sessions to fly under the radar. With Hyperbrowsers privacy and anti-detection features, you can tweak things like browser fingerprints, pick the right proxies, and decide exactly how requests get routed. This helps your automated visits look and feel more like regular browsingsomething thats especially handy if youre dealing with strict anti-bot measures or running sensitive operations.

Whether you need to appear as if youre browsing from a specific region, or you want to vary details like your device type and OS, its all possible. You can set things up so your workflows feel less like scripted tasks and more like genuine user behavior. Add in built-in captcha-solving capabilities, and youve got a setup that keeps you moving forward, even if the sites youre visiting throw a few hurdles your way.

Stealth Mode
Stealth mode helps you avoid detection by anti-bot systems. It randomizes browser fingerprints and can be configured when creating a new session via the API. Options include:

Devices - Specify mobile or desktop device profiles

Locales - Set browser locale (e.g. en-US, fr-FR)

Operating Systems - Simulate different OSes like Android, iOS, Windows, macOS, Linux

Screen Size - Specify viewport dimensions to emulate different devices

User Agents - Rotate user agent strings

To enable stealth mode and other stealth configurations, you can set the desired options in the session creation params when creating a session.

Node
Copy
import { connect } from "puppeteer-core";
import { Hyperbrowser } from "@hyperbrowser/sdk";
import { config } from "dotenv";

config();

const client = new Hyperbrowser({
  apiKey: process.env.HYPERBROWSER_API_KEY,
});

const main = async () => {
  const session = await client.sessions.create({
    useStealth: true,
    operatingSystems: ["macos"],
    device: ["desktop"],
    locales: ["en"],
    screen: {
      width: 1920,
      height: 1080,
    },
  });
  const browser = await connect({
    browserWSEndpoint: session.wsEndpoint,
  });

  const [page] = await browser.pages();

  // Navigate to a website
  console.log("Navigating to Hacker News...");
  await page.goto("https://news.ycombinator.com/");
  const pageTitle = await page.title();
  console.log("Page 1:", pageTitle);
  await page.evaluate(() => {
    console.log("Page 1:", document.title);
  });

  // Clean up
  await page.close();
  await browser.close();
  await client.sessions.stop(session.id);
};

main();
Python
Copy
import asyncio
from pyppeteer import connect
import os
from dotenv import load_dotenv
from hyperbrowser import AsyncHyperbrowser
from hyperbrowser.models.session import CreateSessionParams, ScreenConfig

# Load environment variables from .env file
load_dotenv()

client = AsyncHyperbrowser(api_key=os.getenv("HYPERBROWSER_API_KEY"))


async def main():
    # Create a session and connect to it using Pyppeteer
    session = await client.sessions.create(
        params=CreateSessionParams(
            use_stealth=True,
            operating_systems=["macos"],
            device=["desktop"],
            locales=["en"],
            screen=ScreenConfig(width=1920, height=1080),
        )
    )
    browser = connect(browserWSEndpoint=session.ws_endpoint)

    pages = await browser.pages()
    page = pages[0]

    # Navigate to a website
    print("Navigating to Hacker News...")
    await page.goto("https://news.ycombinator.com/")
    page_title = await page.title()
    print("Page title:", page_title)
    await page.evaluate("() => { console.log('Page 1:', document.title); }")

    # Clean up
    await page.close()
    await browser.close()
    await client.sessions.stop(session.id)

# Run the async main function
if __name__ == "__main__":
    asyncio.get_event_loop().run_until_complete(main())
To see all the available options, check out the Create Session API Reference

Proxies
Route browser traffic through proxies to change IP addresses. You can:

Use Hyperbrowser's proxy pool

Bring your own proxies

To enable these proxy configurations, you can set them in the session creation params.

Node
Copy
import { connect } from "puppeteer-core";
import { Hyperbrowser } from "@hyperbrowser/sdk";
import { config } from "dotenv";

config();

const client = new Hyperbrowser({
  apiKey: process.env.HYPERBROWSER_API_KEY,
});

const main = async () => {
  const session = await client.sessions.create({
    useProxy: true,
    proxyCountry: "US",
    // use own proxy
    proxyServer: "...",
    proxyServerUsername: "...",
    proxyServerPassword: "...",
  });
  const browser = await connect({
    browserWSEndpoint: session.wsEndpoint,
  });

  const [page] = await browser.pages();

  // Navigate to a website
  console.log("Navigating to Hacker News...");
  await page.goto("https://news.ycombinator.com/");
  const pageTitle = await page.title();
  console.log("Page 1:", pageTitle);
  await page.evaluate(() => {
    console.log("Page 1:", document.title);
  });

  // Clean up
  await page.close();
  await browser.close();
  await client.sessions.stop(session.id);
};

main();
Python
Copy
import asyncio
from pyppeteer import connect
import os
from dotenv import load_dotenv
from hyperbrowser import AsyncHyperbrowser
from hyperbrowser.models.session import CreateSessionParams

# Load environment variables from .env file
load_dotenv()

client = AsyncHyperbrowser(api_key=os.getenv("HYPERBROWSER_API_KEY"))


async def main():
    # Create a session and connect to it using Pyppeteer
    session = await client.sessions.create(
        params=CreateSessionParams(
            use_proxy=True,
            proxy_country="US",
            # use own proxy
            proxy_server="...",
            proxy_server_username="...",
            proxy_server_password="...",
        )
    )
    browser = connect(browserWSEndpoint=session.ws_endpoint)

    pages = await browser.pages()
    page = pages[0]

    # Navigate to a website
    print("Navigating to Hacker News...")
    await page.goto("https://news.ycombinator.com/")
    page_title = await page.title()
    print("Page title:", page_title)
    await page.evaluate("() => { console.log('Page 1:', document.title); }")

    # Clean up
    await page.close()
    await browser.close()
    await client.sessions.stop(session.id)

# Run the async main function
if __name__ == "__main__":
    asyncio.get_event_loop().run_until_complete(main())
Using proxies can introduce latency to any page navigations, so make sure to properly await these navigations with timeouts. 

Proxy usage is only available on the PAID plans.

CAPTCHA Solving
Hyperbrowser automatically solves CAPTCHAs when the solveCaptchas parameter is set to true for session creation.

Node
Copy
import { connect } from "puppeteer-core";
import { Hyperbrowser } from "@hyperbrowser/sdk";
import { config } from "dotenv";

config();

const client = new Hyperbrowser({
  apiKey: process.env.HYPERBROWSER_API_KEY,
});

const main = async () => {
  const session = await client.sessions.create({
    solveCaptchas: true,
  });
  const browser = await connect({
    browserWSEndpoint: session.wsEndpoint,
  });

  const [page] = await browser.pages();

  // Navigate to a website
  console.log("Navigating to Hacker News...");
  await page.goto("https://news.ycombinator.com/");
  const pageTitle = await page.title();
  console.log("Page 1:", pageTitle);
  await page.evaluate(() => {
    console.log("Page 1:", document.title);
  });

  // Clean up
  await page.close();
  await browser.close();
  await client.sessions.stop(session.id);
};

main();
Python
Copy
import asyncio
from pyppeteer import connect
import os
from dotenv import load_dotenv
from hyperbrowser import AsyncHyperbrowser
from hyperbrowser.models.session import CreateSessionParams

# Load environment variables from .env file
load_dotenv()

client = AsyncHyperbrowser(api_key=os.getenv("HYPERBROWSER_API_KEY"))


async def main():
    # Create a session and connect to it using Pyppeteer
    session = await client.sessions.create(
        params=CreateSessionParams(
           solve_captchas=True,
        )
    )
    browser = connect(browserWSEndpoint=session.ws_endpoint)

    pages = await browser.pages()
    page = pages[0]

    # Navigate to a website
    print("Navigating to Hacker News...")
    await page.goto("https://news.ycombinator.com/")
    page_title = await page.title()
    print("Page title:", page_title)
    await page.evaluate("() => { console.log('Page 1:', document.title); }")

    # Clean up
    await page.close()
    await browser.close()
    await client.sessions.stop(session.id)

# Run the async main function
if __name__ == "__main__":
    asyncio.get_event_loop().run_until_complete(main())
Captcha solving can take a bit of time, so make sure to implement proper waiting strategies when navigating to pages that might contain CAPTCHAs:

Copy
await page.goto("https://news.ycombinator.com/",
    { waitUntil: "networkidle0" }
);

// OR
const sleep = (ms) => new Promise((res) => setTimeout(res, ms));

await page.waitForNavigation({ waitUntil: "networkidle0"});
await sleep(15000);
CAPTCHA solving is only available on PAID plans.

Ad Blocking
Hyperbrowser's browser instances can automatically block ads and trackers. This improves page load times and further reduces detection risk. In addition to ads, Hyperbrowser allows you to block trackers and other annoyances including cookie notices.

To enable ad blocking, set the proper configurations in the session create parameters.

Node
Copy
import { connect } from "puppeteer-core";
import { Hyperbrowser } from "@hyperbrowser/sdk";
import { config } from "dotenv";

config();

const client = new Hyperbrowser({
  apiKey: process.env.HYPERBROWSER_API_KEY,
});

const main = async () => {
  const session = await client.sessions.create({
    adblock: true,
    trackers: true,
    annoyances: true,
    // You must have trackers set to true to enable blocking annoyances and
    // adblock set to true to enable blocking trackers.
  });
  const browser = await connect({
    browserWSEndpoint: session.wsEndpoint,
  });

  const [page] = await browser.pages();

  // Navigate to a website
  console.log("Navigating to Hacker News...");
  await page.goto("https://news.ycombinator.com/");
  const pageTitle = await page.title();
  console.log("Page 1:", pageTitle);
  await page.evaluate(() => {
    console.log("Page 1:", document.title);
  });

  // Clean up
  await page.close();
  await browser.close();
  await client.sessions.stop(session.id);
};

main();
Python
Copy
import asyncio
from pyppeteer import connect
import os
from dotenv import load_dotenv
from hyperbrowser import AsyncHyperbrowser
from hyperbrowser.models.session import CreateSessionParams

# Load environment variables from .env file
load_dotenv()

client = AsyncHyperbrowser(api_key=os.getenv("HYPERBROWSER_API_KEY"))


async def main():
    # Create a session and connect to it using Pyppeteer
    session = await client.sessions.create(
        params=CreateSessionParams(
           adblock=True,
           trackers=True,
           annoyances=True,
           # You must have trackers set to true to enable blocking annoyances and
           # adblock set to true to enable blocking trackers.
        )
    )
    browser = connect(browserWSEndpoint=session.ws_endpoint)

    pages = await browser.pages()
    page = pages[0]

    # Navigate to a website
    print("Navigating to Hacker News...")
    await page.goto("https://news.ycombinator.com/")
    page_title = await page.title()
    print("Page title:", page_title)
    await page.evaluate("() => { console.log('Page 1:', document.title); }")

    # Clean up
    await page.close()
    await browser.close()
    await client.sessions.stop(session.id)

# Run the async main function
if __name__ == "__main__":
    asyncio.get_event_loop().run_until_complete(main())
Profiles
Hyperbrowser Browser Profiles

Hyperbrowser profiles allow you to reuse browser state like cookies, local storage, and network cache across multiple sessions. This can improve performance and enable seamless workflows requiring persistent data.

How Profiles Work
A profile is essentially a saved snapshot of a browser's user data directory. By default, each Hyperbrowser session uses a fresh user data directory to ensure isolation.

When you create a profile and then use and persist it in a new session, Hyperbrowser saves that session's user data directory. You can then attach the profile to future sessions to pick up where you left off.

Common use cases for profiles include:

Reusing authenticated sessions

Improving page load times with a primed cache

Preserving application state across sessions

Using Profiles
1. Create a Profile
First, create a new profile using the Profiles API. Note the returned id - you'll need this to attach the profile to sessions.

Node
Copy
const profile = await client.profiles.create();
console.log("profile", profile.id);
Python
Copy
profile = client.profiles.create()
print("profile", profile.id)
cURL
Copy
curl -X POST 'https://app.hyperbrowser.ai/api/profile' \
-H 'Content-Type: application/json' \
-H 'x-api-key: YOUR_API_KEY' \
-d '{}'
2. Attach Profile to Session
When creating a new session with the Sessions API, include the id in the profile field:

Node
Copy
const session = await client.sessions.create({
  profile: {
    id: "<PROFILE_ID>",
    persistChanges: true, // set to true for the first session of a new profile
  },
});
Python
Copy
session = client.sessions.create(
    params=CreateSessionParams(
        profile=CreateSessionProfile(
            id="<PROFILE_ID>",
            # set to true for the first session of a new profile
            persist_changes=True,
        ),
    )
)
cURL
Copy
curl -X POST 'https://app.hyperbrowser.ai/api/session' \
-H 'Content-Type: application/json' \
-H 'x-api-key: YOUR_API_KEY' \
-d '{
    "profile": {
      "id": "<PROFILE_ID>"
    }
}'
Set "persistChanges": true in the profile object if you want the session to update the profile with any changes to cookies, cache, etc. You will need to do this for the first time you use a new profile in a session so it can be used in subsequent sessions. 

3. Reuse Profile
Attach the same id to additional sessions to reuse browser state. Created profiles are reusable until you delete them.

Deleting Profiles
Delete unused profiles to free up resources. Once deleted, a profile is no longer attachable to sessions.

To delete a profile, send a DELETE request to the Profiles API with the target id:

Node
Copy
const response = await client.profiles.delete("<PROFILE_ID>");
console.log("response", response);
Python
Copy
response = client.profiles.delete("<PROFILE_ID>")
print("response", response)
cURL
Copy
curl -X DELETE 'https://app.hyperbrowser.ai/api/profile/<PROFILE_ID>' \
-H 'x-api-key: YOUR_API_KEY'
Deletion is irreversible, so be sure you no longer need a profile before deleting.

Recordings
Hyperbrowser Session Recordings

Hyperbrowser allows you to record and replay your browser sessions. It uses rrweb, an open-source web session replay library. Session recordings let you:

Visually debug test failures and errors

Analyze user behavior and interactions

Share reproducible bug reports

Save and archive session data

Enabling Session Recording
To record a session, set the enableWebRecording option to true when creating a new Hyperbrowser session:

Node
Copy
import { Hyperbrowser } from "@hyperbrowser/sdk";
import { config } from "dotenv";

config();

const client = new Hyperbrowser({
  apiKey: process.env.HYPERBROWSER_API_KEY,
});

const main = async () => {
  const session = await client.sessions.create({
    enableWebRecording: true,
  });
};

main();
Python
Copy
import asyncio
import os
from dotenv import load_dotenv
from hyperbrowser import AsyncHyperbrowser
from hyperbrowser.models.session import CreateSessionParams

load_dotenv()

client = AsyncHyperbrowser(api_key=os.getenv("HYPERBROWSER_API_KEY"))


async def main():
    session = await client.sessions.create(
        params=CreateSessionParams(
            enable_web_recording=True,
        )
    )


if __name__ == "__main__":
    import asyncio

    asyncio.run(main())
This will record all browser interactions, DOM changes, and network requests for the duration of the session.

Retrieving Recordings
Please contact us at info@hyperbrowser.ai to get access to this feature.

Recorded sessions are automatically saved when the Hyperbrowser session ends. To retrieve a session recording:

Note the id of the session you want to replay

Use the Session Recordings API to download the recording, or if you are using the SDKs, you can just call the getRecording function:

Node
Copy
import { Hyperbrowser } from "@hyperbrowser/sdk";
import { config } from "dotenv";

config();

const client = new Hyperbrowser({
  apiKey: process.env.HYPERBROWSER_API_KEY,
});

const main = async () => {
  const recordingData = await client.sessions.getRecording(
    "91e96d43-0dd2-4882-8d3a-613b12583ba2"
  );
};

main();
Python
Copy
import asyncio
import os
from dotenv import load_dotenv
from hyperbrowser import AsyncHyperbrowser

load_dotenv()

client = AsyncHyperbrowser(api_key=os.getenv("HYPERBROWSER_API_KEY"))


async def main():
    recording_data = await client.sessions.get_recording(
        "91e96d43-0dd2-4882-8d3a-613b12583ba2"
    )


if __name__ == "__main__":
    import asyncio

    asyncio.run(main())
cURL
Copy
curl -X GET 'https://app.hyperbrowser.ai/api/session/{sessionId}/recording' \
-H 'x-api-key: YOUR_API_KEY
The recording data will be returned in rrweb's JSON format.

Replaying Recordings
To replay a session recording, you can use rrweb's player UI or build your own playback interface.

Using rrweb's Player
Here's an example of using rrweb's player to replay a recording:

Include the rrweb player script on your page:

Copy
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/rrweb@latest/dist/rrweb.min.css"/>
<script src="https://cdn.jsdelivr.net/npm/rrweb@latest/dist/rrweb.min.js"></script>
Add a container element for the player:

Copy
<div id="player"></div>
Initialize the player with your recording data:

Copy
// if using rrweb npm package
import rrwebPlayer from "rrweb-player";
import "rrweb-player/dist/style.css";

const recordingData = YOUR_RECORDING_DATA

const replayer = new rrwebPlayer({
  target: document.getElementById('player'),
  props: {
    events: recordingData,
    showController: true,
    autoPlay: true,
  },
});
This will launch an interactive player UI that allows you to play, pause, rewind, and inspect the recorded session.

Building a Custom Player
You can also use rrweb's APIs to build your own playback UI. Refer to the rrweb documentation for thorough details on how to customize the Replayer to your needs.

Storage and Retention
Session recordings are stored securely in Hyperbrowser's cloud infrastructure. Recordings are retained according to your plan's data retention policy.

Limitations
Session recordings capture only the visual state of the page. They do not include server-side logs, database changes, or other non-DOM modifications.

Recordings may not perfectly reproduce complex WebGL or canvas-based animations.

Live View
Hyperbrowser Live View

Hyperbrowser's Live View feature allows you to observe and interact with your browser sessions in real-time. You can use Live View to:

Debug and troubleshoot your scripts

Monitor the progress of long-running automations

Provide a way for end-users to interact with the browser

How it Works
Live View works by providing a secure, authenticated URL that embeds a live stream of the browser session. The URL can be accessed in any modern web browser.

Whenever you create a new session or get the details of an existing session, Hyperbrowser returns a liveUrl field with a unique URL tied to that specific session. The URL remains valid as long as the session is active and the token in the URL hasn't expired (Securing Live View).

Node
Copy
const session = await hbClient.sessions.create();
const liveUrl = session.liveUrl;
Python
Copy
session = hb_client.sessions.create()
live_url = session.live_url
The returned liveUrl will look something like:

Copy
https://app.hyperbrowser.ai/live?token=<TOKEN>&keepAlive=true
You can now open this URL in a web browser to view the live session.

Embedding Live View
You can embed a Live View into your own web application using an iframe:

Copy
<iframe src="<LIVE_URL>"></iframe>
This is useful for providing a seamless experience to your end-users. For example, you could use an embedded Live View to:

Show the progress of a web scraping job

Allow users to complete a complex workflow that requires manual intervention

Provide a preview of an automated process before committing it

Securing Live View
Live View URLs are secured with authentication and encryption. Only users with the correct URL can access the Live View.

However, anyone with the URL can view (and potentially interact with) the session. Be sure to protect Live View URLs as sensitive secrets, especially if you're embedding them in a public web page.

The token in the liveUrl will expire after 12 hours. In this case, you can simply call the GET request for the Sessions API to get the details for the given session id which will also return a new liveUrl with a refreshed token.

Web Scraping
Scrape
Scrape any page and get formatted data

The Scrape API allows you to get the data you want from web pages using with a single call. You can scrape page content and capture it's data in various formats.

For detailed usage, checkout the Scrape API Reference

Hyperbrowser exposes endpoints for starting a scrape request and for getting it's status and results. By default, scraping is handled in an asynchronous manner of first starting the job and then checking it's status until it is completed. However, with our SDKs, we provide a simple function that handles the whole flow and returns the data once the job is completed.

Installation
Node
Copy
npm install @hyperbrowser/sdk
or

Copy
yarn add @hyperbrowser/sdk
Python
Copy
pip install hyperbrowser
Usage
Node
Copy
import { Hyperbrowser } from "@hyperbrowser/sdk";
import { config } from "dotenv";

config();

const client = new Hyperbrowser({
  apiKey: process.env.HYPERBROWSER_API_KEY,
});

const main = async () => {
  // Handles both starting and waiting for scrape job response
  const scrapeResult = await client.scrape.startAndWait({
    url: "https://example.com",
  });
  console.log("Scrape result:", scrapeResult);
};

main();
Python
Copy
import os
from dotenv import load_dotenv
from hyperbrowser import Hyperbrowser
from hyperbrowser.models.scrape import StartScrapeJobParams

# Load environment variables from .env file
load_dotenv()

# Initialize Hyperbrowser client
client = Hyperbrowser(api_key=os.getenv("HYPERBROWSER_API_KEY"))


# Start scraping and wait for completion
scrape_result = client.scrape.start_and_wait(
    StartScrapeJobParams(url="https://example.com")
)
print("Scrape result:", scrape_result)
cURL
Start Scrape Job

Copy
curl -X POST https://app.hyperbrowser.ai/api/scrape \
    -H 'Content-Type: application/json' \
    -H 'x-api-key: <YOUR_API_KEY>' \
    -d '{
        "url": "https://example.com"
    }'
Get Scrape Job Status and Data

Copy
curl https://app.hyperbrowser.ai/api/scrape/{jobId} \
    -H 'x-api-key: <YOUR_API_KEY>'
Response
The Start Scrape Job POST /scrape  endpoint will return a jobId in the response which can be used to get information about the job in subsequent requests.

Copy
{
    "jobId": "962372c4-a140-400b-8c26-4ffe21d9fb9c"
}
The Get Scrape Job GET /scrape/{jobId}  will return the following data:

Copy
{
  "jobId": "962372c4-a140-400b-8c26-4ffe21d9fb9c",
  "status": "completed",
  "data": {
    "metadata": {
      "title": "Example Page",
      "description": "A sample webpage"
    },
    "markdown": "# Example Page\nThis is content...",
  }
}
The status of a scrape job can be one of pending, running, completed, failed . There can also be other optional fields like error with an error message if an error was encountered, and html and links in the data object depending on which formats are requested for the request.

To see the full schema, checkout the API Reference.

Session Configurations
You can also provide configurations for the session that will be used to execute the scrape job just as you would when creating a new session itself. These could include using a proxy or solving CAPTCHAs.

Node
Copy
import { Hyperbrowser } from "@hyperbrowser/sdk";
import { config } from "dotenv";

config();

const client = new Hyperbrowser({
  apiKey: process.env.HYPERBROWSER_API_KEY,
});

const main = async () => {
  const scrapeResult = await client.scrape.startAndWait({
    url: "https://example.com",
    sessionOptions: {
      useProxy: true,
      solveCaptchas: true,
      proxyCountry: "US",
      locales: ["en"],
    },
  });
  console.log("Scrape result:", scrapeResult);
};

main();
Python
Copy
import os
from dotenv import load_dotenv
from hyperbrowser import Hyperbrowser
from hyperbrowser.models.scrape import StartScrapeJobParams
from hyperbrowser.models.session import CreateSessionParams

# Load environment variables from .env file
load_dotenv()

# Initialize Hyperbrowser client
client = Hyperbrowser(api_key=os.getenv("HYPERBROWSER_API_KEY"))


# Start scraping and wait for completion
scrape_result = client.scrape.start_and_wait(
    StartScrapeJobParams(
        url="https://example.com",
        session_options=CreateSessionParams(use_proxy=True, solve_captchas=True),
    )
)
print("Scrape result:", scrape_result)
Using proxy and solving CAPTCHAs will slow down the scrape so use it if necessary.

Scrape Configurations
You can also provide optional parameters for the scrape job itself such as the formats to return, only returning the main content of the page, setting the maximum timeout for navigating to a page, etc.

Node
Copy
import { Hyperbrowser } from "@hyperbrowser/sdk";
import { config } from "dotenv";

config();

const client = new Hyperbrowser({
  apiKey: process.env.HYPERBROWSER_API_KEY,
});

const main = async () => {
  const scrapeResult = await client.scrape.startAndWait({
    url: "https://example.com",
    scrapeOptions: {
      formats: ["markdown", "html", "links"],
      onlyMainContent: false,
      timeout: 15000,
    },
  });
  console.log("Scrape result:", scrapeResult);
};

main();
Python
Copy
import os
from dotenv import load_dotenv
from hyperbrowser import Hyperbrowser
from hyperbrowser.models.scrape import ScrapeOptions, StartScrapeJobParams

# Load environment variables from .env file
load_dotenv()

# Initialize Hyperbrowser client
client = Hyperbrowser(api_key=os.getenv("HYPERBROWSER_API_KEY"))


# Start scraping and wait for completion
scrape_result = client.scrape.start_and_wait(
    StartScrapeJobParams(
        url="https://example.com",
        scrape_options=ScrapeOptions(
            formats=["html", "links", "markdown"], only_main_content=False, timeout=5000
        ),
    )
)
print("Scrape result:", scrape_result)
For a full reference on the scrape endpoint, checkout the API Reference, or read the Advanced Scraping Guide to see more advanced options for scraping.

Batch Scrape
Batch Scrape works the same as regular scrape, except instead of a single URL, you can provide a list of up to 1,000 URLs to scrape at once.

Batch Scrape is currently only available on the Ultra plan.

Node
Copy
import { Hyperbrowser } from "@hyperbrowser/sdk";
import { config } from "dotenv";

config();

const client = new Hyperbrowser({
  apiKey: process.env.HYPERBROWSER_API_KEY,
});

const main = async () => {
  const scrapeResult = await client.scrape.batch.startAndWait({
    urls: ["https://example.com", "https://hyperbrowser.ai"],
    scrapeOptions: {
      formats: ["markdown", "html", "links"],
    },
  });
  console.log("Scrape result:", scrapeResult);
};

main();
Python
Copy
import os
from dotenv import load_dotenv
from hyperbrowser import Hyperbrowser
from hyperbrowser.models.scrape import ScrapeOptions, StartBatchScrapeJobParams

load_dotenv()

client = Hyperbrowser(api_key=os.getenv("HYPERBROWSER_API_KEY"))


scrape_result = client.scrape.batch.start_and_wait(
    StartBatchScrapeJobParams(
        urls=["https://example.com", "https://hyperbrowser.ai"],
        scrape_options=ScrapeOptions(
            formats=["html", "links", "markdown"]
        ),
    )
)
print("Scrape result:", scrape_result)
Response
The Start Batch Scrape Job POST /scrape/batch  endpoint will return a jobId in the response which can be used to get information about the job in subsequent requests.

Copy
{
    "jobId": "962372c4-a140-400b-8c26-4ffe21d9fb9c"
}
The Get Batch Scrape Job GET /scrape/batch/{jobId}  will return the following data:

Copy
{
    "jobId": "962372c4-a140-400b-8c26-4ffe21d9fb9c",
    "status": "completed",
    "totalScrapedPages": 2,
    "totalPageBatches": 1,
    "currentPageBatch": 1,
    "batchSize": 20,
    "data": [
        {
            "markdown": "Hyperbrowser\n\n[Home](https://hyperbrowser.ai/)...",
            "metadata": {
                "url": "https://www.hyperbrowser.ai/",
                "title": "Hyperbrowser",
                "viewport": "width=device-width, initial-scale=1",
                "link:icon": "https://www.hyperbrowser.ai/favicon.ico",
                "sourceURL": "https://hyperbrowser.ai",
                "description": "Infinite Browsers"
            },
            "url": "hyperbrowser.ai",
            "status": "completed",
            "error": null
        },
        {
            "markdown": "Example Domain\n\n# Example Domain...",
            "metadata": {
                "url": "https://www.example.com/",
                "title": "Example Domain",
                "viewport": "width=device-width, initial-scale=1",
                "sourceURL": "https://example.com"
            },
            "url": "example.com",
            "status": "completed",
            "error": null
        }
    ]
}
The status of a batch scrape job can be one of pending, running, completed, failed . The results of all the scrapes will be an array in the data field of the response. Each scraped page will be returned in the order of the initial provided urls, and each one will have its own status and information.

To see the full schema, checkout the API Reference.

As with the single scrape, by default, batch scraping is handled in an asynchronous manner of first starting the job and then checking it's status until it is completed. However, with our SDKs, we provide a simple function (client.scrape.batch.startAndWait) that handles the whole flow and returns the data once the job is completed.

Crawl
Crawl a website and it's links to extract all it's data

The Crawl API allows you to crawl through an entire website and get all it's data with a single call.

For detailed usage, checkout the Crawl API Reference

Hyperbrowser exposes endpoints for starting a crawl request and for getting it's status and results. By default, crawling is handled in an asynchronous manner of first starting the job and then checking it's status until it is completed. However, with our SDKs, we provide a simple function that handles the whole flow and returns the data once the job is completed.

Installation
Node
Copy
npm install @hyperbrowser/sdk
or

Copy
yarn add @hyperbrowser/sdk
Python
Copy
pip install hyperbrowser
Usage
Node
Copy
import { Hyperbrowser } from "@hyperbrowser/sdk";
import { config } from "dotenv";

config();

const client = new Hyperbrowser({
  apiKey: process.env.HYPERBROWSER_API_KEY,
});

const main = async () => {
  // Handles both starting and waiting for crawl job response
  const crawlResult = await client.crawl.startAndWait({
    url: "https://hyperbrowser.ai",
  });
  console.log("Crawl result:", crawlResult);
};

main();
Python
Copy
import os
from dotenv import load_dotenv
from hyperbrowser import Hyperbrowser
from hyperbrowser.models.crawl import StartCrawlJobParams

# Load environment variables from .env file
load_dotenv()

# Initialize Hyperbrowser client
client = Hyperbrowser(api_key=os.getenv("HYPERBROWSER_API_KEY"))


# Start crawling and wait for completion
crawl_result = client.crawl.start_and_wait(
    StartCrawlJobParams(url="https://hyperbrowser.ai")
)
print("Crawl result:", crawl_result)
cURL
Start Crawl Job

Copy
curl -X POST https://app.hyperbrowser.ai/api/crawl \
    -H 'Content-Type: application/json' \
    -H 'x-api-key: <YOUR_API_KEY>' \
    -d '{
        "url": "https://hyperbrowser.ai"
    }'
Get Crawl Job Status and Data

Copy
curl https://app.hyperbrowser.ai/api/crawl/{jobId} \
    -H 'x-api-key: <YOUR_API_KEY>'
Response
The Start Crawl Job POST /crawl  endpoint will return a jobId in the response which can be used to get information about the job in subsequent requests.

Copy
{
    "jobId": "962372c4-a140-400b-8c26-4ffe21d9fb9c"
}
The Get Crawl Job GET /crawl/{jobId}  will return the following data:

Copy
{
  "jobId": "962372c4-a140-400b-8c26-4ffe21d9fb9c",
  "status": "completed",
  "totalCrawledPages": 2,
  "totalPageBatches": 1,
  "currentPageBatch": 1,
  "batchSize": 20,
  "data": [
    {
      "url": "https://example.com",
      "status": "completed",
      "metadata": {
        "title": "Example Page",
        "description": "A sample webpage"
      },
      "markdown": "# Example Page\nThis is content...",
    },
    ...
  ]
}
The status of a crawl job can be one of pending, running, completed, failed . There can also be other optional fields like error with an error message if an error was encountered, and html and links in the data object depending on which formats are requested for the request.

Unlike the scrape endpoint, the crawl endpoint returns a list in the data field with the all the pages that were crawled in the current page batch. The SDKs also provide a function which will start the crawl job, wait until it's complete, and return all the crawled pages for the entire crawl.

Each crawled page has it's own status of completed or failed and can have it's own error field, so be cautious of that.

To see the full schema, checkout the API Reference.

Additional Crawl Configurations
The crawl endpoint provides additional parameters you can provide to tailor the crawl to your needs. You can narrow down the pages crawled by setting a limit to the maximum number of pages visited, only including paths that match a certain pattern, excluding paths that match another pattern, etc.

Node
Copy
import { Hyperbrowser } from "@hyperbrowser/sdk";
import { config } from "dotenv";

config();

const client = new Hyperbrowser({
  apiKey: process.env.HYPERBROWSER_API_KEY,
});

const main = async () => {
  // Handles both starting and waiting for crawl job response
  const crawlResult = await client.crawl.startAndWait({
    url: "https://hyperbrowser.ai",
    maxPages: 5,
    includePatterns: ["/blogs/*"],
  });
  console.log("Crawl result:", crawlResult);
};

main();
Python
Copy
import os
from dotenv import load_dotenv
from hyperbrowser import Hyperbrowser
from hyperbrowser.models.crawl import StartCrawlJobParams

# Load environment variables from .env file
load_dotenv()

# Initialize Hyperbrowser client
client = Hyperbrowser(api_key=os.getenv("HYPERBROWSER_API_KEY"))


# Start crawling and wait for completion
crawl_result = client.crawl.start_and_wait(
    StartCrawlJobParams(
        url="https://hyperbrowser.ai",
        max_pages=5,
        include_patterns: ["/blogs/*"],
    )
)
print("Crawl result:", crawl_result)
Session Configurations
You can also provide configurations for the session that will be used to execute the crawl job just as you would when creating a new session itself. These could include using a proxy or solving CAPTCHAs.

Node
Copy
import { Hyperbrowser } from "@hyperbrowser/sdk";
import { config } from "dotenv";

config();

const client = new Hyperbrowser({
  apiKey: process.env.HYPERBROWSER_API_KEY,
});

const main = async () => {
  const crawlResult = await client.crawl.startAndWait({
    url: "https://example.com",
    sessionOptions: {
      useProxy: true,
      solveCaptchas: true,
      proxyCountry: "US",
      locales: ["en"],
    },
  });
  console.log("Crawl result:", crawlResult);
};

main();
Python
Copy
import os
from dotenv import load_dotenv
from hyperbrowser import Hyperbrowser
from hyperbrowser.models.crawl import StartCrawlJobParams
from hyperbrowser.models.session import CreateSessionParams

# Load environment variables from .env file
load_dotenv()

# Initialize Hyperbrowser client
client = Hyperbrowser(api_key=os.getenv("HYPERBROWSER_API_KEY"))


# Start crawling and wait for completion
crawl_result = client.crawl.start_and_wait(
    StartCrawlJobParams(
        url="https://example.com",
        session_options=CreateSessionParams(use_proxy=True, solve_captchas=True),
    )
)
print("Crawl result:", crawl_result)
Using proxy and solving CAPTCHAs will slow down the crawl so use it only if necessary.

Scrape Configurations
You can also provide optional scrape options for the crawl job such as the formats to return, only returning the main content of the page, setting the maximum timeout for navigating to a page, etc.

Node
Copy
import { Hyperbrowser } from "@hyperbrowser/sdk";
import { config } from "dotenv";

config();

const client = new Hyperbrowser({
  apiKey: process.env.HYPERBROWSER_API_KEY,
});

const main = async () => {
  const crawlResult = await client.crawl.startAndWait({
    url: "https://example.com",
    scrapeOptions: {
      formats: ["markdown", "html", "links"],
      onlyMainContent: false,
      timeout: 10000,
    },
  });
  console.log("Crawl result:", crawlResult);
};

main();
Python
Copy
import os
from dotenv import load_dotenv
from hyperbrowser import Hyperbrowser
from hyperbrowser.models.scrape import ScrapeOptions
from hyperbrowser.models.crawl import StartCrawlJobParams

# Load environment variables from .env file
load_dotenv()

# Initialize Hyperbrowser client
client = Hyperbrowser(api_key=os.getenv("HYPERBROWSER_API_KEY"))


# Start crawling and wait for completion
crawl_result = client.crawl.start_and_wait(
    StartCrawlJobParams(
        url="https://example.com",
        scrape_options=ScrapeOptions(
            formats=["html", "links", "markdown"], only_main_content=False, timeout=10000
        ),
    )
)
print("Crawl result:", crawl_result)
For a full reference on the crawl endpoint, checkout the API Reference, or read the Advanced Scraping Guide to see more advanced options for scraping.

Extract
Extract data from pages using AI

The Extract API allows you to get data in a structured format for any provided URLs with a single call.

For detailed usage, checkout the Extract API Reference

Hyperbrowser exposes endpoints for starting an extract request and for getting it's status and results. By default, extracting is handled in an asynchronous manner of first starting the job and then checking it's status until it is completed. However, with our SDKs, we provide a simple function that handles the whole flow and returns the data once the job is completed.

Installation
Node
Copy
npm install @hyperbrowser/sdk
or

Copy
yarn add @hyperbrowser/sdk
Python
Copy
pip install hyperbrowser
Usage
Node
Copy
import { Hyperbrowser } from "@hyperbrowser/sdk";
import { config } from "dotenv";
import { z } from "zod";

config();

const client = new Hyperbrowser({
  apiKey: process.env.HYPERBROWSER_API_KEY,
});

const main = async () => {
  const schema = z.object({
    productName: z.string(),
    productOverview: z.string(),
    keyFeatures: z.array(z.string()),
    pricing: z.array(
      z.object({
        plan: z.string(),
        price: z.string(),
        features: z.array(z.string()),
      })
    ),
  });

  // Handles both starting and waiting for extract job response
  const result = await client.extract.startAndWait({
    urls: ["https://hyperbrowser.ai"],
    prompt:
      "Extract the product name, an overview of the product, its key features, and a list of its pricing plans from the page.",
    schema: schema,
  });

  console.log("result", JSON.stringify(result, null, 2));
};

main();
Python
Copy
import os
import json
from typing import List
from dotenv import load_dotenv
from hyperbrowser import Hyperbrowser
from hyperbrowser.models.extract import StartExtractJobParams
from pydantic import BaseModel


# Load environment variables from .env file
load_dotenv()

# Initialize Hyperbrowser client
client = Hyperbrowser(api_key=os.getenv("HYPERBROWSER_API_KEY"))


class PricingSchema(BaseModel):
    plan: str
    price: str
    features: List[str]


class ExtractSchema(BaseModel):
    product_name: str
    product_overview: str
    key_features: List[str]
    pricing: List[PricingSchema]


def main():
    result = client.extract.start_and_wait(
        params=StartExtractJobParams(
            urls=["https://hyperbrowser.ai"],
            prompt="Extract the product name, an overview of the product, its key features, and a list of its pricing plans from the page.",
            schema=ExtractSchema,
        )
    )
    print("result:", json.dumps(result.data, indent=2))


main()
cURL
Start Extract Job

Copy
curl -X POST https://app.hyperbrowser.ai/api/extract \
    -H 'Content-Type: application/json' \
    -H 'x-api-key: <YOUR_API_KEY>' \
    -d '{
        "urls": ["https://hyperbrowser.ai"],
        "prompt": "Extract the product name, an overview of the product, its key features, and a list of its pricing plans from the page.",
        "schema": {
          "type": "object",
          "properties": {
            "productName": {
              "type": "string"
            },
            "productOverview": {
              "type": "string"
            },
            "keyFeatures": {
              "type": "array",
              "items": {
                "type": "string"
              }
            },
            "pricing": {
              "type": "array",
              "items": {
                "type": "object",
                "properties": {
                  "plan": {
                    "type": "string"
                  },
                  "price": {
                    "type": "string"
                  },
                  "features": {
                    "type": "array",
                    "items": {
                      "type": "string"
                    }
                  }
                },
                "required": [
                  "plan",
                  "price",
                  "features"
                ]
              }
            }
          },
          "required": [
            "productName",
            "productOverview",
            "keyFeatures",
            "pricing"
          ]
        }
    }'
Get Extract Job Status and Data

Copy
curl https://app.hyperbrowser.ai/api/extract/{jobId} \
    -H 'x-api-key: <YOUR_API_KEY>'
You can configure the extract request with the following parameters:

urls - A required list of urls you want to use to extract data from. To allow crawling for any of the urls provided in the list, simply add /* to the end of the url (https://hyperbrowser.ai/*). This will crawl other pages on the site with the same origin and find relevant pages to use for the extraction context.

schema - A strict json schema you want the returned data to be structured as. Gives the best results.

prompt - A prompt describing how you want the data structured. Useful if you don't have a specific schema in mind.

maxLinks - The maximum number of links to look for if performing a crawl for any given url.

waitFor -  A delay in milliseconds to wait after the page loads before initiating the scrape to get data for extraction from page. This can be useful for allowing dynamic content to fully render. This is also useful for waiting to detect CAPTCHAs on the page if you have solveCaptchas set to true in the sessionOptions.

sessionOptions - Options for the session.

You must provide either a schema or a prompt in your request, and if both are provided the schema takes precedence.

For the Node SDK, you can simply pass in a zod schema for ease of use or an actual json schema. For the Python SDK, you can pass in a pydantic model or an actual json schema.

Ensure that the root level of the schema is type: "object" .

Response
The Start Extract Job POST /extract  endpoint will return a jobId in the response which can be used to get information about the job in subsequent requests.

Copy
{
    "jobId": "962372c4-a140-400b-8c26-4ffe21d9fb9c"
}
The Get Extract Job GET /extract/{jobId}  will return the following data:

Copy
{
  "jobId": "962372c4-a140-400b-8c26-4ffe21d9fb9c",
  "status": "completed",
  "data": {
    "pricing": [
      {
        "plan": "Free",
        "price": "$0",
        "features": [
          "3,000 Credits Included",
          "5 Concurrent Browsers",
          "7 Days Data Retention",
          "Basic Stealth Mode"
        ]
      },
      {
        "plan": "Startup",
        "price": "$30 / Month",
        "features": [
          "18,000 Credits Included",
          "25 Concurrent Browsers",
          "30 Day Data Retention",
          "Auto Captcha Solving",
          "Basic Stealth Mode"
        ]
      },
      {
        "plan": "Scale",
        "price": "$100 / Month",
        "features": [
          "60,000 Credits Included",
          "100 Concurrent Browsers",
          "30 Day Data Retention",
          "Auto Captcha Solving",
          "Advanced Stealth Mode"
        ]
      },
      {
        "plan": "Enterprise",
        "price": "Custom",
        "features": [
          "Volume discounts available",
          "Premium Support",
          "HIPAA/SOC 2",
          "250+ Concurrent Browsers",
          "180+ Day Data Retention",
          "Auto Captcha Solving",
          "Advanced Stealth Mode"
        ]
      }
    ],
    "keyFeatures": [
      "Run headless browsers to automate tasks like web scraping, testing, and form filling.",
      "Use browsers to scrape and structure web data at scale for analysis and insights.",
      "Integrate with AI agents to enable browsing, data collection, and interaction with web apps.",
      "Automatically solve captchas to streamline automation workflows.",
      "Operate browsers in stealth mode to bypass bot detection and stay undetected.",
      "Manage browser sessions with logging, debugging, and secure resource isolation."
    ],
    "productName": "Hyperbrowser",
    "productOverview": "Hyperbrowser is a platform for running and scaling headless browsers in secure, isolated containers. Built for web automation and AI-driven use cases."
  }
}
The status of an extract job can be one of pending, running, completed, failed . There can also be an optional error field with an error message if an error was encountered.

To see the full schema, checkout the API Reference.

Session Configurations
You can also provide configurations for the session that will be used to execute the extract job just as you would when creating a new session itself. These could include using a proxy or solving CAPTCHAs. To see the full list of session configurations, checkout the Session API Reference.

Node
Copy
import { config } from "dotenv";
import { z } from "zod";

config();

const client = new Hyperbrowser({
  apiKey: process.env.HYPERBROWSER_API_KEY,
});

const main = async () => {
  const schema = z.object({
    productName: z.string(),
    productOverview: z.string(),
    keyFeatures: z.array(z.string()),
    pricing: z.array(
      z.object({
        plan: z.string(),
        price: z.string(),
        features: z.array(z.string()),
      })
    ),
  });

  const result = await client.extract.startAndWait({
    urls: ["https://hyperbrowser.ai"],
    prompt:
      "Extract the product name, an overview of the product, its key features, and its pricing plans from the page.",
    schema: schema,
    // include sessionOptions
    sessionOptions: {
      useProxy: true,
      solveCaptchas: true,
    },
  });

  console.log("result", JSON.stringify(result, null, 2));
};

main();
Python
Copy
import os
from dotenv import load_dotenv
from hyperbrowser import Hyperbrowser
from hyperbrowser.models.extract import StartExtractJobParams
from pydantic import BaseModel


load_dotenv()


client = Hyperbrowser(api_key=os.getenv("HYPERBROWSER_API_KEY"))


class PricingSchema(BaseModel):
    plan: str
    price: str
    features: List[str]


class ExtractSchema(BaseModel):
    product_name: str
    product_overview: str
    key_features: List[str]
    pricing: List[PricingSchema]


def main():
    result = client.extract.start_and_wait(
        params=StartExtractJobParams(
            urls=["https://hyperbrowser.ai"],
            prompt="Extract the product name, an overview of the product, its key features, and a list of its pricing plans from the page.",
            schema=ExtractSchema,
            # include session_options
            session_options=CreateSessionParams(use_proxy=True, solve_captchas=True),
        )
    )
    print("result:", json.dumps(result.data, indent=2))


main()
Hyperbrowser's CAPTCHA solving and proxy usage features require being on a PAID plan.

Using proxy and solving CAPTCHAs will slow down the page scraping in the extract job so use it only if necessary.

For a full reference on the extract endpoint, checkout the API Reference.

Billing
Credit usage for extract jobs are charged based on the total number of output tokens used for successful extract jobs. Each output token costs 0.015 credits which comes out to $30 per million output tokens.

Guides
Scraping
Advanced Options for Hyperbrowser Scraping

Basic Usage
With supplying just a url, you can easily extract the contents of a page in markdown format with the /scrape endpoint.

Node
Copy
import { Hyperbrowser } from "@hyperbrowser/sdk";
import { config } from "dotenv";

config();

const client = new Hyperbrowser({
  apiKey: process.env.HYPERBROWSER_API_KEY,
});

const main = async () => {
  // Handles both starting and waiting for scrape job response
  const scrapeResult = await client.scrape.startAndWait({
    url: "https://example.com",
  });
  console.log("Scrape result:", scrapeResult);
};

main();
Python
Copy
import os
from dotenv import load_dotenv
from hyperbrowser import Hyperbrowser
from hyperbrowser.models.scrape import StartScrapeJobParams

# Load environment variables from .env file
load_dotenv()

# Initialize Hyperbrowser client
client = Hyperbrowser(api_key=os.getenv("HYPERBROWSER_API_KEY"))


# Start scraping and wait for completion
scrape_result = client.scrape.start_and_wait(
    StartScrapeJobParams(url="https://example.com")
)
print("Scrape result:", scrape_result)
cURL
Start Scrape Job

Copy
curl -X POST https://app.hyperbrowser.ai/api/scrape \
    -H 'Content-Type: application/json' \
    -H 'x-api-key: <YOUR_API_KEY>' \
    -d '{
        "url": "https://example.com"
    }'
Get Scrape Job Status and Data

Copy
curl https://app.hyperbrowser.ai/api/scrape/{jobId} \
    -H 'x-api-key: <YOUR_API_KEY>'
Now, let's take an in depth look at all the provided options for scraping.

Scrape Options
formats

Type: array

Items: string

Enum: ["html", "links", "markdown", "screenshot"]

Description: Choose the formats to include in the API response:

html - Returns the scraped content as HTML.

links - Includes a list of links found on the page.

markdown - Provides the content in Markdown format.

screenshot - Provides a screenshot of the page.

Default: ["markdown"]

includeTags

Type: array

Items: string

Description: Provide an array of HTML tags, classes, or IDs to include in the scraped content. Only elements matching these selectors will be returned.

Default: undefined

excludeTags

Type: array

Items: string

Description: Provide an array of HTML tags, classes, or IDs to exclude from the scraped content. Elements matching these selectors will be omitted from the response.

Default: undefined

onlyMainContent

Type: boolean

Description: When set to true (default), the API will attempt to return only the main content of the page, excluding common elements like headers, navigation menus, and footers. Set to false to return the full page content.

Default: true

waitFor

Type: number

Description: Specify a delay in milliseconds to wait after the page loads before initiating the scrape. This can be useful for allowing dynamic content to fully render. This is also useful for waiting to detect CAPTCHAs on the page if you have solveCaptchas set to true in the sessionOptions.

Default: 0

timeout

Type: number

Description: Specify the maximum time in milliseconds to wait for the page to load before timing out. This would be like doing:

Copy
await page.goto("https://example.com", { waitUntil: "load", timeout: 30000 })
Default: 30000 (30 seconds)

waitUntil 

Type: string

Enum: ["load", "domcontentloaded", "networkidle"] 

Description: Specify the condition to wait for the page to load:

domcontentloaded: Wait until the HTML is fully parsed and DOM is ready

load - Wait until DOM and all resources are completely loaded

networkidle - Wait until no more network requests occur for a certain period of time

Default: load 

screenshotOptions

Type: object

Properties:

fullPage - Take screenshot of the full page beyond the viewport

Type: boolean

Default: false

format - The image type of the screenshot

Type: string

Enum: ["webp", "jpeg", "png"]

Default: webp 

Description: Configurations for the returned screenshot. Only applicable if screenshot is provided in the formats array.

Session Options
Enabling Stealth Mode with useStealth

Type: boolean

Description: When set to true, the session will be launched in stealth mode, which employs various techniques to make the browser harder to detect as an automated tool.

Default: false

Using a Proxy with useProxy

Type: boolean

Description: When set to true, the session will be launched with a proxy server.

Default: false

Specifying a Custom Proxy Server with proxyServer

Type: string

Description: The hostname or IP address of the proxy server to use for the session. This option is only used when useProxy is set to true.

Default: undefined

Providing Proxy Server Authentication with proxyServerUsername and proxyServerPassword

Type: string

Description: The username and password to use for authenticating with the proxy server, if required. These options are only used when useProxy is set to true and the proxy server requires authentication.

Default: undefined

Selecting a Proxy Location with proxyCountry

Type: string

Enum: ["US", "GB", "CA", ...]

Description: The country where the proxy server should be located.

Default: "US"

Specifying Operating Systems with operatingSystems

Type: array

Items: string

Enum: ["windows", "android", "macos", "linux", "ios"]

Description: An array of operating systems to use for fingerprinting.

Default: undefined

Choosing Device Types with device

Type: array

Items: string

Enum: ["desktop", "mobile"]

Description: An array of device types to use for fingerprinting.

Default: undefined

Selecting Browser Platforms with platform

Type: array

Items: string

Enum: ["chrome", "firefox", "safari", "edge"]

Description: An array of browser platforms to use for fingerprinting.

Default: undefined

Setting Browser Locales with locales

Type: array

Items: string

Enum: ["en", "es", "fr", ...]

Description: An array of browser locales to specify the language for the browser.

Default: ["en"]

Customizing Screen Resolution with screen

Type: object

Properties:

width (number, default 1280): The screen width in pixels.

height (number, default 720): The screen height in pixels.

Description: An object specifying the screen resolution to emulate in the session.

Solving CAPTCHAs Automatically with solveCaptchas

Type: boolean

Description: When set to true, the session will attempt to automatically solve any CAPTCHAs encountered during the session.

Default: false

Blocking Ads with adblock

Type: boolean

Description: When set to true, the session will attempt to block ads and other unwanted content during the session.

Default: false

Blocking Trackers with trackers

Type: boolean

Description: When set to true, the session will attempt to block web trackers and other privacy-invasive technologies during the session.

Default: false

Blocking Annoyances with annoyances

Type: boolean

Description: When set to true, the session will attempt to block common annoyances like pop-ups, overlays, and other disruptive elements during the session.

Default: false

Example
By configuring these options when making a scrape request, you can control the format and content of the scraped data, as well as the behavior of the scraper itself.

For example, to scrape a page with the following:

In stealth mode

With CAPTCHA solving

Return only the main content as HTML

Exclude any <span> elements

Wait 2 seconds after the page loads and before scraping

Copy
curl -X POST https://app.hyperbrowser.ai/api/scrape \
    -H 'Content-Type: application/json' \
    -H 'x-api-key: <YOUR_API_KEY>' \
    -d '{
            "url": "https://example.com",
            "sessionOptions": {
                    "useStealth": true,
                    "solveCaptchas": true
            },
            "scrapeOptions": {
                    "formats": ["html"],
                    "onlyMainContent": true, 
                    "excludeTags": ["span"],
                    "waitFor": 2000
            }
    }'
Crawl a Site
Instead of just scraping a single page, you might want to get all the content across multiple pages on a site. The /crawl  endpoint is perfect for such a task. You can use the same sessionOptions and scrapeOptions as before for this endpoint as well. The crawl endpoint does have some extra parameters that are used to tailor the crawl to your scraping needs.

Crawl Options
Limiting the Number of Pages to Crawl with maxPages

Type: integer

Minimum: 1

Description: The maximum number of pages to crawl before stopping. 

Following Links with followLinks

Type: boolean

Default: true

Description: When set to true, the crawler will follow links found on the pages it visits, allowing it to discover new pages and expand the scope of the crawl. When set to false, the crawler will only visit the starting URL and any explicitly specified pages, without following any additional links.

Ignoring the Sitemap with ignoreSitemap

Type: boolean

Default: false

Description: When set to true, the crawler will not pre-generate a list of urls from potential sitemaps it finds. The crawler will try to locate sitemaps beginning at the base URL of the URL provided in the url param.

Excluding Pages with excludePatterns

Type: array

Items: string

Description: An array of regular expressions or wildcard patterns specifying which URLs should be excluded from the crawl. Any pages whose URLs' path match one of these patterns will be skipped.

Including Pages with includePatterns

Type: array

Items: string

Description: An array of regular expressions or wildcard patterns specifying which URLs should be included in the crawl. Only pages whose URLs' path match one of these path patterns will be visited.

Example
By configuring these options when initiating a crawl, you can control the scope and behavior of the crawler to suit your specific needs.

For example, to crawl a site with the following:

Maximum of 5 pages

Only include /blog pages

Return only the main content as HTML

Exclude any <span> elements

Wait 2 seconds after the page loads and before scraping

Copy
curl -X POST https://app.hyperbrowser.ai/api/crawl \
    -H 'Content-Type: application/json' \
    -H 'x-api-key: <YOUR_API_KEY>' \
    -d '{
            "url": "https://example.com",
            "maxPages": 5,
            "includePatterns": ["/blog/*"],
            "scrapeOptions": {
                    "formats": ["html"],
                    "onlyMainContent": true, 
                    "excludeTags": ["span"],
                    "waitFor": 2000
            }
    }'
AI Function Calling
Using Hyperbrowser with OpenAI and Anthropic Function Tools

Hyperbrowser integrates seamlessly with OpenAI and Anthropic's function calling APIs, enabling you to enhance your AI applications with web scraping and crawling capabilities. This guide will walk you through setting up and using Hyperbrowser's scrape and crawl tools with OpenAI and Anthropic.

Setup
Installation
First, install the necessary dependencies to run our script.

Node
Copy
npm install @hyperbrowser/sdk dotenv openai
Python
Copy
pip install hyperbrowser openai python-dotenv
Setup your Environment
To use Hyperbrowser with your code, you will need an API Key. You can get one easily from the dashboard. Once you have your API Key, add it to your .env file as HYPERBROWSER_API_KEY . You will also need an OPENAI_API_KEY.

Code
Node
Copy
import OpenAI from "openai";
import { Hyperbrowser } from "@hyperbrowser/sdk";
import { WebsiteCrawlTool, WebsiteScrapeTool } from "@hyperbrowser/sdk/tools";
import { config } from "dotenv";

config();

// Initialize clients
const hb = new Hyperbrowser({ apiKey: process.env.HYPERBROWSER_API_KEY });
const oai = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY,
});

async function handleToolCall(tc) {
  console.log("Handling tool call");

  try {
    const args = JSON.parse(tc.function.arguments);
    console.log(`Tool call ID: ${tc.id}`);
    console.log(`Function name: ${tc.function.name}`);
    console.log(`Function args: ${JSON.stringify(args, null, 2)}`);
    console.log("-".repeat(50));

    if (
      tc.function.name === WebsiteCrawlTool.openaiToolDefinition.function.name
    ) {
      const response = await WebsiteCrawlTool.runnable(hb, args);
      return {
        tool_call_id: tc.id,
        content: response,
        role: "tool",
      };
    } else if (
      tc.function.name === WebsiteScrapeTool.openaiToolDefinition.function.name
    ) {
      const response = await WebsiteScrapeTool.runnable(hb, args);
      return {
        tool_call_id: tc.id,
        content: response,
        role: "tool",
      };
    } else {
      return {
        tool_call_id: tc.id,
        content: "Unknown tool call",
        role: "tool",
      };
    }
  } catch (e) {
    console.error(e);
    return {
      role: "tool",
      tool_call_id: tc.id,
      content: `Error occurred: ${e}`,
    };
  }
}

const messages = [
  {
    role: "user",
    content: "What does Hyperbrowser.ai do? Provide citations.",
  },
];

async function openaiChat() {
  while (true) {
    const resp = await oai.beta.chat.completions.parse({
      model: "gpt-4o-mini",
      messages: messages,
      tools: [
        WebsiteCrawlTool.openaiToolDefinition,
        WebsiteScrapeTool.openaiToolDefinition,
      ],
    });

    const choice = resp.choices[0];
    messages.push(choice.message);

    if (choice.finish_reason === "tool_calls") {
      for (const tc of choice.message.tool_calls) {
        const result = await handleToolCall(tc);
        messages.push(result);
      }
    } else if (choice.finish_reason === "stop") {
      console.log(choice.message.content);
      break;
    } else {
      throw new Error("Unknown Error Occurred");
    }
  }
}

openaiChat();
Python
Copy
import json
import os

from hyperbrowser import Hyperbrowser
from hyperbrowser.tools import WebsiteCrawlTool, WebsiteScrapeTool

from openai import OpenAI
from openai.types.chat import (
    ChatCompletionMessageToolCall,
    ChatCompletionMessageParam,
    ChatCompletionToolMessageParam,
)
from dotenv import load_dotenv

load_dotenv()

oai = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
hb = Hyperbrowser(api_key=os.getenv("HYPERBROWSER_API_KEY"))


def handle_tool_call(
    tc: ChatCompletionMessageToolCall,
) -> ChatCompletionToolMessageParam:
    print("Handling tool call")

    try:
        args = json.loads(tc.function.arguments)
        print(f"Tool call ID: {tc.id}")
        print(f"Function name: {tc.function.name}")
        print(f"Function args: {args}")
        print("-" * 50)
        if (
            tc.function.name
            == WebsiteCrawlTool.openai_tool_definition["function"]["name"]
        ):
            response = WebsiteCrawlTool.runnable(hb, args)
            return {"tool_call_id": tc.id, "content": response, "role": "tool"}

        elif (
            tc.function.name
            == WebsiteScrapeTool.openai_tool_definition["function"]["name"]
        ):
            response = WebsiteScrapeTool.runnable(hb, args)
            return {"tool_call_id": tc.id, "content": response, "role": "tool"}
        else:
            return {
                "tool_call_id": tc.id,
                "content": "Unknown tool call",
                "role": "tool",
            }
    except Exception as e:
        print(e)
        return {"role": "tool", "tool_call_id": tc.id, "content": f"Error occured: {e}"}


messages: list[ChatCompletionMessageParam] = [
    {
        "role": "user",
        "content": "What does Hyperbrowser.ai do? Provide citations.",
    },
]

while True:
    response = oai.beta.chat.completions.parse(
        messages=messages,
        model="gpt-4o-mini",
        tools=[
            WebsiteCrawlTool.openai_tool_definition,
            WebsiteScrapeTool.openai_tool_definition,
        ],
    )

    choice = response.choices[0]
    messages.append(choice.message)  # type: ignore
    if choice.finish_reason == "tool_calls":
        for tc in choice.message.tool_calls:  # type: ignore
            result = handle_tool_call(tc=tc)
            messages.append(result)

    elif choice.finish_reason == "stop":
        print(choice.message.content)
        break

    else:
        raise Exception("Unknown Error Occured")
Hyperbrowser exposes WebsiteCrawlTool and WebsiteScrapeTool to be used for OpenAI and Anthropic function calling. Each class provides a tool definition for both OpenAI and Anthropic that defines the schema which can be passed into the tools argument. Then, in the handleToolCall function, we parse the tool call arguments and dispatch the appropriate tool class runnable function based on the function name which will return the result of the scrape or crawl in formatted markdown.

Extract Information with an LLM
Use Hyperbrowser to scrape a wikipedia page and extract information with an LLM

In this guide, we'll use Hyperbrowser's Node.js SDK to get formatted data from a Wikipedia page and then feed it into an LLM like ChatGPT to extract the information we want. Our goal is to get a list of the most populous cities.

Setup
First, lets create a new Node.js project.

Copy
mkdir wiki-scraper && cd wiki-scraper
npm init -y
Installation
Next, let's install the necessary dependencies to run our script.

Copy
npm install @hyperbrowser/sdk dotenv openai zod
Setup your Environment
To use Hyperbrowser with your code, you will need an API Key. You can get one easily from the dashboard. Once you have your API Key, add it to your .env file as HYPERBROWSER_API_KEY . You will also need an OPENAI_API_KEY to use ChatGPT to extract information from our scraped data.

Code
Next, create a new file scraper.js and add the following code:

Copy
import { Hyperbrowser } from "@hyperbrowser/sdk";
import { config } from "dotenv";
import { z } from "zod";
import OpenAI from "openai";
import { zodResponseFormat } from "openai/helpers/zod";

config();

const client = new Hyperbrowser({
  apiKey: process.env.HYPERBROWSER_API_KEY,
});
const openai = new OpenAI({ apiKey: process.env.OPENAI_API_KEY });

const CitySchema = z.object({
  city: z.string(),
  country: z.string(),
  population: z.number(),
  rank: z.number(),
});

const ResponseSchema = z.object({ cities: z.array(CitySchema) });

const SYSTEM_PROMPT = `You are a helpful assistant that can extract information from markdown and convert it into a structured format.
Ensure the output adheres to the following:
- city: The name of the city
- country: The name of the country
- population: The population of the city
- rank: The rank of the city

Provide the extracted data as a JSON object. Parse the Markdown content carefully to identify and categorize the city details accurately.
`;

const main = async () => {
  console.log("Started scraping");
  const scrapeResult = await client.scrape.startAndWait({
    url: "https://en.wikipedia.org/wiki/List_of_largest_cities",
    scrapeOptions: {
      // Only return the markdown for the scraped data
      formats: ["markdown"],
      // Only include the table element with class `wikitable` from the page
      includeTags: [".wikitable"],
      // Remove any img tags from the table
      excludeTags: ["img"],
    },
  });
  console.log("Finished scraping");
  if (scrapeResult.status === "failed") {
    console.error("Scrape failed:", scrapeResult.error);
    return;
  }
  if (!scrapeResult.data.markdown) {
    console.error("No markdown data found in the scrape result");
    return;
  }

  console.log("Extracting data from markdown");
  const completion = await openai.beta.chat.completions.parse({
    model: "gpt-4o-mini",
    messages: [
      {
        role: "system",
        content: SYSTEM_PROMPT,
      },
      { role: "user", content: scrapeResult.data.markdown },
    ],
    response_format: zodResponseFormat(ResponseSchema, "cities"),
  });
  console.log("Finished extracting data from markdown");

  const cities = completion.choices[0].message.parsed;

  const data = JSON.stringify(cities, null, 2);
  fs.writeFileSync("cities.json", data);
};

main();
With just a single call to the SDKs crawl startAndWait function, we can get back the exact information we need from the page in properly formatted markdown. To make sure we narrow down the data we get back to just the information we need, we make sure to only include the wikiTable class element and remove any unnecessary image tags.

Once we have the markdown text, we can simply just pass it into the request to the parse function from the openai library with the response_format we want and we will have our list of the most populous cities.

Run the Scraper
Once you have the code copied, you can run the script with:

Copy
node scraper.js
If everything completes successfully, you should see a cities.json file in your project directory with the data in this format:

Copy
{
  "cities": [
    {
      "city": "Tokyo",
      "country": "Japan",
      "population": 37468000,
      "rank": 1
    },
    {
      "city": "Delhi",
      "country": "India",
      "population": 28514000,
      "rank": 2
    },
    {
      "city": "Shanghai",
      "country": "China",
      "population": 25582000,
      "rank": 3
    },
    ...
  ]
}
Next Steps
This is a simple example, but you can adapt it to scrape more complex data from other sites, or crawl entire websites.

Using Hyperbrowser Session
Using Hyperbrowser's session

In this guide, we will see how to use Hyperbrowser and Puppeteer to create a new session, connect to it, and scrape current weather data.

Setup
First, lets create a new Node.js project.

Copy
mkdir weather-scraper && cd weather-scraper
npm init -y
Installation
Next, let's install the necessary dependencies to run our script.

Copy
npm install @hyperbrowser/sdk puppeteer-core dotenv
Setup your Environment
To use Hyperbrowser with your code, you will need an API Key. You can get one easily from the dashboard. Once you have your API Key, add it to your .env file as HYPERBROWSER_API_KEY.

Code
Next, create a new file index.js and add the following code:

Copy
import { Hyperbrowser } from "@hyperbrowser/sdk";
import { config } from "dotenv";
import { connect } from "puppeteer-core";

config();

const client = new Hyperbrowser({
  apiKey: process.env.HYPERBROWSER_API_KEY,
});

const main = async () => {
  const location = process.argv[2];
  if (!location) {
    console.error("Please provide a location as a command line argument");
    process.exit(1);
  }

  console.log("Starting session");
  const session = await client.sessions.create();
  console.log("Session created:", session.id);

  try {
    const browser = await connect({ browserWSEndpoint: session.wsEndpoint });

    const [page] = await browser.pages();

    await page.goto("https://openweathermap.org/city", {
      waitUntil: "load",
      timeout: 20_000,
    });
    await page.waitForSelector(".search-container", {
      visible: true,
      timeout: 10_000,
    });
    await page.type(".search-container input", location);
    await page.click(".search button");
    await page.waitForSelector(".search-dropdown-menu", {
      visible: true,
      timeout: 10_000,
    });

    const [response] = await Promise.all([
      page.waitForNavigation(),
      page.click(".search-dropdown-menu li:first-child"),
    ]);

    await page.waitForSelector(".current-container", {
      visible: true,
      timeout: 10_000,
    });
    const locationName = await page.$eval(
      ".current-container h2",
      (el) => el.textContent
    );
    const currentTemp = await page.$eval(
      ".current-container .current-temp",
      (el) => el.textContent
    );
    const description = await page.$eval(
      ".current-container .bold",
      (el) => el.textContent
    );

    const windInfo = await page.$eval(".weather-items .wind-line", (el) =>
      el.textContent.trim()
    );
    const pressureInfo = await page.$eval(
      ".weather-items li:nth-child(2)",
      (el) => el.textContent.trim()
    );
    const humidityInfo = await page.$eval(
      ".weather-items li:nth-child(3)",
      (el) => el.textContent.trim()?.split(":")[1]
    );
    const dewpoint = await page.$eval(
      ".weather-items li:nth-child(4)",
      (el) => el.textContent.trim()?.split(":")[1]
    );
    const visibility = await page.$eval(
      ".weather-items li:nth-child(5)",
      (el) => el.textContent.trim()?.split(":")[1]
    );

    console.log("\nWeather Information:");
    console.log("------------------");
    console.log(`Location: ${locationName}`);
    console.log(`Temperature: ${currentTemp}`);
    console.log(`Conditions: ${description}`);
    console.log(`Wind: ${windInfo}`);
    console.log(`Pressure: ${pressureInfo}`);
    console.log(`Humidity: ${humidityInfo}`);
    console.log(`Dew Point: ${dewpoint}`);
    console.log(`Visibility: ${visibility}`);
    console.log("------------------\n");

    await page.screenshot({ path: "screenshot.png" });
    await page.close();
    await browser.close();
  } catch (error) {
    console.error(`Encountered an error: ${error}`);
  } finally {
    await client.sessions.stop(session.id);
    console.log("Session stopped:", session.id);
  }
};

main().catch((error) => {
  console.error(`Encountered an error: ${error}`);
});
Run the Scraper
To run the weather scraper:

Open a terminal and navigate to your project directory

Run the script with a location argument:

Copy
node index.js "New York"
Replace "New York" with the location you want weather data for.

The script will:

Create a new Hyperbrowser session

Launch a Puppeteer browser and connect to the session

Navigate to the OpenWeatherMap city page

Search for the specified location and hit the Search button

Select the first option from a list in a dropdown menu and navigate to that page

Scrape the current weather data from the page

Print the weather information to the console

Save a screenshot of the page

Close the browser and stop the Hyperbrowser session

You should see output like:

Copy
Weather Information:  
------------------ 
Location: New York City, US
Temperature: 9C
Conditions: overcast clouds
Wind: Gentle breeze, 3.6 m/s, west-southwest  
Pressure: 1013 hPa
Humidity: 81%
Dew Point: 6C 
Visibility: 10 km
------------------
And a screenshot.png file saved in your project directory.

How it Works
Let's break down the key steps:

We import the required libraries and load the environment variables

We create a new Hyperbrowser client with the API key

We start a new Hyperbrowser session with client.sessions.create()

We launch a Puppeteer browser and connect it to the Hyperbrowser session

We navigate to the OpenWeatherMap city page

We search for the location provided as a command line argument

We wait for the search results and click the first result

We scrape the weather data from the page using Puppeteer's page.$eval method

We print the scraped data, take a screenshot, and save it to disk

Finally, we close the browser and stop the Hyperbrowser session

Next Steps
This example demonstrates a basic weather scraping workflow using a Hyperbrowser session. You can expand on it to:

Accept multiple locations and fetch weather data for each

Get the 8-day forecast for the location

Schedule the script to run periodically and save historical weather data

CAPTCHA Solving
Using Hyperbrowser's CAPTCHA Solving

Hyperbrowser's CAPTCHA solving feature requires being on a PAID plan.

In this guide, we will see how to use Hyperbrowser and its integrated CAPTCHA solver to scrape Today's Top Deals from Amazon without being blocked.

Setup
First, lets create a new Node.js project.

Copy
mkdir amazon-deals-scraper && cd amazon-deals-scraper
npm init -y
Installation
Next, let's install the necessary dependencies to run our script.

Copy
npm install @hyperbrowser/sdk puppeteer-core dotenv
Setup your Environment
To use Hyperbrowser with your code, you will need an API Key. You can get one easily from the dashboard. Once you have your API Key, add it to your .env file as HYPERBROWSER_API_KEY.

Code
Next, create a new file index.js and add the following code:

Copy
import { Hyperbrowser } from "@hyperbrowser/sdk";
import { config } from "dotenv";
import { connect } from "puppeteer-core";

config();

const client = new Hyperbrowser({
  apiKey: process.env.HYPERBROWSER_API_KEY,
});

const sleep = (ms) => new Promise((resolve) => setTimeout(resolve, ms));

const main = async () => {
  console.log("Starting session");
  const session = await client.sessions.create({
    solveCaptchas: true,
    adblock: true,
    annoyances: true,
    trackers: true,
  });
  console.log("Session created:", session.id);

  try {
    const browser = await connect({ browserWSEndpoint: session.wsEndpoint });

    const [page] = await browser.pages();

    await page.goto("https://amazon.com/deals", {
      waitUntil: "load",
      timeout: 20_000,
    });

    const pageTitle = await page.title();
    console.log("Navigated to Page:", pageTitle);

    await sleep(10_000);

    const products = await page.evaluate(() => {
      const items = document.querySelectorAll(".dcl-carousel-element");
      return Array.from(items)
        .map((item) => {
          const nameElement = item.querySelector(".dcl-product-label");
          const dealPriceElement = item.querySelector(
            ".dcl-product-price-new .a-offscreen"
          );
          const originalPriceElement = item.querySelector(
            ".dcl-product-price-old .a-offscreen"
          );
          const percentOffElement = item.querySelector(
            ".dcl-badge .a-size-mini"
          );

          return {
            name: nameElement ? nameElement.textContent.trim() : null,
            dealPrice: dealPriceElement
              ? dealPriceElement.textContent.trim()
              : null,
            originalPrice: originalPriceElement
              ? originalPriceElement.textContent.trim()
              : null,
            percentOff: percentOffElement
              ? percentOffElement.textContent.trim()
              : null,
          };
        })
        .filter((product) => product.name && product.dealPrice);
    });

    console.log("Found products:", JSON.stringify(products, null, 2));

    await page.close();
    await browser.close();
  } catch (error) {
    console.error(`Encountered an error: ${error}`);
  } finally {
    await client.sessions.stop(session.id);
    console.log("Session stopped:", session.id);
  }
};

main().catch((error) => {
  console.error(`Encountered an error: ${error}`);
});
Run the Scraper
To run the Amazon deals scraper:

In your terminal, navigate to the project directory

Run the script with Node.js:

Copy
node index.js
The script will:

Create a new Hyperbrowser session with captcha solving, ad blocking, and anti-tracking enabled

Launch a Puppeteer browser and connect it to the session

Navigate to the Amazon deals page, solving any CAPTCHAs that are encountered

Wait 10 seconds for the page to load its content

Scrape the deal data using Puppeteer's page.evaluate method

Print the scraped products to the console

Close the browser and stop the Hyperbrowser session

You should see the scraped products printed in the console, like:

Copy
[
  {
    "name": "Apple AirPods Pro",
    "dealPrice": "$197.00",
    "originalPrice": "$249.99", 
    "percentOff": "21% off"
  },
  {
    "name": "Echo Dot (4th Gen)", 
    "dealPrice": "$27.99",
    "originalPrice": "$49.99",
    "percentOff": "44% off"  
  }
]
How it Works
Let's break down the key parts:

We create a new Hyperbrowser session with solveCaptchas, adblock, annoyances, and trackers set to true. This enables the captcha solver and other anti-bot evasion features.

We launch a Puppeteer browser and connect it to the Hyperbrowser session.

We navigate to the Amazon deals page and wait for any CAPTCHAs to be solved automatically by Hyperbrowser.

We pause execution for 10 seconds with sleep to allow all content to be loaded.

We use page.evaluate to run JavaScript on the page to scrape the deal data.

In the evaluator function, we select the deal elements, extract the relevant data, and return an array of product objects.

We print the scraped data, close the browser, and stop the Hyperbrowser session.

Without the solveCaptchas enabled, we would encounter a screen like this when trying to navigate to the deals page:


The captcha solver runs automatically in the background, so we don't need to handle captchas explicitly in our script. If a captcha appears, Hyperbrowser will solve it and continue loading the page. In this case, it would solve this CAPTCHA and continue on to the deals page.

reference
SDKs
Hyperbrowser provides SDKs in Node and Python.

Node
Learn about Hyperbrowser's Node SDK

View on Github

Installation
Copy
npm install @hyperbrowser/sdk
or

Copy
yarn add @hyperbrowser/sdk
Usage
Copy
import { connect } from "puppeteer-core";
import { Hyperbrowser } from "@hyperbrowser/sdk";
import dotenv from "dotenv";

dotenv.config();

const client = new Hyperbrowser({
  apiKey: process.env.HYPERBROWSER_API_KEY,
});

(async () => {
  const session = await client.sessions.create();

  const browser = await connect({
    browserWSEndpoint: session.wsEndpoint,
    defaultViewport: null,
  });

  // Create a new page
  const [page] = await browser.pages();

  // Navigate to a website
  console.log("Navigating to Hacker News...");
  await page.goto("https://news.ycombinator.com/");
  const pageTitle = await page.title();
  console.log("Page title:", pageTitle);

  await page.close();
  await browser.close();
  console.log("Session completed!");
  await client.sessions.stop(session.id);
})().catch((error) => console.error(error.message));
Sessions
Create Session
Creates a new browser session with optional configuration.

Method: client.sessions.create(params?: CreateSessionParams): Promise<SessionDetail>

Endpoint: POST /api/session

Parameters:

CreateSessionParams:

useStealth?: boolean - Use stealth mode.

useProxy?: boolean - Use proxy.

proxyServer?: string - Proxy server URL to route the session through.

proxyServerUsername?: string - Username for proxy server authentication.

proxyServerPassword?: string - Password for proxy server authentication.

proxyCountry?:Country - Desired proxy country.

proxyState?:  State- Desired State. Currently only US states are supported. States need to be in two letter codes

proxyCity?: string - Desired City. Some cities might not be supported, so before using a new city, we recommend trying it out.

operatingSystems?: OperatingSystem[] - Preferred operating systems for the session. Possible values are:

OperatingSystem.WINDOWS

OperatingSystem.ANDROID

OperatingSystem.MACOS

OperatingSystem.LINUX

OperatingSystem.IOS

device?: ("desktop" | "mobile")[] - Preferred device types. Possible values are:

"desktop"

"mobile"

platform?: Platform[] - Preferred browser platforms. Possible values are:

Platform.CHROME

Platform.FIREFOX

Platform.SAFARI

Platform.EDGE

locales?: ISO639_1[] - Preferred locales (languages) for the session. Use ISO 639-1 codes.

screen?: ScreenConfig - Screen configuration for the session.

width: number - Screen width.

height: number - Screen height.

solveCaptchas?: boolean - Solve captchas.

adblock?: boolean - Block ads.

trackers?: boolean - Block trackers.

annoyances?: boolean - Block annoyances.

enableWebRecording?: boolean - Default true

extensionIds?: string[] - Array of extension Ids 

acceptCookies?: boolean - Automatically Accept Cookies on the page

urlBlocklist?: string[]

browserArgs?: string[]

Response: SessionDetail

Example:

Copy
const session = await client.sessions.create();
console.log(session.id);
Get Session Details
Retrieves details of a specific session.

Method: client.sessions.get(id: string): Promise<SessionDetail>

Endpoint: GET /api/session/{id}

Parameters:

id: string - Session ID

Response: SessionDetail

Example:

Copy
const session = await client.sessions.get("182bd5e5-6e1a-4fe4-a799-aa6d9a6ab26e");
console.log(session.id);
List Sessions
Retrieves a list of all sessions with optional filtering.

Method: client.sessions.list(params?: SessionListParams): Promise<SessionListResponse>

Endpoint: GET /api/sessions

Parameters:

SessionListParams:

status?: "active" | "closed" | "error" - Filter sessions by status

page?: number - Page number for pagination

Response: SessionListResponse

Example:

Copy
const response = await client.sessions.list({
  status: "active",
  page: 1,
});
console.log(response.sessions);
Stop Session
Stops a running session.

Method: client.sessions.stop(id: string): Promise<BasicResponse>

Endpoint: PUT /api/session/{id}/stop

Parameters:

id: string - Session ID

Response: BasicResponse

Example:

Copy
const response = await client.sessions.stop(
  "182bd5e5-6e1a-4fe4-a799-aa6d9a6ab26e"
);
console.log(`Session stopped: ${response.success}`);
Get Session Recording
Get the recording of a session.

Method: client.sessions.getRecording(id: string): Promise<SessionRecording[]>

Endpoint: GET /api/session/{id}/recording

Parameters:

id: string - Session ID

Response: SessionRecording[]

Example:

Copy
const recordingData = await client.sessions.getRecording(
    "182bd5e5-6e1a-4fe4-a799-aa6d9a6ab26e"
);
console.log(recordingData);
Types
SessionStatus
Copy
type SessionStatus = "active" | "closed" | "error";
Country
Copy
type Country =
  | "AD"
  | "AE"
  | "AF"
  ...
State
Currently only US States are supported. Standard two letter state codes are used.

Copy
type State =
  | "AL"
  | "AK"
  | "AZ"
  ...
OperatingSystem
Copy
type OperatingSystem = "windows" | "android" | "macos" | "linux" | "ios";
Platform
Copy
type Platform = "chrome" | "firefox" | "safari" | "edge";
ISO639_1
Copy
type ISO639_1 =
  | "aa"
  | "ab"
  | "ae"
  ...
BasicResponse
Copy
interface BasicResponse {
  success: boolean;
}
Session
Copy
interface Session {
  id: string;
  teamId: string;
  status: SessionStatus;
  startTime?: number;
  endTime?: number;
  createdAt: string;
  updatedAt: string;
  sessionUrl: string;
}
SessionDetail
Copy
interface SessionDetail extends Session {
  wsEndpoint?: string;
  liveUrl?: string;
  token?: string;
}
SessionListResponse
Copy
interface SessionListResponse {
  sessions: Session[];
  totalCount: number;
  page: number;
  perPage: number;
}
ScreenConfig
Copy
interface ScreenConfig {
  width: number;
  height: number;
}
CreateSessionParams
Copy
interface CreateSessionParams {
  useStealth?: boolean;
  useProxy?: boolean;
  proxyServer?: string;
  proxyServerPassword?: string;
  proxyServerUsername?: string;
  proxyCountry?: Country;
  operatingSystems?: OperatingSystem[];
  device?: ("desktop" | "mobile")[];
  platform?: Platform[];
  locales?: ISO639_1[];
  screen?: ScreenConfig;
  solveCaptchas?: boolean;
  adblock?: boolean;
  trackers?: boolean;
  annoyances?: boolean;
  enableWebRecording?: boolean;
  extensionIds?: string[];
  acceptCookies?: boolean;
  urlBlocklist?: string[];
  browserArgs?: string[];
}
SessionRecording
Copy
interface SessionRecording {
  type: number;
  data: unknown;
  timestamp: number;
  delay?: number;
}
Profiles
Create Profile
Creates a new profile.

Method: client.profiles.create(): Promise<CreateProfileResponse>

Endpoint: POST /api/profile

Response: CreateProfileResponse

Example:

Copy
const profile = await client.profiles.create();
console.log(profile.id);
Get Profile
Get details of an existing profile.

Method: client.profiles.get(id: string): Promise<ProfileResponse>

Endpoint: GET /api/profile/{id}

Parameters:

id: string  - Profile ID

Response: ProfileResponse

Example:

Copy
const profile = await client.profiles.get("36946080-9b81-4288-81d5-b15f2191f222");
console.log(profile.id);
Delete Profile
Delete an existing profile.

Method: client.profiles.delete(id: string): Promise<BasicResponse>

Endpoint: DELETE /api/profile/{id}

Parameters:

id: string  - Profile ID

Response: BasicResponse

Example:

Copy
const response = await client.profiles.delete("36946080-9b81-4288-81d5-b15f2191f222");
console.log(response);
Types
CreateProfileResponse
Copy
interface CreateProfileResponse {
  id: string;
}
ProfileResponse
Copy
interface ProfileResponse {
  id: string;
  teamId: string;
  createdAt: string;
  updatedAt: string;
}
Scrape
Start Scrape Job
Starts a scrape job for a given URL.

Method: client.scrape.start(params: StartScrapeJobParams): Promise<StartScrapeJobResponse>

Endpoint: POST /api/scrape

Parameters:

StartScrapeJobParams:

url: string - URL to scrape

sessionOptions?: CreateSessionParams 

scrapeOptions?: ScrapeOptions 

Response: StartScrapeJobResponse

Example:

Copy
const response = await client.scrape.start({
  url: "https://example.com",
});
console.log(response.jobId);
Get Scrape Job
Retrieves details of a specific scrape job.

Method: client.scrape.get(id: string): Promise<ScrapeJobResponse>

Endpoint: GET /api/scrape/{id}

Parameters:

id: string - Scrape job ID

Response: ScrapeJobResponse

Example:

Copy
const response = await client.scrape.get(
  "182bd5e5-6e1a-4fe4-a799-aa6d9a6ab26e"
);
console.log(response.status);
Start Scrape Job and Wait
Start a scrape job and wait for it to complete

Method: client.scrape.startAndWait(params: StartScrapeJobParams): Promise<ScrapeJobResponse> 

Parameters:

StartScrapeJobParams:

url: string - URL to scrape

sessionOptions?: CreateSessionParams 

scrapeOptions?: ScrapeOptions 

Response: ScrapeJobResponse

Example:

Copy
const response = await client.scrape.startAndWait({
  url: "https://example.com"
});
console.log(response.status);
Types
ScrapeFormat
Copy
type ScrapeFormat = "markdown" | "html" | "links" | "screenshot";
ScrapeJobStatus
Copy
type ScrapeJobStatus = "pending" | "running" | "completed" | "failed";
ScrapeOptions
Copy
interface ScrapeOptions {
  formats?: ScrapeFormat[];
  includeTags?: string[];
  excludeTags?: string[];
  onlyMainContent?: boolean;
  waitFor?: number;
  timeout?: number;
}
StartScrapeJobResponse
Copy
interface StartScrapeJobResponse {
  jobId: string;
}
ScrapeJobData
Copy
interface ScrapeJobData {
  metadata?: Record<string, string | string[]>;
  markdown?: string;
  html?: string;
  links?: string[];
}
ScrapeJobResponse
Copy
interface ScrapeJobResponse {
  jobId: string;
  status: ScrapeJobStatus;
  data?: ScrapeJobData;
  error?: string;
}
Crawl
Start Crawl Job
Starts a crawl job for a given URL.

Method: client.crawl.start(params: StartCrawlJobParams): Promise<StartCrawlJobResponse>

Endpoint: POST /api/crawl

Parameters:

StartCrawlJobParams:

url: string - URL to scrape

maxPages?: number - Max number of pages to crawl

followLinks?: boolean - Follow links on the page

ignoreSitemap?: boolean - Ignore sitemap when finding links to crawl

excludePatterns?: string[] - Patterns for paths to exclude from crawl

includePatterns?: string[] - Patterns for paths to include in the crawl

sessionOptions?: CreateSessionParams 

scrapeOptions?: ScrapeOptions 

Response: StartCrawlJobResponse

Example:

Copy
const response = await client.crawl.start({
  url: "https://example.com",
});
console.log(response.jobId);
Get Crawl Job
Retrieves details of a specific crawl job.

Method: client.crawl.get(id: string): Promise<CrawlJobResponse>

Endpoint: GET /api/crawl/{id}

Parameters:

id: string - Crawl job ID

Response: CrawlJobResponse

Example:

Copy
const response = await client.crawl.get(
  "182bd5e5-6e1a-4fe4-a799-aa6d9a6ab26e"
);
console.log(response.status);
Start Crawl Job and Wait
Start a crawl job and wait for it to complete

Method: client.crawl.startAndWait(params: StartCrawlJobParams, returnAllPages: boolean = true): Promise<CrawlJobResponse> 

Parameters:

StartCrawlJobParams:

url: string - URL to scrape

maxPages?: number - Max number of pages to crawl

followLinks?: boolean - Follow links on the page

ignoreSitemap?: boolean - Ignore sitemap when finding links to crawl

excludePatterns?: string[] - Patterns for paths to exclude from crawl

includePatterns?: string[] - Patterns for paths to include in the crawl

sessionOptions?: CreateSessionParams 

scrapeOptions?: ScrapeOptions 

returnAllPages: boolean - Return all pages in the crawl job response

Response: CrawlJobResponse

Example:

Copy
const response = await client.crawl.startAndWait({
  url: "https://example.com"
});
console.log(response.status);
Types
CrawlPageStatus
Copy
type CrawlPageStatus = "completed" | "failed";
CrawlJobStatus
Copy
type CrawlJobStatus = "pending" | "running" | "completed" | "failed";
StartCrawlJobResponse
Copy
interface StartCrawlJobResponse {
  jobId: string;
}
CrawledPage
Copy
interface CrawledPage {
  url: string;
  status: CrawlPageStatus;
  error?: string | null;
  metadata?: Record<string, string | string[]>;
  markdown?: string;
  html?: string;
  links?: string[];
}
CrawlJobResponse
Copy
interface CrawlJobResponse {
  jobId: string;
  status: CrawlJobStatus;
  data?: CrawledPage[];
  error?: string;
  totalCrawledPages: number;
  totalPageBatches: number;
  currentPageBatch: number;
  batchSize: number;
}
Extensions
Add an extension
Adds a new chrome manifest V3  extension

Method: client.extensions.create(params:CreateExtensionParams): Promise<ExtensionResponse>

Endpoint: POST /api/extensions/add

Parameters:

params: CreateExtensionParams

filePath: string - Path to the zip containing the manifest V3 compliant extension

name?: string - Optional name to give to the extension. Does not affect functionality.

Response: ExtensionResponse

Example: 

Copy
const response = await client.extensions.create({
  filePath: "/Users/test-user/Downloads/extension.zip",
});
console.log(response);
List all available extension
List all available extensions

Method: client.extensions.list(): Promise< ListExtensionsResponse >

Endpoint: POST /api/extensions/list

Parameters:

N/A

Response: ListExtensionResponse

Example: 

Copy
const extensionsList = await client.extensions.list();
for (let i=0;i<extensionsList.length;i++){
    const extension = extensionsList[i]
    console.log(`extension-${i} => `, JSON.stringify(extension))
}
Types
CreateExtensionParams
Copy
interface CreateExtensionParams {
  filePath: string;
  name?: string;
}
ExtensionResponse
Copy
interface ExtensionResponse {
  name: string;
  id: string;
  createdAt: string;
  updatedAt: string;
}
ListExtensionsResponse
Copy
type ListExtensionsResponse = Array<ExtensionResponse>
Python
Learn about Hyperbrowser's Python SDK

View on Github

Installation
Copy
pip install hyperbrowser
Usage
Hyperbrowser's Python SDK includes both a sync and async client.

Async
Copy
import os
from dotenv import load_dotenv
import asyncio
from pyppeteer import connect
from hyperbrowser import AsyncHyperbrowser

load_dotenv()

client = AsyncHyperbrowser(api_key=os.getenv("HYPERBROWSER_API_KEY"))

async def main():
    session = await client.sessions.create()

    ws_endpoint = session.ws_endpoint
    browser = await connect(browserWSEndpoint=ws_endpoint, defaultViewport=None)

    # Get pages
    pages = await browser.pages()
    if not pages:
        raise Exception("No pages available")

    page = pages[0]

    # Navigate to a website
    print("Navigating to Hacker News...")
    await page.goto("https://news.ycombinator.com/")
    page_title = await page.title()
    print("Page title:", page_title)

    await page.close()
    await browser.disconnect()
    await client.sessions.stop(session.id)
    print("Session completed!")

# Run the asyncio event loop
asyncio.get_event_loop().run_until_complete(main())
Sync
Copy
import os
from dotenv import load_dotenv
from playwright.sync_api import sync_playwright
from hyperbrowser import Hyperbrowser

load_dotenv()

client = Hyperbrowser(api_key=os.getenv("HYPERBROWSER_API_KEY"))

def main():
    session = client.sessions.create()

    ws_endpoint = session.ws_endpoint

    # Launch Playwright and connect to the remote browser
    with sync_playwright() as p:
        browser = p.chromium.connect_over_cdp(ws_endpoint)
        context = browser.new_context()
        
        # Get the first page or create a new one
        if len(context.pages) == 0:
            page = context.new_page()
        else:
            page = context.pages[0]
        
        # Navigate to a website
        print("Navigating to Hacker News...")
        page.goto("https://news.ycombinator.com/")
        page_title = page.title()
        print("Page title:", page_title)
        
        page.close()
        browser.close()
        print("Session completed!")
    client.sessions.stop(session.id)

main()
Sessions
Create Session
Creates a new browser session with optional configuration.

Method: client.sessions.create(params?: CreateSessionParams): SessionDetail

Endpoint: POST /api/session

Parameters:

CreateSessionParams:

use_stealth?: boolean - Use stealth mode.

use_proxy?: boolean - Use proxy.

proxy_server?: string - Proxy server URL to route the session through.

proxy_server_username?: string - Username for proxy server authentication.

proxy_server_password?: string - Password for proxy server authentication.

proxy_country?: Country - Desired proxy country.

proxy_state?:  State - Desired State. Currently only US states are supported. States need to be in two letter codes

proxy_city?: string - Desired City. Some cities might not be supported, so before using a new city, we recommend trying it out.

operating_systems?: OperatingSystem[] - Preferred operating systems for the session. Possible values are:

OperatingSystem.WINDOWS

OperatingSystem.ANDROID

OperatingSystem.MACOS

OperatingSystem.LINUX

OperatingSystem.IOS

device?: ("desktop" | "mobile")[] - Preferred device types. Possible values are:

"desktop"

"mobile"

platform?: Platform[] - Preferred browser platforms. Possible values are:

Platform.CHROME

Platform.FIREFOX

Platform.SAFARI

Platform.EDGE

locales?: ISO639_1[] - Preferred locales (languages) for the session. Use ISO 639-1 codes.

screen?: ScreenConfig - Screen configuration for the session.

width: number - Screen width.

height: number - Screen height.

solve_captchas?: boolean - Solve captchas.

adblock?: boolean - Block ads.

trackers?: boolean - Block trackers.

annoyances?: boolean - Block annoyances.

enable_web_recording?: boolean - Default true

extension_ids?: string[] - Array of extension Ids 

accept_cookies?: boolean - Automatically Accept Cookies on the page

url_blocklist?: string[]

browser_args?: string[]

Response: SessionDetail

Example:

Copy
session = client.sessions.create()
print(session.id)
Get Session Details
Retrieves details of a specific session.

Method: client.sessions.get(id: str): SessionDetail

Endpoint: GET /api/session/{id}

Parameters:

id: string - Session ID

Response: SessionDetail

Example:

Copy
session = client.sessions.get("182bd5e5-6e1a-4fe4-a799-aa6d9a6ab26e")
print(session.id)
List Sessions
Retrieves a list of all sessions with optional filtering.

Method: client.sessions.list(params?: SessionListParams): SessionListResponse

Endpoint: GET /api/sessions

Parameters:

SessionListParams:

status?: "active" | "closed" | "error" - Filter sessions by status

page?: number - Page number for pagination

Response: SessionListResponse

Example:

Copy
response = client.sessions.list()
print(response.sessions)
Stop Session
Stops a running session.

Method: client.sessions.stop(id: str): BasicResponse

Endpoint: PUT /api/session/{id}/stop

Parameters:

id: string - Session ID

Response: BasicResponse

Example:

Copy
response = client.sessions.stop(
  "182bd5e5-6e1a-4fe4-a799-aa6d9a6ab26e"
)
print(f"Session stopped: {response.success}")
Get Session Recording
Get the recording of a session.

Method: client.sessions.get_recording(id: str): SessionRecording[]

Endpoint: GET /api/session/{id}/recording

Parameters:

id: string - Session ID

Response: SessionRecording[]

Example:

Copy
recordingData = client.sessions.get_recording(
    "182bd5e5-6e1a-4fe4-a799-aa6d9a6ab26e"
);
print(recordingData)
Types
SessionStatus
Copy
SessionStatus = Literal["active", "closed", "error"]
Country
Copy
Country = Literal["AD", "AE", "AF", ...]
States
Copy
State = Literal["AL", "AK", "AZ", ...]
OperatingSystem
Copy
OperatingSystem = Literal["windows", "android", "macos", "linux", "ios"]
Platform
Copy
Platform = Literal["chrome", "firefox", "safari", "edge"]
ISO639_1
Copy
ISO639_1 = Literal["aa", "ab", "ae", ...]
BasicResponse
Copy
class BasicResponse(BaseModel):
    success: bool
Session
Copy
class Session(BaseModel):
    id: str
    team_id: str = Field(alias="teamId")
    status: SessionStatus
    created_at: datetime = Field(alias="createdAt")
    updated_at: datetime = Field(alias="updatedAt")
    start_time: Optional[int] = Field(default=None, alias="startTime")
    end_time: Optional[int] = Field(default=None, alias="endTime")
    duration: Optional[int] = None
    session_url: str = Field(alias="sessionUrl")
SessionDetail
Copy
class SessionDetail(Session):
    ws_endpoint: Optional[str] = Field(alias="wsEndpoint", default=None)
    live_url: str = Field(alias="liveUrl")
    token: str = Field(alias="token")
SessionListResponse
Copy
class SessionListResponse(BaseModel):
    sessions: List[Session]
    total_count: int = Field(alias="totalCount")
    page: int
    per_page: int = Field(alias="perPage")
ScreenConfig
Copy
class ScreenConfig(BaseModel):
    width: int = Field(default=1280, serialization_alias="width")
    height: int = Field(default=720, serialization_alias="height")
CreateSessionParams
Copy
class CreateSessionParams(BaseModel):
    use_stealth: bool = Field(default=False, serialization_alias="useStealth")
    use_proxy: bool = Field(default=False, serialization_alias="useProxy")
    proxy_server: Optional[str] = Field(default=None, serialization_alias="proxyServer")
    proxy_server_password: Optional[str] = Field(
        default=None, serialization_alias="proxyServerPassword"
    )
    proxy_server_username: Optional[str] = Field(
        default=None, serialization_alias="proxyServerUsername"
    )
    proxy_country: Optional[Country] = Field(
        default="US", serialization_alias="proxyCountry"
    )
    operating_systems: Optional[List[OperatingSystem]] = Field(
        default=None, serialization_alias="operatingSystems"
    )
    device: Optional[List[Literal["desktop", "mobile"]]] = Field(default=None)
    platform: Optional[List[Platform]] = Field(default=None)
    locales: List[ISO639_1] = Field(default=["en"])
    screen: Optional[ScreenConfig] = Field(default=None)
    solve_captchas: bool = Field(default=False, serialization_alias="solveCaptchas")
    adblock: bool = Field(default=False, serialization_alias="adblock")
    trackers: bool = Field(default=False, serialization_alias="trackers")
    annoyances: bool = Field(default=False, serialization_alias="annoyances")
    enable_web_recording: Optional[bool] = Field(
        default=True, serialization_alias="enableWebRecording"
    )
    extension_ids: Optional[List[str]] = Field(
        default=None, serialization_alias="extensionIds"
    )
    accept_cookies: Optional[bool] = Field(
        default=None, serialization_alias="acceptCookies"
    )
    url_blocklist: Optional[List[str]] = Field(default=None, serialization_alias="urlBlocklist")
    browser_args: Optional[List[str]] = Field(default=None, serialization_alias="browserArgs")
SessionRecording
Copy
class SessionRecording(BaseModel):
    type: int
    data: Any
    timestamp: int
    delay: Optional[int] = None
Profiles
Create Profile
Creates a new profile.

Method: client.profiles.create(): CreateProfileResponse

Endpoint: POST /api/profile

Response: CreateProfileResponse

Example:

Copy
profile = client.profiles.create()
print(profile.id)
Get Profile
Get details of an existing profile.

Method: client.profiles.get(id: str): ProfileResponse

Endpoint: GET /api/profile/{id}

Parameters:

id: string  - Profile ID

Response: ProfileResponse

Example:

Copy
profile = client.profiles.get("36946080-9b81-4288-81d5-b15f2191f222")
print(profile.id)
Delete Profile
Delete an existing profile.

Method: client.profiles.delete(id: str): BasicResponse

Endpoint: DELETE /api/profile/{id}

Parameters:

id: string  - Profile ID

Response: BasicResponse

Example:

Copy
response = client.profiles.delete("36946080-9b81-4288-81d5-b15f2191f222")
print(response)
Types
CreateProfileResponse
Copy
class CreateProfileResponse(BaseModel):
    id: str
ProfileResponse
Copy
class ProfileResponse(BaseModel):
    id: str
    team_id: str = Field(alias="teamId")
    created_at: datetime = Field(alias="createdAt")
    updated_at: datetime = Field(alias="updatedAt")
Scrape
Start Scrape Job
Starts a scrape job for a given URL.

Method: client.scrape.start(params: StartScrapeJobParams): StartScrapeJobResponse

Endpoint: POST /api/scrape

Parameters:

StartScrapeJobParams:

url: string - URL to scrape

session_options?: CreateSessionParams 

scrape_options?: ScrapeOptions 

Response: StartScrapeJobResponse

Example:

Copy
response = client.scrape.start(StartScrapeJobParams(url="https://example.com"))
print(response.jobId)
Get Scrape Job
Retrieves details of a specific scrape job.

Method: client.scrape.get(id: str): ScrapeJobResponse

Endpoint: GET /api/scrape/{id}

Parameters:

id: string - Scrape job ID

Response: ScrapeJobResponse

Example:

Copy
response = client.scrape.get(
  "182bd5e5-6e1a-4fe4-a799-aa6d9a6ab26e"
)
print(response.status)
Start Scrape Job and Wait
Start a scrape job and wait for it to complete

Method: client.scrape.start_and_wait(params: StartScrapeJobParams): ScrapeJobResponse 

Parameters:

StartScrapeJobParams:

url: string - URL to scrape

session_options?: CreateSessionParams 

scrape_options?: ScrapeOptions 

Response: ScrapeJobResponse

Example:

Copy
response = client.scrape.start_and_wait(StartScrapeJobParams(url="https://example.com"))
print(response.status)
Types
ScrapeFormat
Copy
ScrapeFormat = Literal["markdown", "html", "links", "screenshot"]
ScrapeJobStatus
Copy
ScrapeJobStatus = Literal["pending", "running", "completed", "failed"]
ScrapeOptions
Copy
class ScrapeOptions(BaseModel):
    formats: Optional[List[ScrapeFormat]] = None
    include_tags: Optional[List[str]] = Field(
        default=None, serialization_alias="includeTags"
    )
    exclude_tags: Optional[List[str]] = Field(
        default=None, serialization_alias="excludeTags"
    )
    only_main_content: Optional[bool] = Field(
        default=None, serialization_alias="onlyMainContent"
    )
    wait_for: Optional[int] = Field(default=None, serialization_alias="waitFor")
    timeout: Optional[int] = Field(default=None, serialization_alias="timeout")
StartScrapeJobResponse
Copy
class StartScrapeJobResponse(BaseModel):
    job_id: str = Field(alias="jobId")
ScrapeJobData
Copy
class ScrapeJobData(BaseModel):
    metadata: Optional[dict[str, Union[str, list[str]]]] = None
    html: Optional[str] = None
    markdown: Optional[str] = None
    links: Optional[List[str]] = None
ScrapeJobResponse
Copy
class ScrapeJobResponse(BaseModel):
    job_id: str = Field(alias="jobId")
    status: ScrapeJobStatus
    error: Optional[str] = None
    data: Optional[ScrapeJobData] = None
Crawl
Start Crawl Job
Starts a crawl job for a given URL.

Method: client.crawl.start(params: StartCrawlJobParams): StartCrawlJobResponse

Endpoint: POST /api/crawl

Parameters:

StartCrawlJobParams:

url: string - URL to scrape

max_pages?: number - Max number of pages to crawl

follow_links?: boolean - Follow links on the page

ignore_sitemap?: boolean - Ignore sitemap when finding links to crawl

exclude_patterns?: string[] - Patterns for paths to exclude from crawl

include_patterns?: string[] - Patterns for paths to include in the crawl

session_options?: CreateSessionParams 

scrape_options?: ScrapeOptions 

Response: StartCrawlJobResponse

Example:

Copy
response = client.crawl.start(StartCrawlJobParams(url="https://example.com"))
print(response.status)
Get Crawl Job
Retrieves details of a specific crawl job.

Method: client.crawl.get(id: str): CrawlJobResponse

Endpoint: GET /api/crawl/{id}

Parameters:

id: string - Crawl job ID

Response: CrawlJobResponse

Example:

Copy
response = client.crawl.get(
  "182bd5e5-6e1a-4fe4-a799-aa6d9a6ab26e"
)
print(response.status)
Start Crawl Job and Wait
Start a crawl job and wait for it to complete

Method: client.crawl.start_and_wait(params: StartCrawlJobParams): CrawlJobResponse 

Parameters:

StartCrawlJobParams:

url: string - URL to scrape

max_pages?: number - Max number of pages to crawl

follow_links?: boolean - Follow links on the page

ignore_sitemap?: boolean - Ignore sitemap when finding links to crawl

exclude_patterns?: string[] - Patterns for paths to exclude from crawl

include_patterns?: string[] - Patterns for paths to include in the crawl

session_options?: CreateSessionParams 

scrape_options?: ScrapeOptions 

Response: CrawlJobResponse

Example:

Copy
response = client.crawl.start_and_wait(StartCrawlJobParams(url="https://example.com"))
print(response.status)
Types
CrawlPageStatus
Copy
CrawlPageStatus = Literal["completed", "failed"]
CrawlJobStatus
Copy
CrawlJobStatus = Literal["pending", "running", "completed", "failed"]
StartCrawlJobResponse
Copy
class StartCrawlJobResponse(BaseModel):
    job_id: str = Field(alias="jobId")
CrawledPage
Copy
class CrawledPage(BaseModel):
    metadata: Optional[dict[str, Union[str, list[str]]]] = None
    html: Optional[str] = None
    markdown: Optional[str] = None
    links: Optional[List[str]] = None
    url: str
    status: CrawlPageStatus
    error: Optional[str] = None
CrawlJobResponse
Copy
class CrawlJobResponse(BaseModel):
    job_id: str = Field(alias="jobId")
    status: CrawlJobStatus
    error: Optional[str] = None
    data: List[CrawledPage] = Field(alias="data")
    total_crawled_pages: int = Field(alias="totalCrawledPages")
    total_page_batches: int = Field(alias="totalPageBatches")
    current_page_batch: int = Field(alias="currentPageBatch")
    batch_size: int = Field(alias="batchSize")
Extensions
Add an extension
Adds a new chrome manifest V3  extension

Method: client.extensions.create(params:CreateExtensionParams): Promise<ExtensionResponse>

Endpoint: POST /api/extensions/add

Parameters:

params: CreateExtensionParams

file_path: string - Path to the zip containing the manifest V3 compliant extension

name?: string - Optional name to give to the extension. Does not affect functionality.

Response: ExtensionResponse

Example: 

Copy
extension = client.extensions.create(
    params=CreateExtensionParams(file_path="/Users/test-user/Downloads/extension.zip")
)
print(extension);
List all available extension
List all available extensions

Method: client.extensions.list(): Promise< ListExtensionsResponse >

Endpoint: POST /api/extensions/list

Parameters:

N/A

Response: List[ExtensionResponse]

Example: 

Copy
extensionsList = client.extensions.list();
for i in range(len(extensionsList)):
    extension = extensionsList[i]
    print(f"extension-{i} => ", json.dumps(extension))
Types
CreateExtensionParams
Copy
class CreateExtensionParams(BaseModel):
    name: Optional[str] = Field(default=None, serialization_alias="name")
    file_path: str = Field(serialization_alias="filePath")
ExtensionResponse
Copy
class ExtensionResponse(BaseModel):
    id: str = Field(serialization_alias="id")
    name: str = Field(serialization_alias="name")
    created_at: datetime = Field(serialization_alias="createdAt",alias="createdAt")
    updated_at: datetime = Field(serialization_alias="updatedAt",alias="updatedAt")
API Reference
Hyperbrowser API endpoints are documented using OpenAPI specification. It offers methods to create new sessions, get session details, stop sessions, and more.

Sessions
Create new session
post
/api/session

Test it

Authorizations
Body
useStealth
boolean  default: false
useProxy
boolean  default: false
proxyServer
string
proxyServerPassword
string
proxyServerUsername
string
proxyCity
string | nullable
Desired Country. Some cities might not be supported, so before using a new city, we recommend trying it out

Example: new york
solveCaptchas
boolean  default: false
adblock
boolean  default: false
trackers
boolean  default: false
annoyances
boolean  default: false
enableWebRecording
boolean
profile
object

Show child attributes
acceptCookies
boolean
proxyCountry
string  enum  default: US
Options: US, GB, CA
proxyState
string  enum | nullable
Optional state code for proxies to US states. Takes in two letter state code.

Options: AL, AK, AZ
extensionIds
string[]  default: 
urlBlocklist
string[]  default: 
browserArgs
string[]  default: 
operatingSystems
string  enum[]

Show child attributes
device
string  enum[]

Show child attributes
platform
string  enum[]

Show child attributes
locales
string  enum[]  default: en

Show child attributes
screen
object

Show child attributes
Responses

200
Session created
cURL
JavaScript
Python
HTTP
Copy
curl -L \
  --request POST \
  --url 'https://app.hyperbrowser.ai/api/session' \
  --header 'x-api-key: YOUR_API_KEY' \
  --header 'Content-Type: application/json' \
  --data '{
    "useStealth": false,
    "useProxy": false,
    "proxyServer": "text",
    "proxyServerPassword": "text",
    "proxyServerUsername": "text",
    "proxyCity": "new york",
    "solveCaptchas": false,
    "adblock": false,
    "trackers": false,
    "annoyances": false,
    "enableWebRecording": true,
    "profile": {
      "id": "text",
      "persistChanges": true
    },
    "acceptCookies": true,
    "proxyCountry": "US",
    "proxyState": "AL",
    "extensionIds": [],
    "urlBlocklist": [],
    "browserArgs": [],
    "operatingSystems": [
      "windows"
    ],
    "device": [
      "desktop"
    ],
    "platform": [
      "chrome"
    ],
    "locales": [
      "en"
    ],
    "screen": {
      "width": 1280,
      "height": 720
    }
  }'
200
Copy
{
  "id": "123e4567-e89b-12d3-a456-426614174000",
  "teamId": "123e4567-e89b-12d3-a456-426614174000",
  "startTime": "text",
  "endTime": "text",
  "createdAt": "text",
  "updatedAt": "text",
  "status": "active",
  "sessionUrl": "text",
  "liveUrl": "text",
  "token": "text",
  "wsEndpoint": "text"
}
Session created

Get session by ID
get
/api/session/{id}

Test it

Authorizations
Path parameters
id
string
Responses

200
Session details

404
Session not found
cURL
JavaScript
Python
HTTP
Copy
curl -L \
  --url 'https://app.hyperbrowser.ai/api/session/{id}' \
  --header 'x-api-key: YOUR_API_KEY'
200
404
Copy
{
  "id": "123e4567-e89b-12d3-a456-426614174000",
  "teamId": "123e4567-e89b-12d3-a456-426614174000",
  "startTime": "text",
  "endTime": "text",
  "createdAt": "text",
  "updatedAt": "text",
  "status": "active",
  "sessionUrl": "text",
  "liveUrl": "text",
  "token": "text",
  "wsEndpoint": "text"
}
Session details

Stop a session
put
/api/session/{id}/stop

Test it

Authorizations
Path parameters
id
string
Responses

200
Session stopped successfully

404
Session not found

500
Server error
cURL
JavaScript
Python
HTTP
Copy
curl -L \
  --request PUT \
  --url 'https://app.hyperbrowser.ai/api/session/{id}/stop' \
  --header 'x-api-key: YOUR_API_KEY'
200
404
500
Copy
{
  "success": true
}
Session stopped successfully

Get list of sessions
get
/api/sessions

Test it

Authorizations
Query parameters
page
number  default: 1
status
string  enum
Options: active, closed, error
Responses

200
List of sessions

400
Invalid query parameters

500
Server error
cURL
JavaScript
Python
HTTP
Copy
curl -L \
  --url 'https://app.hyperbrowser.ai/api/sessions' \
  --header 'x-api-key: YOUR_API_KEY'
200
400
500
Copy
{
  "totalCount": 100,
  "page": 1,
  "pageSize": 10,
  "sessions": [
    {
      "id": "123e4567-e89b-12d3-a456-426614174000",
      "teamId": "123e4567-e89b-12d3-a456-426614174000",
      "startTime": "text",
      "endTime": "text",
      "createdAt": "text",
      "updatedAt": "text",
      "status": "active"
    }
  ]
}
List of sessions

Scrape
Create new scrape job
post
/api/scrape

Test it

Authorizations
Body
url
string  min: 1
sessionOptions
object

Show child attributes
scrapeOptions
object

Show child attributes
Responses

200
Scrape job created

400
Invalid request parameters

500
Server error
cURL
JavaScript
Python
HTTP
Copy
curl -L \
  --request POST \
  --url 'https://app.hyperbrowser.ai/api/scrape' \
  --header 'x-api-key: YOUR_API_KEY' \
  --header 'Content-Type: application/json' \
  --data '{
    "url": "text",
    "sessionOptions": {
      "useStealth": false,
      "useProxy": false,
      "proxyServer": "text",
      "proxyServerPassword": "text",
      "proxyServerUsername": "text",
      "proxyCity": "new york",
      "solveCaptchas": false,
      "adblock": false,
      "trackers": false,
      "annoyances": false,
      "enableWebRecording": true,
      "profile": {
        "id": "text",
        "persistChanges": true
      },
      "acceptCookies": true,
      "proxyCountry": "US",
      "proxyState": "AL",
      "extensionIds": [],
      "urlBlocklist": [],
      "browserArgs": [],
      "operatingSystems": [
        "windows"
      ],
      "device": [
        "desktop"
      ],
      "platform": [
        "chrome"
      ],
      "locales": [
        "en"
      ],
      "screen": {
        "width": 1280,
        "height": 720
      }
    },
    "scrapeOptions": {
      "onlyMainContent": true,
      "waitFor": 0,
      "timeout": 30000,
      "waitUntil": "load",
      "includeTags": [
        "text"
      ],
      "excludeTags": [
        "text"
      ],
      "formats": [
        "markdown"
      ],
      "screenshotOptions": {
        "fullPage": false,
        "format": "webp"
      }
    }
  }'
200
400
500
Copy
{
  "jobId": "text"
}
Scrape job created

Get scrape job status and result
get
/api/scrape/{id}

Test it

Authorizations
Path parameters
id
string  uuid
Responses

200
Scrape job details

404
Job not found

500
Server error
cURL
JavaScript
Python
HTTP
Copy
curl -L \
  --url 'https://app.hyperbrowser.ai/api/scrape/{id}' \
  --header 'x-api-key: YOUR_API_KEY'
200
404
500
Copy
{
  "jobId": "text",
  "data": {
    "markdown": "text",
    "html": "text",
    "screenshot": "text",
    "links": [
      "text"
    ],
    "metadata": {
      "ANY_ADDITIONAL_PROPERTY": "text"
    }
  },
  "error": "text",
  "status": "pending"
}
Scrape job details

Start a batch scrape job
post
/api/scrape/batch

Test it

Authorizations
Body
sessionOptions
object

Show child attributes
scrapeOptions
object

Show child attributes
urls
string[]
Responses

200
Batch scrape job started successfully

400
Invalid request parameters

402
Insufficient plan

429
Too many concurrent batch scrape jobs

500
Server error
cURL
JavaScript
Python
HTTP
Copy
curl -L \
  --request POST \
  --url 'https://app.hyperbrowser.ai/api/scrape/batch' \
  --header 'x-api-key: YOUR_API_KEY' \
  --header 'Content-Type: application/json' \
  --data '{
    "sessionOptions": {
      "useStealth": false,
      "useProxy": false,
      "proxyServer": "text",
      "proxyServerPassword": "text",
      "proxyServerUsername": "text",
      "proxyCity": "new york",
      "solveCaptchas": false,
      "adblock": false,
      "trackers": false,
      "annoyances": false,
      "enableWebRecording": true,
      "profile": {
        "id": "text",
        "persistChanges": true
      },
      "acceptCookies": true,
      "proxyCountry": "US",
      "proxyState": "AL",
      "extensionIds": [],
      "urlBlocklist": [],
      "browserArgs": [],
      "operatingSystems": [
        "windows"
      ],
      "device": [
        "desktop"
      ],
      "platform": [
        "chrome"
      ],
      "locales": [
        "en"
      ],
      "screen": {
        "width": 1280,
        "height": 720
      }
    },
    "scrapeOptions": {
      "onlyMainContent": true,
      "waitFor": 0,
      "timeout": 30000,
      "waitUntil": "load",
      "includeTags": [
        "text"
      ],
      "excludeTags": [
        "text"
      ],
      "formats": [
        "markdown"
      ],
      "screenshotOptions": {
        "fullPage": false,
        "format": "webp"
      }
    },
    "urls": [
      "text"
    ]
  }'
200
400
402
429
500
Copy
{
  "jobId": "text"
}
Batch scrape job started successfully

Get batch scrape job status and results
get
/api/scrape/batch/{id}

Test it

Authorizations
Path parameters
id
string
Responses

200
Batch scrape job details

400
Invalid request parameters

404
Batch scrape job not found

500
Server error
cURL
JavaScript
Python
HTTP
Copy
curl -L \
  --url 'https://app.hyperbrowser.ai/api/scrape/batch/{id}' \
  --header 'x-api-key: YOUR_API_KEY'
200
400
404
500
Copy
{
  "jobId": "text",
  "error": "text",
  "totalScrapedPages": 1,
  "totalPageBatches": 1,
  "currentPageBatch": 1,
  "batchSize": 1,
  "status": "pending",
  "data": [
    {
      "url": "text",
      "error": "text",
      "markdown": "text",
      "html": "text",
      "screenshot": "text",
      "status": "completed",
      "links": [
        "text"
      ],
      "metadata": {
        "ANY_ADDITIONAL_PROPERTY": "text"
      }
    }
  ]
}
Batch scrape job details

Crawl
Start a crawl job
post
/api/crawl

Test it

Authorizations
Body
url
string
maxPages
integer  min: 1
followLinks
boolean  default: true
ignoreSitemap
boolean  default: false
sessionOptions
object

Show child attributes
scrapeOptions
object

Show child attributes
excludePatterns
string[]
includePatterns
string[]
Responses

200
Crawl job started successfully

400
Invalid request parameters

500
Server error
cURL
JavaScript
Python
HTTP
Copy
curl -L \
  --request POST \
  --url 'https://app.hyperbrowser.ai/api/crawl' \
  --header 'x-api-key: YOUR_API_KEY' \
  --header 'Content-Type: application/json' \
  --data '{
    "url": "text",
    "maxPages": 1,
    "followLinks": true,
    "ignoreSitemap": false,
    "sessionOptions": {
      "useStealth": false,
      "useProxy": false,
      "proxyServer": "text",
      "proxyServerPassword": "text",
      "proxyServerUsername": "text",
      "proxyCity": "new york",
      "solveCaptchas": false,
      "adblock": false,
      "trackers": false,
      "annoyances": false,
      "enableWebRecording": true,
      "profile": {
        "id": "text",
        "persistChanges": true
      },
      "acceptCookies": true,
      "proxyCountry": "US",
      "proxyState": "AL",
      "extensionIds": [],
      "urlBlocklist": [],
      "browserArgs": [],
      "operatingSystems": [
        "windows"
      ],
      "device": [
        "desktop"
      ],
      "platform": [
        "chrome"
      ],
      "locales": [
        "en"
      ],
      "screen": {
        "width": 1280,
        "height": 720
      }
    },
    "scrapeOptions": {
      "onlyMainContent": true,
      "waitFor": 0,
      "timeout": 30000,
      "waitUntil": "load",
      "includeTags": [
        "text"
      ],
      "excludeTags": [
        "text"
      ],
      "formats": [
        "markdown"
      ],
      "screenshotOptions": {
        "fullPage": false,
        "format": "webp"
      }
    },
    "excludePatterns": [
      "text"
    ],
    "includePatterns": [
      "text"
    ]
  }'
200
400
500
Copy
{
  "jobId": "text"
}
Crawl job started successfully

Get crawl job status and results
get
/api/crawl/{id}

Test it

Authorizations
Path parameters
id
string
Query parameters
page
integer
batchSize
integer  min: 1
Responses

200
Crawl job details retrieved successfully

404
Crawl job not found

500
Server error
cURL
JavaScript
Python
HTTP
Copy
curl -L \
  --url 'https://app.hyperbrowser.ai/api/crawl/{id}' \
  --header 'x-api-key: YOUR_API_KEY'
200
404
500
Copy
{
  "jobId": "123e4567-e89b-12d3-a456-426614174000",
  "error": "text",
  "totalCrawledPages": 1,
  "totalPageBatches": 1,
  "currentPageBatch": 1,
  "batchSize": 1,
  "status": "pending",
  "data": [
    {
      "url": "text",
      "error": "text",
      "markdown": "text",
      "html": "text",
      "screenshot": "text",
      "status": "completed",
      "links": [
        "text"
      ],
      "metadata": {
        "ANY_ADDITIONAL_PROPERTY": "text"
      }
    }
  ]
}
Crawl job details retrieved successfully

Profiles
Creates a new profile
post
/api/profile

Test it

Authorizations
Responses

200
Profile created
cURL
JavaScript
Python
HTTP
Copy
curl -L \
  --request POST \
  --url 'https://app.hyperbrowser.ai/api/profile' \
  --header 'x-api-key: YOUR_API_KEY'
200
Copy
{
  "id": "text"
}
Profile created

Get profile by ID
get
/api/profile/{id}

Test it

Authorizations
Path parameters
id
string
Responses

200
Profile details

404
Profile not found
cURL
JavaScript
Python
HTTP
Copy
curl -L \
  --url 'https://app.hyperbrowser.ai/api/profile/{id}' \
  --header 'x-api-key: YOUR_API_KEY'
200
404
Copy
{
  "id": "text",
  "teamId": "text",
  "createdAt": "text",
  "updatedAt": "text"
}
Profile details

Delete profile by ID
delete
/api/profile/{id}

Test it

Authorizations
Path parameters
id
string
Responses

200
Profile deleted
cURL
JavaScript
Python
HTTP
Copy
curl -L \
  --request DELETE \
  --url 'https://app.hyperbrowser.ai/api/profile/{id}' \
  --header 'x-api-key: YOUR_API_KEY'
200
Copy
{
  "success": true
}
Profile deleted

Extensions
Add a new extension
post
/api/extensions/add

Test it

Authorizations
Body
file
string  binary
name
string
Responses

200
Extension added successfully
cURL
JavaScript
Python
HTTP
Copy
curl -L \
  --request POST \
  --url 'https://app.hyperbrowser.ai/api/extensions/add' \
  --header 'x-api-key: YOUR_API_KEY' \
  --header 'Content-Type: multipart/form-data' \
  --form 'file=text' \
  --form 'name=text'
200
Copy
{
  "id": "text",
  "name": "text",
  "createdAt": "text",
  "updatedAt": "text"
}
Extension added successfully

List all extensions
get
/api/extensions/list

Test it

Authorizations
Responses

200
Extension added successfully
cURL
JavaScript
Python
HTTP
Copy
curl -L \
  --url 'https://app.hyperbrowser.ai/api/extensions/list' \
  --header 'x-api-key: YOUR_API_KEY'
200
Copy
[
  {
    "id": "text",
    "name": "text",
    "createdAt": "text",
    "updatedAt": "text"
  }
]
Extension added successfully

Integrations
LangChain
Using Hyperbrowser's Document Loader Integration

Hyperbrowser provides a Document Loader integration with LangChain via the langchain-hyperbrowser package. It can be used to load the metadata and contents(in formatted markdown or html) of any site as a LangChain Document.

Installation and Setup
To get started with langchain-hyperbrowser, you can install the package using pip:

Copy
pip install langchain-hyperbrowser
And you should configure credentials by setting the following environment variables:

HYPERBROWSER_API_KEY=<your-api-key>

You can get an API Key easily from the dashboard. Once you have your API Key, add it to your .env file as HYPERBROWSER_API_KEY or you can pass it via the api_key argument in the constructor. 

Document Loader
The HyperbrowserLoader class in langchain-hyperbrowser can easily be used to load content from any single page or multiple pages as well as crawl an entire site. The content can be loaded as markdown or html.

Copy
from langchain_hyperbrowser import HyperbrowserLoader

loader = HyperbrowserLoader(urls="https://example.com")
docs = loader.load()

print(docs[0])
Advanced Usage
You can specify the operation to be performed by the loader. The default operation is scrape. For scrape, you can provide a single URL or a list of URLs to be scraped. For crawl, you can only provide a single URL. The crawl operation will crawl the provided page and subpages and return a document for each page.

Copy
loader = HyperbrowserLoader(
  urls="https://hyperbrowser.ai", api_key="YOUR_API_KEY", operation="crawl"
)
Optional params for the loader can also be provided in the params argument. For more information on the supported params, you can see the params for scraping or crawling.

Copy
loader = HyperbrowserLoader(
  urls="https://example.com",
  api_key="YOUR_API_KEY",
  operation="scrape",
  params={"scrape_options": {"include_tags": ["h1", "h2", "p"]}}
)
LlamaIndex
Using Hyperbrowser's Web Reader Integration

Installation and Setup
To get started with LlamaIndex and Hyperbrowser, you can install the necessary packages using pip:

Copy
pip install llama-index-core llama-index-readers-web hyperbrowser
And you should configure credentials by setting the following environment variables:

HYPERBROWSER_API_KEY=<your-api-key>

You can get an API Key easily from the dashboard. Once you have your API Key, add it to your .env file as HYPERBROWSER_API_KEY or you can pass it via the api_key argument in the HyperbrowserWebReader constructor.

Usage
Once you have your API Key and have installed the packages you can load webpages into LlamaIndex using HyperbrowserWebReader.

Copy
from llama_index.readers.web import HyperbrowserWebReader

reader = HyperbrowserWebReader(api_key="your_api_key_here")
To load data, you can specify the operation to be performed by the loader. The default operation is scrape. For scrape, you can provide a single URL or a list of URLs to be scraped. For crawl, you can only provide a single URL. The crawl operation will crawl the provided page and subpages and return a document for each page. HyperbrowserWebReader supports loading and lazy loading data in both sync and async modes.

Copy
documents = reader.load_data(
    urls=["https://example.com"],
    operation="scrape",
)
Optional params for the loader can also be provided in the params argument. For more information on the supported params, you can see the params for scraping or crawling.

Copy
documents = reader.load_data(
    urls=["https://example.com"],
    operation="scrape",
    params={"scrape_options": {"include_tags": ["h1", "h2", "p"]}},
)

Playwright nav map 

Skip to main content
Playwright logo
Playwright
Docs
API
Node.js
Community

API reference
Playwright Test
Playwright Library
Classes
APIRequest
APIRequestContext
APIResponse
Accessibility
Browser
BrowserContext
BrowserServer
BrowserType
CDPSession
Clock
ConsoleMessage
Coverage
Dialog
Download
ElementHandle
FileChooser
Frame
FrameLocator
JSHandle
Keyboard
Locator
Logger
Mouse
Page
Request
Response
Route
Selectors
TimeoutError
Touchscreen
Tracing
Video
WebError
WebSocket
WebSocketRoute
Worker
Assertions
APIResponseAssertions
GenericAssertions
LocatorAssertions
PageAssertions
SnapshotAssertions
Test Runner
Fixtures
FullConfig
FullProject
Location
Playwright Test
TestConfig
TestInfo
TestInfoError
TestOptions
TestProject
WorkerInfo
Test Reporter
Reporter
Suite
TestCase
TestError
TestResult
TestStep
Experimental
Android
AndroidDevice
AndroidInput
AndroidSocket
AndroidWebView
Electron
ElectronApplication
API referenceClassesLocator
Locator
Locators are the central piece of Playwright's auto-waiting and retry-ability. In a nutshell, locators represent a way to find element(s) on the page at any moment. A locator can be created with the page.locator() method.

Learn more about locators.

Methods
all
Added in: v1.29 
When the locator points to a list of elements, this returns an array of locators, pointing to their respective elements.

note
locator.all() does not wait for elements to match the locator, and instead immediately returns whatever is present in the page.

When the list of elements changes dynamically, locator.all() will produce unpredictable and flaky results.

When the list of elements is stable, but loaded dynamically, wait for the full list to finish loading before calling locator.all().

Usage

for (const li of await page.getByRole('listitem').all())
  await li.click();

Returns

Promise<Array<Locator>>#
allInnerTexts
Added in: v1.14 
Returns an array of node.innerText values for all matching nodes.

Asserting text
If you need to assert text on the page, prefer expect(locator).toHaveText() with useInnerText option to avoid flakiness. See assertions guide for more details.

Usage

const texts = await page.getByRole('link').allInnerTexts();

Returns

Promise<Array<string>>#
allTextContents
Added in: v1.14 
Returns an array of node.textContent values for all matching nodes.

Asserting text
If you need to assert text on the page, prefer expect(locator).toHaveText() to avoid flakiness. See assertions guide for more details.

Usage

const texts = await page.getByRole('link').allTextContents();

Returns

Promise<Array<string>>#
and
Added in: v1.34 
Creates a locator that matches both this locator and the argument locator.

Usage

The following example finds a button with a specific title.

const button = page.getByRole('button').and(page.getByTitle('Subscribe'));

Arguments

locator Locator#

Additional locator to match.

Returns

Locator#
ariaSnapshot
Added in: v1.49 
Captures the aria snapshot of the given element. Read more about aria snapshots and expect(locator).toMatchAriaSnapshot() for the corresponding assertion.

Usage

await page.getByRole('link').ariaSnapshot();

Arguments

options Object (optional)
timeout number (optional)#

Maximum time in milliseconds. Defaults to 0 - no timeout. The default value can be changed via actionTimeout option in the config, or by using the browserContext.setDefaultTimeout() or page.setDefaultTimeout() methods.

Returns

Promise<string>#
Details

This method captures the aria snapshot of the given element. The snapshot is a string that represents the state of the element and its children. The snapshot can be used to assert the state of the element in the test, or to compare it to state in the future.

The ARIA snapshot is represented using YAML markup language:

The keys of the objects are the roles and optional accessible names of the elements.
The values are either text content or an array of child elements.
Generic static text can be represented with the text key.
Below is the HTML markup and the respective ARIA snapshot:

<ul aria-label="Links">
  <li><a href="/">Home</a></li>
  <li><a href="/about">About</a></li>
<ul>

- list "Links":
  - listitem:
    - link "Home"
  - listitem:
    - link "About"

blur
Added in: v1.28 
Calls blur on the element.

Usage

await locator.blur();
await locator.blur(options);

Arguments

options Object (optional)
timeout number (optional)#

Maximum time in milliseconds. Defaults to 0 - no timeout. The default value can be changed via actionTimeout option in the config, or by using the browserContext.setDefaultTimeout() or page.setDefaultTimeout() methods.

Returns

Promise<void>#
boundingBox
Added in: v1.14 
This method returns the bounding box of the element matching the locator, or null if the element is not visible. The bounding box is calculated relative to the main frame viewport - which is usually the same as the browser window.

Usage

const box = await page.getByRole('button').boundingBox();
await page.mouse.click(box.x + box.width / 2, box.y + box.height / 2);

Arguments

options Object (optional)
timeout number (optional)#

Maximum time in milliseconds. Defaults to 0 - no timeout. The default value can be changed via actionTimeout option in the config, or by using the browserContext.setDefaultTimeout() or page.setDefaultTimeout() methods.

Returns

Promise<null | Object>#
x number

the x coordinate of the element in pixels.

y number

the y coordinate of the element in pixels.

width number

the width of the element in pixels.

height number

the height of the element in pixels.

Details

Scrolling affects the returned bounding box, similarly to Element.getBoundingClientRect. That means x and/or y may be negative.

Elements from child frames return the bounding box relative to the main frame, unlike the Element.getBoundingClientRect.

Assuming the page is static, it is safe to use bounding box coordinates to perform input. For example, the following snippet should click the center of the element.

check
Added in: v1.14 
Ensure that checkbox or radio element is checked.

Usage

await page.getByRole('checkbox').check();

Arguments

options Object (optional)
force boolean (optional)#

Whether to bypass the actionability checks. Defaults to false.

noWaitAfter boolean (optional)#

Deprecated
This option has no effect.

This option has no effect.

position Object (optional)#

x number

y number

A point to use relative to the top-left corner of element padding box. If not specified, uses some visible point of the element.

timeout number (optional)#

Maximum time in milliseconds. Defaults to 0 - no timeout. The default value can be changed via actionTimeout option in the config, or by using the browserContext.setDefaultTimeout() or page.setDefaultTimeout() methods.

trial boolean (optional)#

When set, this method only performs the actionability checks and skips the action. Defaults to false. Useful to wait until the element is ready for the action without performing it.

Returns

Promise<void>#
Details

Performs the following steps:

Ensure that element is a checkbox or a radio input. If not, this method throws. If the element is already checked, this method returns immediately.
Wait for actionability checks on the element, unless force option is set.
Scroll the element into view if needed.
Use page.mouse to click in the center of the element.
Ensure that the element is now checked. If not, this method throws.
If the element is detached from the DOM at any moment during the action, this method throws.

When all steps combined have not finished during the specified timeout, this method throws a TimeoutError. Passing zero timeout disables this.

clear
Added in: v1.28 
Clear the input field.

Usage

await page.getByRole('textbox').clear();

Arguments

options Object (optional)
force boolean (optional)#

Whether to bypass the actionability checks. Defaults to false.

noWaitAfter boolean (optional)#

Deprecated
This option has no effect.

This option has no effect.

timeout number (optional)#

Maximum time in milliseconds. Defaults to 0 - no timeout. The default value can be changed via actionTimeout option in the config, or by using the browserContext.setDefaultTimeout() or page.setDefaultTimeout() methods.

Returns

Promise<void>#
Details

This method waits for actionability checks, focuses the element, clears it and triggers an input event after clearing.

If the target element is not an <input>, <textarea> or [contenteditable] element, this method throws an error. However, if the element is inside the <label> element that has an associated control, the control will be cleared instead.

click
Added in: v1.14 
Click an element.

Usage

Click a button:

await page.getByRole('button').click();

Shift-right-click at a specific position on a canvas:

await page.locator('canvas').click({
  button: 'right',
  modifiers: ['Shift'],
  position: { x: 23, y: 32 },
});

Arguments

options Object (optional)
button "left" | "right" | "middle" (optional)#

Defaults to left.

clickCount number (optional)#

defaults to 1. See UIEvent.detail.

delay number (optional)#

Time to wait between mousedown and mouseup in milliseconds. Defaults to 0.

force boolean (optional)#

Whether to bypass the actionability checks. Defaults to false.

modifiers Array<"Alt" | "Control" | "ControlOrMeta" | "Meta" | "Shift"> (optional)#

Modifier keys to press. Ensures that only these modifiers are pressed during the operation, and then restores current modifiers back. If not specified, currently pressed modifiers are used. "ControlOrMeta" resolves to "Control" on Windows and Linux and to "Meta" on macOS.

noWaitAfter boolean (optional)#

Deprecated
This option will default to true in the future.

Actions that initiate navigations are waiting for these navigations to happen and for pages to start loading. You can opt out of waiting via setting this flag. You would only need this option in the exceptional cases such as navigating to inaccessible pages. Defaults to false.

position Object (optional)#

x number

y number

A point to use relative to the top-left corner of element padding box. If not specified, uses some visible point of the element.

timeout number (optional)#

Maximum time in milliseconds. Defaults to 0 - no timeout. The default value can be changed via actionTimeout option in the config, or by using the browserContext.setDefaultTimeout() or page.setDefaultTimeout() methods.

trial boolean (optional)#

When set, this method only performs the actionability checks and skips the action. Defaults to false. Useful to wait until the element is ready for the action without performing it. Note that keyboard modifiers will be pressed regardless of trial to allow testing elements which are only visible when those keys are pressed.

Returns

Promise<void>#
Details

This method clicks the element by performing the following steps:

Wait for actionability checks on the element, unless force option is set.
Scroll the element into view if needed.
Use page.mouse to click in the center of the element, or the specified position.
Wait for initiated navigations to either succeed or fail, unless noWaitAfter option is set.
If the element is detached from the DOM at any moment during the action, this method throws.

When all steps combined have not finished during the specified timeout, this method throws a TimeoutError. Passing zero timeout disables this.

contentFrame
Added in: v1.43 
Returns a FrameLocator object pointing to the same iframe as this locator.

Useful when you have a Locator object obtained somewhere, and later on would like to interact with the content inside the frame.

For a reverse operation, use frameLocator.owner().

Usage

const locator = page.locator('iframe[name="embedded"]');
// ...
const frameLocator = locator.contentFrame();
await frameLocator.getByRole('button').click();

Returns

FrameLocator#
count
Added in: v1.14 
Returns the number of elements matching the locator.

Asserting count
If you need to assert the number of elements on the page, prefer expect(locator).toHaveCount() to avoid flakiness. See assertions guide for more details.

Usage

const count = await page.getByRole('listitem').count();

Returns

Promise<number>#
dblclick
Added in: v1.14 
Double-click an element.

Usage

await locator.dblclick();
await locator.dblclick(options);

Arguments

options Object (optional)
button "left" | "right" | "middle" (optional)#

Defaults to left.

delay number (optional)#

Time to wait between mousedown and mouseup in milliseconds. Defaults to 0.

force boolean (optional)#

Whether to bypass the actionability checks. Defaults to false.

modifiers Array<"Alt" | "Control" | "ControlOrMeta" | "Meta" | "Shift"> (optional)#

Modifier keys to press. Ensures that only these modifiers are pressed during the operation, and then restores current modifiers back. If not specified, currently pressed modifiers are used. "ControlOrMeta" resolves to "Control" on Windows and Linux and to "Meta" on macOS.

noWaitAfter boolean (optional)#

Deprecated
This option has no effect.

This option has no effect.

position Object (optional)#

x number

y number

A point to use relative to the top-left corner of element padding box. If not specified, uses some visible point of the element.

timeout number (optional)#

Maximum time in milliseconds. Defaults to 0 - no timeout. The default value can be changed via actionTimeout option in the config, or by using the browserContext.setDefaultTimeout() or page.setDefaultTimeout() methods.

trial boolean (optional)#

When set, this method only performs the actionability checks and skips the action. Defaults to false. Useful to wait until the element is ready for the action without performing it. Note that keyboard modifiers will be pressed regardless of trial to allow testing elements which are only visible when those keys are pressed.

Returns

Promise<void>#
Details

This method double clicks the element by performing the following steps:

Wait for actionability checks on the element, unless force option is set.
Scroll the element into view if needed.
Use page.mouse to double click in the center of the element, or the specified position.
If the element is detached from the DOM at any moment during the action, this method throws.

When all steps combined have not finished during the specified timeout, this method throws a TimeoutError. Passing zero timeout disables this.

note
element.dblclick() dispatches two click events and a single dblclick event.

dispatchEvent
Added in: v1.14 
Programmatically dispatch an event on the matching element.

Usage

await locator.dispatchEvent('click');

Arguments

type string#

DOM event type: "click", "dragstart", etc.

eventInit EvaluationArgument (optional)#

Optional event-specific initialization properties.

options Object (optional)

timeout number (optional)#

Maximum time in milliseconds. Defaults to 0 - no timeout. The default value can be changed via actionTimeout option in the config, or by using the browserContext.setDefaultTimeout() or page.setDefaultTimeout() methods.

Returns

Promise<void>#
Details

The snippet above dispatches the click event on the element. Regardless of the visibility state of the element, click is dispatched. This is equivalent to calling element.click().

Under the hood, it creates an instance of an event based on the given type, initializes it with eventInit properties and dispatches it on the element. Events are composed, cancelable and bubble by default.

Since eventInit is event-specific, please refer to the events documentation for the lists of initial properties:

DeviceMotionEvent
DeviceOrientationEvent
DragEvent
Event
FocusEvent
KeyboardEvent
MouseEvent
PointerEvent
TouchEvent
WheelEvent
You can also specify JSHandle as the property value if you want live objects to be passed into the event:

const dataTransfer = await page.evaluateHandle(() => new DataTransfer());
await locator.dispatchEvent('dragstart', { dataTransfer });

dragTo
Added in: v1.18 
Drag the source element towards the target element and drop it.

Usage

const source = page.locator('#source');
const target = page.locator('#target');

await source.dragTo(target);
// or specify exact positions relative to the top-left corners of the elements:
await source.dragTo(target, {
  sourcePosition: { x: 34, y: 7 },
  targetPosition: { x: 10, y: 20 },
});

Arguments

target Locator#

Locator of the element to drag to.

options Object (optional)

force boolean (optional)#

Whether to bypass the actionability checks. Defaults to false.

noWaitAfter boolean (optional)#

Deprecated
This option has no effect.

This option has no effect.

sourcePosition Object (optional)#

x number

y number

Clicks on the source element at this point relative to the top-left corner of the element's padding box. If not specified, some visible point of the element is used.

targetPosition Object (optional)#

x number

y number

Drops on the target element at this point relative to the top-left corner of the element's padding box. If not specified, some visible point of the element is used.

timeout number (optional)#

Maximum time in milliseconds. Defaults to 0 - no timeout. The default value can be changed via actionTimeout option in the config, or by using the browserContext.setDefaultTimeout() or page.setDefaultTimeout() methods.

trial boolean (optional)#

When set, this method only performs the actionability checks and skips the action. Defaults to false. Useful to wait until the element is ready for the action without performing it.

Returns

Promise<void>#
Details

This method drags the locator to another target locator or target position. It will first move to the source element, perform a mousedown, then move to the target element or position and perform a mouseup.

evaluate
Added in: v1.14 
Execute JavaScript code in the page, taking the matching element as an argument.

Usage

const tweets = page.locator('.tweet .retweets');
expect(await tweets.evaluate(node => node.innerText)).toBe('10 retweets');

Arguments

pageFunction function | string#

Function to be evaluated in the page context.

arg EvaluationArgument (optional)#

Optional argument to pass to pageFunction.

options Object (optional)

timeout number (optional)#

Maximum time in milliseconds. Defaults to 0 - no timeout. The default value can be changed via actionTimeout option in the config, or by using the browserContext.setDefaultTimeout() or page.setDefaultTimeout() methods.

Returns

Promise<Serializable>#
Details

Returns the return value of pageFunction, called with the matching element as a first argument, and arg as a second argument.

If pageFunction returns a Promise, this method will wait for the promise to resolve and return its value.

If pageFunction throws or rejects, this method throws.

evaluateAll
Added in: v1.14 
Execute JavaScript code in the page, taking all matching elements as an argument.

Usage

const locator = page.locator('div');
const moreThanTen = await locator.evaluateAll((divs, min) => divs.length > min, 10);

Arguments

pageFunction function | string#

Function to be evaluated in the page context.

arg EvaluationArgument (optional)#

Optional argument to pass to pageFunction.

Returns

Promise<Serializable>#
Details

Returns the return value of pageFunction, called with an array of all matching elements as a first argument, and arg as a second argument.

If pageFunction returns a Promise, this method will wait for the promise to resolve and return its value.

If pageFunction throws or rejects, this method throws.

evaluateHandle
Added in: v1.14 
Execute JavaScript code in the page, taking the matching element as an argument, and return a JSHandle with the result.

Usage

await locator.evaluateHandle(pageFunction);
await locator.evaluateHandle(pageFunction, arg, options);

Arguments

pageFunction function | string#

Function to be evaluated in the page context.

arg EvaluationArgument (optional)#

Optional argument to pass to pageFunction.

options Object (optional)

timeout number (optional)#

Maximum time in milliseconds. Defaults to 0 - no timeout. The default value can be changed via actionTimeout option in the config, or by using the browserContext.setDefaultTimeout() or page.setDefaultTimeout() methods.

Returns

Promise<JSHandle>#
Details

Returns the return value of pageFunction as aJSHandle, called with the matching element as a first argument, and arg as a second argument.

The only difference between locator.evaluate() and locator.evaluateHandle() is that locator.evaluateHandle() returns JSHandle.

If pageFunction returns a Promise, this method will wait for the promise to resolve and return its value.

If pageFunction throws or rejects, this method throws.

See page.evaluateHandle() for more details.

fill
Added in: v1.14 
Set a value to the input field.

Usage

await page.getByRole('textbox').fill('example value');

Arguments

value string#

Value to set for the <input>, <textarea> or [contenteditable] element.

options Object (optional)

force boolean (optional)#

Whether to bypass the actionability checks. Defaults to false.

noWaitAfter boolean (optional)#

Deprecated
This option has no effect.

This option has no effect.

timeout number (optional)#

Maximum time in milliseconds. Defaults to 0 - no timeout. The default value can be changed via actionTimeout option in the config, or by using the browserContext.setDefaultTimeout() or page.setDefaultTimeout() methods.

Returns

Promise<void>#
Details

This method waits for actionability checks, focuses the element, fills it and triggers an input event after filling. Note that you can pass an empty string to clear the input field.

If the target element is not an <input>, <textarea> or [contenteditable] element, this method throws an error. However, if the element is inside the <label> element that has an associated control, the control will be filled instead.

To send fine-grained keyboard events, use locator.pressSequentially().

filter
Added in: v1.22 
This method narrows existing locator according to the options, for example filters by text. It can be chained to filter multiple times.

Usage

const rowLocator = page.locator('tr');
// ...
await rowLocator
    .filter({ hasText: 'text in column 1' })
    .filter({ has: page.getByRole('button', { name: 'column 2 button' }) })
    .screenshot();

Arguments

options Object (optional)
has Locator (optional)#

Narrows down the results of the method to those which contain elements matching this relative locator. For example, article that has text=Playwright matches <article><div>Playwright</div></article>.

Inner locator must be relative to the outer locator and is queried starting with the outer locator match, not the document root. For example, you can find content that has div in <article><content><div>Playwright</div></content></article>. However, looking for content that has article div will fail, because the inner locator must be relative and should not use any elements outside the content.

Note that outer and inner locators must belong to the same frame. Inner locator must not contain FrameLocators.

hasNot Locator (optional) Added in: v1.33#

Matches elements that do not contain an element that matches an inner locator. Inner locator is queried against the outer one. For example, article that does not have div matches <article><span>Playwright</span></article>.

Note that outer and inner locators must belong to the same frame. Inner locator must not contain FrameLocators.

hasNotText string | RegExp (optional) Added in: v1.33#

Matches elements that do not contain specified text somewhere inside, possibly in a child or a descendant element. When passed a string, matching is case-insensitive and searches for a substring.

hasText string | RegExp (optional)#

Matches elements containing specified text somewhere inside, possibly in a child or a descendant element. When passed a string, matching is case-insensitive and searches for a substring. For example, "Playwright" matches <article><div>Playwright</div></article>.

Returns

Locator#
first
Added in: v1.14 
Returns locator to the first matching element.

Usage

locator.first();

Returns

Locator#
focus
Added in: v1.14 
Calls focus on the matching element.

Usage

await locator.focus();
await locator.focus(options);

Arguments

options Object (optional)
timeout number (optional)#

Maximum time in milliseconds. Defaults to 0 - no timeout. The default value can be changed via actionTimeout option in the config, or by using the browserContext.setDefaultTimeout() or page.setDefaultTimeout() methods.

Returns

Promise<void>#
frameLocator
Added in: v1.17 
When working with iframes, you can create a frame locator that will enter the iframe and allow locating elements in that iframe:

Usage

const locator = page.frameLocator('iframe').getByText('Submit');
await locator.click();

Arguments

selector string#

A selector to use when resolving DOM element.

Returns

FrameLocator#
getAttribute
Added in: v1.14 
Returns the matching element's attribute value.

Asserting attributes
If you need to assert an element's attribute, prefer expect(locator).toHaveAttribute() to avoid flakiness. See assertions guide for more details.

Usage

await locator.getAttribute(name);
await locator.getAttribute(name, options);

Arguments

name string#

Attribute name to get the value for.

options Object (optional)

timeout number (optional)#

Maximum time in milliseconds. Defaults to 0 - no timeout. The default value can be changed via actionTimeout option in the config, or by using the browserContext.setDefaultTimeout() or page.setDefaultTimeout() methods.

Returns

Promise<null | string>#
getByAltText
Added in: v1.27 
Allows locating elements by their alt text.

Usage

For example, this method will find the image by alt text "Playwright logo":

<img alt='Playwright logo'>

await page.getByAltText('Playwright logo').click();

Arguments

text string | RegExp#

Text to locate the element for.

options Object (optional)

exact boolean (optional)#

Whether to find an exact match: case-sensitive and whole-string. Default to false. Ignored when locating by a regular expression. Note that exact match still trims whitespace.

Returns

Locator#
getByLabel
Added in: v1.27 
Allows locating input elements by the text of the associated <label> or aria-labelledby element, or by the aria-label attribute.

Usage

For example, this method will find inputs by label "Username" and "Password" in the following DOM:

<input aria-label="Username">
<label for="password-input">Password:</label>
<input id="password-input">

await page.getByLabel('Username').fill('john');
await page.getByLabel('Password').fill('secret');

Arguments

text string | RegExp#

Text to locate the element for.

options Object (optional)

exact boolean (optional)#

Whether to find an exact match: case-sensitive and whole-string. Default to false. Ignored when locating by a regular expression. Note that exact match still trims whitespace.

Returns

Locator#
getByPlaceholder
Added in: v1.27 
Allows locating input elements by the placeholder text.

Usage

For example, consider the following DOM structure.

<input type="email" placeholder="name@example.com" />

You can fill the input after locating it by the placeholder text:

await page
    .getByPlaceholder('name@example.com')
    .fill('playwright@microsoft.com');

Arguments

text string | RegExp#

Text to locate the element for.

options Object (optional)

exact boolean (optional)#

Whether to find an exact match: case-sensitive and whole-string. Default to false. Ignored when locating by a regular expression. Note that exact match still trims whitespace.

Returns

Locator#
getByRole
Added in: v1.27 
Allows locating elements by their ARIA role, ARIA attributes and accessible name.

Usage

Consider the following DOM structure.

<h3>Sign up</h3>
<label>
  <input type="checkbox" /> Subscribe
</label>
<br/>
<button>Submit</button>

You can locate each element by it's implicit role:

await expect(page.getByRole('heading', { name: 'Sign up' })).toBeVisible();

await page.getByRole('checkbox', { name: 'Subscribe' }).check();

await page.getByRole('button', { name: /submit/i }).click();

Arguments

role "alert" | "alertdialog" | "application" | "article" | "banner" | "blockquote" | "button" | "caption" | "cell" | "checkbox" | "code" | "columnheader" | "combobox" | "complementary" | "contentinfo" | "definition" | "deletion" | "dialog" | "directory" | "document" | "emphasis" | "feed" | "figure" | "form" | "generic" | "grid" | "gridcell" | "group" | "heading" | "img" | "insertion" | "link" | "list" | "listbox" | "listitem" | "log" | "main" | "marquee" | "math" | "meter" | "menu" | "menubar" | "menuitem" | "menuitemcheckbox" | "menuitemradio" | "navigation" | "none" | "note" | "option" | "paragraph" | "presentation" | "progressbar" | "radio" | "radiogroup" | "region" | "row" | "rowgroup" | "rowheader" | "scrollbar" | "search" | "searchbox" | "separator" | "slider" | "spinbutton" | "status" | "strong" | "subscript" | "superscript" | "switch" | "tab" | "table" | "tablist" | "tabpanel" | "term" | "textbox" | "time" | "timer" | "toolbar" | "tooltip" | "tree" | "treegrid" | "treeitem"#

Required aria role.

options Object (optional)

checked boolean (optional)#

An attribute that is usually set by aria-checked or native <input type=checkbox> controls.

Learn more about aria-checked.

disabled boolean (optional)#

An attribute that is usually set by aria-disabled or disabled.

note
Unlike most other attributes, disabled is inherited through the DOM hierarchy. Learn more about aria-disabled.

exact boolean (optional) Added in: v1.28#

Whether name is matched exactly: case-sensitive and whole-string. Defaults to false. Ignored when name is a regular expression. Note that exact match still trims whitespace.

expanded boolean (optional)#

An attribute that is usually set by aria-expanded.

Learn more about aria-expanded.

includeHidden boolean (optional)#

Option that controls whether hidden elements are matched. By default, only non-hidden elements, as defined by ARIA, are matched by role selector.

Learn more about aria-hidden.

level number (optional)#

A number attribute that is usually present for roles heading, listitem, row, treeitem, with default values for <h1>-<h6> elements.

Learn more about aria-level.

name string | RegExp (optional)#

Option to match the accessible name. By default, matching is case-insensitive and searches for a substring, use exact to control this behavior.

Learn more about accessible name.

pressed boolean (optional)#

An attribute that is usually set by aria-pressed.

Learn more about aria-pressed.

selected boolean (optional)#

An attribute that is usually set by aria-selected.

Learn more about aria-selected.

Returns

Locator#
Details

Role selector does not replace accessibility audits and conformance tests, but rather gives early feedback about the ARIA guidelines.

Many html elements have an implicitly defined role that is recognized by the role selector. You can find all the supported roles here. ARIA guidelines do not recommend duplicating implicit roles and attributes by setting role and/or aria-* attributes to default values.

getByTestId
Added in: v1.27 
Locate element by the test id.

Usage

Consider the following DOM structure.

<button data-testid="directions">Itinraire</button>

You can locate the element by it's test id:

await page.getByTestId('directions').click();

Arguments

testId string | RegExp#

Id to locate the element by.

Returns

Locator#
Details

By default, the data-testid attribute is used as a test id. Use selectors.setTestIdAttribute() to configure a different test id attribute if necessary.

// Set custom test id attribute from @playwright/test config:
import { defineConfig } from '@playwright/test';

export default defineConfig({
  use: {
    testIdAttribute: 'data-pw'
  },
});

getByText
Added in: v1.27 
Allows locating elements that contain given text.

See also locator.filter() that allows to match by another criteria, like an accessible role, and then filter by the text content.

Usage

Consider the following DOM structure:

<div>Hello <span>world</span></div>
<div>Hello</div>

You can locate by text substring, exact string, or a regular expression:

// Matches <span>
page.getByText('world');

// Matches first <div>
page.getByText('Hello world');

// Matches second <div>
page.getByText('Hello', { exact: true });

// Matches both <div>s
page.getByText(/Hello/);

// Matches second <div>
page.getByText(/^hello$/i);

Arguments

text string | RegExp#

Text to locate the element for.

options Object (optional)

exact boolean (optional)#

Whether to find an exact match: case-sensitive and whole-string. Default to false. Ignored when locating by a regular expression. Note that exact match still trims whitespace.

Returns

Locator#
Details

Matching by text always normalizes whitespace, even with exact match. For example, it turns multiple spaces into one, turns line breaks into spaces and ignores leading and trailing whitespace.

Input elements of the type button and submit are matched by their value instead of the text content. For example, locating by text "Log in" matches <input type=button value="Log in">.

getByTitle
Added in: v1.27 
Allows locating elements by their title attribute.

Usage

Consider the following DOM structure.

<span title='Issues count'>25 issues</span>

You can check the issues count after locating it by the title text:

await expect(page.getByTitle('Issues count')).toHaveText('25 issues');

Arguments

text string | RegExp#

Text to locate the element for.

options Object (optional)

exact boolean (optional)#

Whether to find an exact match: case-sensitive and whole-string. Default to false. Ignored when locating by a regular expression. Note that exact match still trims whitespace.

Returns

Locator#
highlight
Added in: v1.20 
Highlight the corresponding element(s) on the screen. Useful for debugging, don't commit the code that uses locator.highlight().

Usage

await locator.highlight();

Returns

Promise<void>#
hover
Added in: v1.14 
Hover over the matching element.

Usage

await page.getByRole('link').hover();

Arguments

options Object (optional)
force boolean (optional)#

Whether to bypass the actionability checks. Defaults to false.

modifiers Array<"Alt" | "Control" | "ControlOrMeta" | "Meta" | "Shift"> (optional)#

Modifier keys to press. Ensures that only these modifiers are pressed during the operation, and then restores current modifiers back. If not specified, currently pressed modifiers are used. "ControlOrMeta" resolves to "Control" on Windows and Linux and to "Meta" on macOS.

noWaitAfter boolean (optional) Added in: v1.28#

Deprecated
This option has no effect.

This option has no effect.

position Object (optional)#

x number

y number

A point to use relative to the top-left corner of element padding box. If not specified, uses some visible point of the element.

timeout number (optional)#

Maximum time in milliseconds. Defaults to 0 - no timeout. The default value can be changed via actionTimeout option in the config, or by using the browserContext.setDefaultTimeout() or page.setDefaultTimeout() methods.

trial boolean (optional)#

When set, this method only performs the actionability checks and skips the action. Defaults to false. Useful to wait until the element is ready for the action without performing it. Note that keyboard modifiers will be pressed regardless of trial to allow testing elements which are only visible when those keys are pressed.

Returns

Promise<void>#
Details

This method hovers over the element by performing the following steps:

Wait for actionability checks on the element, unless force option is set.
Scroll the element into view if needed.
Use page.mouse to hover over the center of the element, or the specified position.
If the element is detached from the DOM at any moment during the action, this method throws.

When all steps combined have not finished during the specified timeout, this method throws a TimeoutError. Passing zero timeout disables this.

innerHTML
Added in: v1.14 
Returns the element.innerHTML.

Usage

await locator.innerHTML();
await locator.innerHTML(options);

Arguments

options Object (optional)
timeout number (optional)#

Maximum time in milliseconds. Defaults to 0 - no timeout. The default value can be changed via actionTimeout option in the config, or by using the browserContext.setDefaultTimeout() or page.setDefaultTimeout() methods.

Returns

Promise<string>#
innerText
Added in: v1.14 
Returns the element.innerText.

Asserting text
If you need to assert text on the page, prefer expect(locator).toHaveText() with useInnerText option to avoid flakiness. See assertions guide for more details.

Usage

await locator.innerText();
await locator.innerText(options);

Arguments

options Object (optional)
timeout number (optional)#

Maximum time in milliseconds. Defaults to 0 - no timeout. The default value can be changed via actionTimeout option in the config, or by using the browserContext.setDefaultTimeout() or page.setDefaultTimeout() methods.

Returns

Promise<string>#
inputValue
Added in: v1.14 
Returns the value for the matching <input> or <textarea> or <select> element.

Asserting value
If you need to assert input value, prefer expect(locator).toHaveValue() to avoid flakiness. See assertions guide for more details.

Usage

const value = await page.getByRole('textbox').inputValue();

Arguments

options Object (optional)
timeout number (optional)#

Maximum time in milliseconds. Defaults to 0 - no timeout. The default value can be changed via actionTimeout option in the config, or by using the browserContext.setDefaultTimeout() or page.setDefaultTimeout() methods.

Returns

Promise<string>#
Details

Throws elements that are not an input, textarea or a select. However, if the element is inside the <label> element that has an associated control, returns the value of the control.

isChecked
Added in: v1.14 
Returns whether the element is checked. Throws if the element is not a checkbox or radio input.

Asserting checked state
If you need to assert that checkbox is checked, prefer expect(locator).toBeChecked() to avoid flakiness. See assertions guide for more details.

Usage

const checked = await page.getByRole('checkbox').isChecked();

Arguments

options Object (optional)
timeout number (optional)#

Maximum time in milliseconds. Defaults to 0 - no timeout. The default value can be changed via actionTimeout option in the config, or by using the browserContext.setDefaultTimeout() or page.setDefaultTimeout() methods.

Returns

Promise<boolean>#
isDisabled
Added in: v1.14 
Returns whether the element is disabled, the opposite of enabled.

Asserting disabled state
If you need to assert that an element is disabled, prefer expect(locator).toBeDisabled() to avoid flakiness. See assertions guide for more details.

Usage

const disabled = await page.getByRole('button').isDisabled();

Arguments

options Object (optional)
timeout number (optional)#

Maximum time in milliseconds. Defaults to 0 - no timeout. The default value can be changed via actionTimeout option in the config, or by using the browserContext.setDefaultTimeout() or page.setDefaultTimeout() methods.

Returns

Promise<boolean>#
isEditable
Added in: v1.14 
Returns whether the element is editable. If the target element is not an <input>, <textarea>, <select>, [contenteditable] and does not have a role allowing [aria-readonly], this method throws an error.

Asserting editable state
If you need to assert that an element is editable, prefer expect(locator).toBeEditable() to avoid flakiness. See assertions guide for more details.

Usage

const editable = await page.getByRole('textbox').isEditable();

Arguments

options Object (optional)
timeout number (optional)#

Maximum time in milliseconds. Defaults to 0 - no timeout. The default value can be changed via actionTimeout option in the config, or by using the browserContext.setDefaultTimeout() or page.setDefaultTimeout() methods.

Returns

Promise<boolean>#
isEnabled
Added in: v1.14 
Returns whether the element is enabled.

Asserting enabled state
If you need to assert that an element is enabled, prefer expect(locator).toBeEnabled() to avoid flakiness. See assertions guide for more details.

Usage

const enabled = await page.getByRole('button').isEnabled();

Arguments

options Object (optional)
timeout number (optional)#

Maximum time in milliseconds. Defaults to 0 - no timeout. The default value can be changed via actionTimeout option in the config, or by using the browserContext.setDefaultTimeout() or page.setDefaultTimeout() methods.

Returns

Promise<boolean>#
isHidden
Added in: v1.14 
Returns whether the element is hidden, the opposite of visible.

Asserting visibility
If you need to assert that element is hidden, prefer expect(locator).toBeHidden() to avoid flakiness. See assertions guide for more details.

Usage

const hidden = await page.getByRole('button').isHidden();

Arguments

options Object (optional)
timeout number (optional)#

Deprecated
This option is ignored. locator.isHidden() does not wait for the element to become hidden and returns immediately.

Returns

Promise<boolean>#
isVisible
Added in: v1.14 
Returns whether the element is visible.

Asserting visibility
If you need to assert that element is visible, prefer expect(locator).toBeVisible() to avoid flakiness. See assertions guide for more details.

Usage

const visible = await page.getByRole('button').isVisible();

Arguments

options Object (optional)
timeout number (optional)#

Deprecated
This option is ignored. locator.isVisible() does not wait for the element to become visible and returns immediately.

Returns

Promise<boolean>#
last
Added in: v1.14 
Returns locator to the last matching element.

Usage

const banana = await page.getByRole('listitem').last();

Returns

Locator#
locator
Added in: v1.14 
The method finds an element matching the specified selector in the locator's subtree. It also accepts filter options, similar to locator.filter() method.

Learn more about locators.

Usage

locator.locator(selectorOrLocator);
locator.locator(selectorOrLocator, options);

Arguments

selectorOrLocator string | Locator#

A selector or locator to use when resolving DOM element.

options Object (optional)

has Locator (optional)#

Narrows down the results of the method to those which contain elements matching this relative locator. For example, article that has text=Playwright matches <article><div>Playwright</div></article>.

Inner locator must be relative to the outer locator and is queried starting with the outer locator match, not the document root. For example, you can find content that has div in <article><content><div>Playwright</div></content></article>. However, looking for content that has article div will fail, because the inner locator must be relative and should not use any elements outside the content.

Note that outer and inner locators must belong to the same frame. Inner locator must not contain FrameLocators.

hasNot Locator (optional) Added in: v1.33#

Matches elements that do not contain an element that matches an inner locator. Inner locator is queried against the outer one. For example, article that does not have div matches <article><span>Playwright</span></article>.

Note that outer and inner locators must belong to the same frame. Inner locator must not contain FrameLocators.

hasNotText string | RegExp (optional) Added in: v1.33#

Matches elements that do not contain specified text somewhere inside, possibly in a child or a descendant element. When passed a string, matching is case-insensitive and searches for a substring.

hasText string | RegExp (optional)#

Matches elements containing specified text somewhere inside, possibly in a child or a descendant element. When passed a string, matching is case-insensitive and searches for a substring. For example, "Playwright" matches <article><div>Playwright</div></article>.

Returns

Locator#
nth
Added in: v1.14 
Returns locator to the n-th matching element. It's zero based, nth(0) selects the first element.

Usage

const banana = await page.getByRole('listitem').nth(2);

Arguments

index number#
Returns

Locator#
or
Added in: v1.33 
Creates a locator matching all elements that match one or both of the two locators.

Note that when both locators match something, the resulting locator will have multiple matches, potentially causing a locator strictness violation.

Usage

Consider a scenario where you'd like to click on a "New email" button, but sometimes a security settings dialog shows up instead. In this case, you can wait for either a "New email" button, or a dialog and act accordingly.

note
If both "New email" button and security dialog appear on screen, the "or" locator will match both of them, possibly throwing the "strict mode violation" error. In this case, you can use locator.first() to only match one of them.

const newEmail = page.getByRole('button', { name: 'New' });
const dialog = page.getByText('Confirm security settings');
await expect(newEmail.or(dialog).first()).toBeVisible();
if (await dialog.isVisible())
  await page.getByRole('button', { name: 'Dismiss' }).click();
await newEmail.click();

Arguments

locator Locator#

Alternative locator to match.

Returns

Locator#
page
Added in: v1.19 
A page this locator belongs to.

Usage

locator.page();

Returns

Page#
press
Added in: v1.14 
Focuses the matching element and presses a combination of the keys.

Usage

await page.getByRole('textbox').press('Backspace');

Arguments

key string#

Name of the key to press or a character to generate, such as ArrowLeft or a.

options Object (optional)

delay number (optional)#

Time to wait between keydown and keyup in milliseconds. Defaults to 0.

noWaitAfter boolean (optional)#

Deprecated
This option will default to true in the future.

Actions that initiate navigations are waiting for these navigations to happen and for pages to start loading. You can opt out of waiting via setting this flag. You would only need this option in the exceptional cases such as navigating to inaccessible pages. Defaults to false.

timeout number (optional)#

Maximum time in milliseconds. Defaults to 0 - no timeout. The default value can be changed via actionTimeout option in the config, or by using the browserContext.setDefaultTimeout() or page.setDefaultTimeout() methods.

Returns

Promise<void>#
Details

Focuses the element, and then uses keyboard.down() and keyboard.up().

key can specify the intended keyboardEvent.key value or a single character to generate the text for. A superset of the key values can be found here. Examples of the keys are:

F1 - F12, Digit0- Digit9, KeyA- KeyZ, Backquote, Minus, Equal, Backslash, Backspace, Tab, Delete, Escape, ArrowDown, End, Enter, Home, Insert, PageDown, PageUp, ArrowRight, ArrowUp, etc.

Following modification shortcuts are also supported: Shift, Control, Alt, Meta, ShiftLeft, ControlOrMeta. ControlOrMeta resolves to Control on Windows and Linux and to Meta on macOS.

Holding down Shift will type the text that corresponds to the key in the upper case.

If key is a single character, it is case-sensitive, so the values a and A will generate different respective texts.

Shortcuts such as key: "Control+o", key: "Control++ or key: "Control+Shift+T" are supported as well. When specified with the modifier, modifier is pressed and being held while the subsequent key is being pressed.

pressSequentially
Added in: v1.38 
tip
In most cases, you should use locator.fill() instead. You only need to press keys one by one if there is special keyboard handling on the page.

Focuses the element, and then sends a keydown, keypress/input, and keyup event for each character in the text.

To press a special key, like Control or ArrowDown, use locator.press().

Usage

await locator.pressSequentially('Hello'); // Types instantly
await locator.pressSequentially('World', { delay: 100 }); // Types slower, like a user

An example of typing into a text field and then submitting the form:

const locator = page.getByLabel('Password');
await locator.pressSequentially('my password');
await locator.press('Enter');

Arguments

text string#

String of characters to sequentially press into a focused element.

options Object (optional)

delay number (optional)#

Time to wait between key presses in milliseconds. Defaults to 0.

noWaitAfter boolean (optional)#

Deprecated
This option has no effect.

This option has no effect.

timeout number (optional)#

Maximum time in milliseconds. Defaults to 0 - no timeout. The default value can be changed via actionTimeout option in the config, or by using the browserContext.setDefaultTimeout() or page.setDefaultTimeout() methods.

Returns

Promise<void>#
screenshot
Added in: v1.14 
Take a screenshot of the element matching the locator.

Usage

await page.getByRole('link').screenshot();

Disable animations and save screenshot to a file:

await page.getByRole('link').screenshot({ animations: 'disabled', path: 'link.png' });

Arguments

options Object (optional)
animations "disabled" | "allow" (optional)#

When set to "disabled", stops CSS animations, CSS transitions and Web Animations. Animations get different treatment depending on their duration:

finite animations are fast-forwarded to completion, so they'll fire transitionend event.
infinite animations are canceled to initial state, and then played over after the screenshot.
Defaults to "allow" that leaves animations untouched.

caret "hide" | "initial" (optional)#

When set to "hide", screenshot will hide text caret. When set to "initial", text caret behavior will not be changed. Defaults to "hide".

mask Array<Locator> (optional)#

Specify locators that should be masked when the screenshot is taken. Masked elements will be overlaid with a pink box #FF00FF (customized by maskColor) that completely covers its bounding box.

maskColor string (optional) Added in: v1.35#

Specify the color of the overlay box for masked elements, in CSS color format. Default color is pink #FF00FF.

omitBackground boolean (optional)#

Hides default white background and allows capturing screenshots with transparency. Not applicable to jpeg images. Defaults to false.

path string (optional)#

The file path to save the image to. The screenshot type will be inferred from file extension. If path is a relative path, then it is resolved relative to the current working directory. If no path is provided, the image won't be saved to the disk.

quality number (optional)#

The quality of the image, between 0-100. Not applicable to png images.

scale "css" | "device" (optional)#

When set to "css", screenshot will have a single pixel per each css pixel on the page. For high-dpi devices, this will keep screenshots small. Using "device" option will produce a single pixel per each device pixel, so screenshots of high-dpi devices will be twice as large or even larger.

Defaults to "device".

style string (optional) Added in: v1.41#

Text of the stylesheet to apply while making the screenshot. This is where you can hide dynamic elements, make elements invisible or change their properties to help you creating repeatable screenshots. This stylesheet pierces the Shadow DOM and applies to the inner frames.

timeout number (optional)#

Maximum time in milliseconds. Defaults to 0 - no timeout. The default value can be changed via actionTimeout option in the config, or by using the browserContext.setDefaultTimeout() or page.setDefaultTimeout() methods.

type "png" | "jpeg" (optional)#

Specify screenshot type, defaults to png.

Returns

Promise<Buffer>#
Details

This method captures a screenshot of the page, clipped to the size and position of a particular element matching the locator. If the element is covered by other elements, it will not be actually visible on the screenshot. If the element is a scrollable container, only the currently scrolled content will be visible on the screenshot.

This method waits for the actionability checks, then scrolls element into view before taking a screenshot. If the element is detached from DOM, the method throws an error.

Returns the buffer with the captured screenshot.

scrollIntoViewIfNeeded
Added in: v1.14 
This method waits for actionability checks, then tries to scroll element into view, unless it is completely visible as defined by IntersectionObserver's ratio.

See scrolling for alternative ways to scroll.

Usage

await locator.scrollIntoViewIfNeeded();
await locator.scrollIntoViewIfNeeded(options);

Arguments

options Object (optional)
timeout number (optional)#

Maximum time in milliseconds. Defaults to 0 - no timeout. The default value can be changed via actionTimeout option in the config, or by using the browserContext.setDefaultTimeout() or page.setDefaultTimeout() methods.

Returns

Promise<void>#
selectOption
Added in: v1.14 
Selects option or options in <select>.

Usage

<select multiple>
  <option value="red">Red</div>
  <option value="green">Green</div>
  <option value="blue">Blue</div>
</select>

// single selection matching the value or label
element.selectOption('blue');

// single selection matching the label
element.selectOption({ label: 'Blue' });

// multiple selection for red, green and blue options
element.selectOption(['red', 'green', 'blue']);

Arguments

values null | string | ElementHandle | Array<string> | Object | Array<ElementHandle> | Array<Object>#
value string (optional)

Matches by option.value. Optional.

label string (optional)

Matches by option.label. Optional.

index number (optional)

Matches by the index. Optional.

Options to select. If the <select> has the multiple attribute, all matching options are selected, otherwise only the first option matching one of the passed options is selected. String values are matching both values and labels. Option is considered matching if all specified properties match.
options Object (optional)
force boolean (optional)#

Whether to bypass the actionability checks. Defaults to false.

noWaitAfter boolean (optional)#

Deprecated
This option has no effect.

This option has no effect.

timeout number (optional)#

Maximum time in milliseconds. Defaults to 0 - no timeout. The default value can be changed via actionTimeout option in the config, or by using the browserContext.setDefaultTimeout() or page.setDefaultTimeout() methods.

Returns

Promise<Array<string>>#
Details

This method waits for actionability checks, waits until all specified options are present in the <select> element and selects these options.

If the target element is not a <select> element, this method throws an error. However, if the element is inside the <label> element that has an associated control, the control will be used instead.

Returns the array of option values that have been successfully selected.

Triggers a change and input event once all the provided options have been selected.

selectText
Added in: v1.14 
This method waits for actionability checks, then focuses the element and selects all its text content.

If the element is inside the <label> element that has an associated control, focuses and selects text in the control instead.

Usage

await locator.selectText();
await locator.selectText(options);

Arguments

options Object (optional)
force boolean (optional)#

Whether to bypass the actionability checks. Defaults to false.

timeout number (optional)#

Maximum time in milliseconds. Defaults to 0 - no timeout. The default value can be changed via actionTimeout option in the config, or by using the browserContext.setDefaultTimeout() or page.setDefaultTimeout() methods.

Returns

Promise<void>#
setChecked
Added in: v1.15 
Set the state of a checkbox or a radio element.

Usage

await page.getByRole('checkbox').setChecked(true);

Arguments

checked boolean#

Whether to check or uncheck the checkbox.

options Object (optional)

force boolean (optional)#

Whether to bypass the actionability checks. Defaults to false.

noWaitAfter boolean (optional)#

Deprecated
This option has no effect.

This option has no effect.

position Object (optional)#

x number

y number

A point to use relative to the top-left corner of element padding box. If not specified, uses some visible point of the element.

timeout number (optional)#

Maximum time in milliseconds. Defaults to 0 - no timeout. The default value can be changed via actionTimeout option in the config, or by using the browserContext.setDefaultTimeout() or page.setDefaultTimeout() methods.

trial boolean (optional)#

When set, this method only performs the actionability checks and skips the action. Defaults to false. Useful to wait until the element is ready for the action without performing it.

Returns

Promise<void>#
Details

This method checks or unchecks an element by performing the following steps:

Ensure that matched element is a checkbox or a radio input. If not, this method throws.
If the element already has the right checked state, this method returns immediately.
Wait for actionability checks on the matched element, unless force option is set. If the element is detached during the checks, the whole action is retried.
Scroll the element into view if needed.
Use page.mouse to click in the center of the element.
Ensure that the element is now checked or unchecked. If not, this method throws.
When all steps combined have not finished during the specified timeout, this method throws a TimeoutError. Passing zero timeout disables this.

setInputFiles
Added in: v1.14 
Upload file or multiple files into <input type=file>. For inputs with a [webkitdirectory] attribute, only a single directory path is supported.

Usage

// Select one file
await page.getByLabel('Upload file').setInputFiles(path.join(__dirname, 'myfile.pdf'));

// Select multiple files
await page.getByLabel('Upload files').setInputFiles([
  path.join(__dirname, 'file1.txt'),
  path.join(__dirname, 'file2.txt'),
]);

// Select a directory
await page.getByLabel('Upload directory').setInputFiles(path.join(__dirname, 'mydir'));

// Remove all the selected files
await page.getByLabel('Upload file').setInputFiles([]);

// Upload buffer from memory
await page.getByLabel('Upload file').setInputFiles({
  name: 'file.txt',
  mimeType: 'text/plain',
  buffer: Buffer.from('this is test')
});


Arguments

files string | Array<string> | Object | Array<Object>#
name string

File name

mimeType string

File type

buffer Buffer

File content

options Object (optional)
noWaitAfter boolean (optional)#

Deprecated
This option has no effect.

This option has no effect.

timeout number (optional)#

Maximum time in milliseconds. Defaults to 0 - no timeout. The default value can be changed via actionTimeout option in the config, or by using the browserContext.setDefaultTimeout() or page.setDefaultTimeout() methods.

Returns

Promise<void>#
Details

Sets the value of the file input to these file paths or files. If some of the filePaths are relative paths, then they are resolved relative to the current working directory. For empty array, clears the selected files.

This method expects Locator to point to an input element. However, if the element is inside the <label> element that has an associated control, targets the control instead.

tap
Added in: v1.14 
Perform a tap gesture on the element matching the locator.

Usage

await locator.tap();
await locator.tap(options);

Arguments

options Object (optional)
force boolean (optional)#

Whether to bypass the actionability checks. Defaults to false.

modifiers Array<"Alt" | "Control" | "ControlOrMeta" | "Meta" | "Shift"> (optional)#

Modifier keys to press. Ensures that only these modifiers are pressed during the operation, and then restores current modifiers back. If not specified, currently pressed modifiers are used. "ControlOrMeta" resolves to "Control" on Windows and Linux and to "Meta" on macOS.

noWaitAfter boolean (optional)#

Deprecated
This option has no effect.

This option has no effect.

position Object (optional)#

x number

y number

A point to use relative to the top-left corner of element padding box. If not specified, uses some visible point of the element.

timeout number (optional)#

Maximum time in milliseconds. Defaults to 0 - no timeout. The default value can be changed via actionTimeout option in the config, or by using the browserContext.setDefaultTimeout() or page.setDefaultTimeout() methods.

trial boolean (optional)#

When set, this method only performs the actionability checks and skips the action. Defaults to false. Useful to wait until the element is ready for the action without performing it. Note that keyboard modifiers will be pressed regardless of trial to allow testing elements which are only visible when those keys are pressed.

Returns

Promise<void>#
Details

This method taps the element by performing the following steps:

Wait for actionability checks on the element, unless force option is set.
Scroll the element into view if needed.
Use page.touchscreen to tap the center of the element, or the specified position.
If the element is detached from the DOM at any moment during the action, this method throws.

When all steps combined have not finished during the specified timeout, this method throws a TimeoutError. Passing zero timeout disables this.

note
element.tap() requires that the hasTouch option of the browser context be set to true.

textContent
Added in: v1.14 
Returns the node.textContent.

Asserting text
If you need to assert text on the page, prefer expect(locator).toHaveText() to avoid flakiness. See assertions guide for more details.

Usage

await locator.textContent();
await locator.textContent(options);

Arguments

options Object (optional)
timeout number (optional)#

Maximum time in milliseconds. Defaults to 0 - no timeout. The default value can be changed via actionTimeout option in the config, or by using the browserContext.setDefaultTimeout() or page.setDefaultTimeout() methods.

Returns

Promise<null | string>#
uncheck
Added in: v1.14 
Ensure that checkbox or radio element is unchecked.

Usage

await page.getByRole('checkbox').uncheck();

Arguments

options Object (optional)
force boolean (optional)#

Whether to bypass the actionability checks. Defaults to false.

noWaitAfter boolean (optional)#

Deprecated
This option has no effect.

This option has no effect.

position Object (optional)#

x number

y number

A point to use relative to the top-left corner of element padding box. If not specified, uses some visible point of the element.

timeout number (optional)#

Maximum time in milliseconds. Defaults to 0 - no timeout. The default value can be changed via actionTimeout option in the config, or by using the browserContext.setDefaultTimeout() or page.setDefaultTimeout() methods.

trial boolean (optional)#

When set, this method only performs the actionability checks and skips the action. Defaults to false. Useful to wait until the element is ready for the action without performing it.

Returns

Promise<void>#
Details

This method unchecks the element by performing the following steps:

Ensure that element is a checkbox or a radio input. If not, this method throws. If the element is already unchecked, this method returns immediately.
Wait for actionability checks on the element, unless force option is set.
Scroll the element into view if needed.
Use page.mouse to click in the center of the element.
Ensure that the element is now unchecked. If not, this method throws.
If the element is detached from the DOM at any moment during the action, this method throws.

When all steps combined have not finished during the specified timeout, this method throws a TimeoutError. Passing zero timeout disables this.

waitFor
Added in: v1.16 
Returns when element specified by locator satisfies the state option.

If target element already satisfies the condition, the method returns immediately. Otherwise, waits for up to timeout milliseconds until the condition is met.

Usage

const orderSent = page.locator('#order-sent');
await orderSent.waitFor();

Arguments

options Object (optional)
state "attached" | "detached" | "visible" | "hidden" (optional)#

Defaults to 'visible'. Can be either:

'attached' - wait for element to be present in DOM.
'detached' - wait for element to not be present in DOM.
'visible' - wait for element to have non-empty bounding box and no visibility:hidden. Note that element without any content or with display:none has an empty bounding box and is not considered visible.
'hidden' - wait for element to be either detached from DOM, or have an empty bounding box or visibility:hidden. This is opposite to the 'visible' option.
timeout number (optional)#

Maximum time in milliseconds. Defaults to 0 - no timeout. The default value can be changed via actionTimeout option in the config, or by using the browserContext.setDefaultTimeout() or page.setDefaultTimeout() methods.

Returns

Promise<void>#
Deprecated
elementHandle
Added in: v1.14 
Discouraged
Always prefer using Locators and web assertions over ElementHandles because latter are inherently racy.

Resolves given locator to the first matching DOM element. If there are no matching elements, waits for one. If multiple elements match the locator, throws.

Usage

await locator.elementHandle();
await locator.elementHandle(options);

Arguments

options Object (optional)
timeout number (optional)#

Maximum time in milliseconds. Defaults to 0 - no timeout. The default value can be changed via actionTimeout option in the config, or by using the browserContext.setDefaultTimeout() or page.setDefaultTimeout() methods.

Returns

Promise<ElementHandle>#
elementHandles
Added in: v1.14 
Discouraged
Always prefer using Locators and web assertions over ElementHandles because latter are inherently racy.

Resolves given locator to all matching DOM elements. If there are no matching elements, returns an empty list.

Usage

await locator.elementHandles();

Returns

Promise<Array<ElementHandle>>#
type
Added in: v1.14 
Deprecated
In most cases, you should use locator.fill() instead. You only need to press keys one by one if there is special keyboard handling on the page - in this case use locator.pressSequentially().

Focuses the element, and then sends a keydown, keypress/input, and keyup event for each character in the text.

To press a special key, like Control or ArrowDown, use locator.press().

Usage

Arguments

text string#

A text to type into a focused element.

options Object (optional)

delay number (optional)#

Time to wait between key presses in milliseconds. Defaults to 0.

noWaitAfter boolean (optional)#

Deprecated
This option has no effect.

This option has no effect.

timeout number (optional)#

Maximum time in milliseconds. Defaults to 0 - no timeout. The default value can be changed via actionTimeout option in the config, or by using the browserContext.setDefaultTimeout() or page.setDefaultTimeout() methods.

Returns

Promise<void>#
Previous
Keyboard
Next
Logger
Methods
all
allInnerTexts
allTextContents
and
ariaSnapshot
blur
boundingBox
check
clear
click
contentFrame
count
dblclick
dispatchEvent
dragTo
evaluate
evaluateAll
evaluateHandle
fill
filter
first
focus
frameLocator
getAttribute
getByAltText
getByLabel
getByPlaceholder
getByRole
getByTestId
getByText
getByTitle
highlight
hover
innerHTML
innerText
inputValue
isChecked
isDisabled
isEditable
isEnabled
isHidden
isVisible
last
locator
nth
or
page
press
pressSequentially
screenshot
scrollIntoViewIfNeeded
selectOption
selectText
setChecked
setInputFiles
tap
textContent
uncheck
waitFor
Deprecated
elementHandle
elementHandles
type
Learn
Getting started
Playwright Training
Learn Videos
Feature Videos
Community
Stack Overflow
Discord
Twitter
LinkedIn
More
GitHub
YouTube
Blog
Ambassadors
Copyright  2025 Microsoft

assistants
/
Playground
Dashboard
Docs
API reference

Assistants API quickstart
Beta
Step-by-step guide to creating an assistant.
A typical integration of the Assistants API has the following flow:

Create an Assistant by defining its custom instructions and picking a model. If helpful, add files and enable tools like Code Interpreter, File Search, and Function calling.
Create a Thread when a user starts a conversation.
Add Messages to the Thread as the user asks questions.
Run the Assistant on the Thread to generate a response by calling the model and the tools.
This starter guide walks through the key steps to create and run an Assistant that uses Code Interpreter. In this example, we're creating an Assistant that is a personal math tutor, with the Code Interpreter tool enabled.

Calls to the Assistants API require that you pass a beta HTTP header. This is handled automatically if youre using OpenAIs official Python or Node.js SDKs. OpenAI-Beta: assistants=v2

Step 1: Create an Assistant
An Assistant represents an entity that can be configured to respond to a user's messages using several parameters like model, instructions, and tools.

Create an Assistant
from openai import OpenAI
client = OpenAI()

assistant = client.beta.assistants.create(
  name="Math Tutor",
  instructions="You are a personal math tutor. Write and run code to answer math questions.",
  tools=[{"type": "code_interpreter"}],
  model="gpt-4o",
)
Step 2: Create a Thread
A Thread represents a conversation between a user and one or many Assistants. You can create a Thread when a user (or your AI application) starts a conversation with your Assistant.

Create a Thread
thread = client.beta.threads.create()
Step 3: Add a Message to the Thread
The contents of the messages your users or applications create are added as Message objects to the Thread. Messages can contain both text and files. There is a limit of 100,000 Messages per Thread and we smartly truncate any context that does not fit into the model's context window.

Add a Message to the Thread
message = client.beta.threads.messages.create(
  thread_id=thread.id,
  role="user",
  content="I need to solve the equation `3x + 11 = 14`. Can you help me?"
)
Step 4: Create a Run
Once all the user Messages have been added to the Thread, you can Run the Thread with any Assistant. Creating a Run uses the model and tools associated with the Assistant to generate a response. These responses are added to the Thread as assistant Messages.


With streaming

Without streaming
You can use the 'create and stream' helpers in the Python and Node SDKs to create a run and stream the response.

Create and Stream a Run
from typing_extensions import override
from openai import AssistantEventHandler
 
# First, we create a EventHandler class to define
# how we want to handle the events in the response stream.
 
class EventHandler(AssistantEventHandler):    
  @override
  def on_text_created(self, text) -> None:
    print(f"\nassistant > ", end="", flush=True)
      
  @override
  def on_text_delta(self, delta, snapshot):
    print(delta.value, end="", flush=True)
      
  def on_tool_call_created(self, tool_call):
    print(f"\nassistant > {tool_call.type}\n", flush=True)
  
  def on_tool_call_delta(self, delta, snapshot):
    if delta.type == 'code_interpreter':
      if delta.code_interpreter.input:
        print(delta.code_interpreter.input, end="", flush=True)
      if delta.code_interpreter.outputs:
        print(f"\n\noutput >", flush=True)
        for output in delta.code_interpreter.outputs:
          if output.type == "logs":
            print(f"\n{output.logs}", flush=True)
 
# Then, we use the `stream` SDK helper 
# with the `EventHandler` class to create the Run 
# and stream the response.
 
with client.beta.threads.runs.stream(
  thread_id=thread.id,
  assistant_id=assistant.id,
  instructions="Please address the user as Jane Doe. The user has a premium account.",
  event_handler=EventHandler(),
) as stream:
  stream.until_done()
See the full list of Assistants streaming events in our API reference here. You can also see a list of SDK event listeners for these events in the Python & Node repository documentation.

Next steps
Continue learning about Assistants Concepts in the Deep Dive
Learn more about Tools
Explore the Assistants playground
Check out our Assistants Quickstart app on github
Was this page useful?
